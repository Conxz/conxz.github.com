<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小孔成像</title>
  
  <subtitle>Kong Brain Observatory</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://conxz.net/"/>
  <updated>2020-05-04T18:31:17.175Z</updated>
  <id>http://conxz.net/</id>
  
  <author>
    <name>Xiangzhen Kong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CNS报告</title>
    <link href="http://conxz.net/2020/05/02/CNS-Talks/"/>
    <id>http://conxz.net/2020/05/02/CNS-Talks/</id>
    <published>2020-05-02T21:26:07.000Z</published>
    <updated>2020-05-04T18:31:17.175Z</updated>
    
    <content type="html"><![CDATA[<p>This is a collection of talks from this week’s CNS virtual conference. There are many fantastic talks. Hope the links would keep working well (although based on the conference website, ‘Each session is available 0 hours after the original broadcast of the session until <code>Saturday, May 16, 2020</code>‘). <strong>Please don’t use these for commercial purposes.</strong></p><p>You could check the conference details from <a href="https://www.cogneurosociety.org/schedule/" target="_blank" rel="noopener">Program Page</a>. </p><p><strong>Day 1</strong><br><a href="http://d2jr8iw3t7wi0m.cloudfront.net/CNS01-Keynote.mp4" target="_blank" rel="noopener">Opening Ceremonies &amp; Keynote Address</a></p><p>Invited Symposium 1 - Making Sense Out of Big Data In Cognitive Neuroscience</p><ul><li><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp1_Intro_Buckner.mp4" target="_blank" rel="noopener">Introduction</a></li><li><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp1_Talk1_Stringer.mp4" target="_blank" rel="noopener">Talk 1: High-Dimensional Structure of Signal and Noise in 20,000 Neuron Recording, Carsen Stringer</a></li><li><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp1_Talk2_Kording.mp4" target="_blank" rel="noopener">Talk 2: Casual Inference with Big Data Sets, Konrad Kording</a></li><li><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp1_Talk3_Buckner.mp4" target="_blank" rel="noopener">Talk 3: Lessons and Opportunities of Big Data Superstructing in a Virtual World, Randy L. Buckner</a></li></ul><p><a href="http://d2jr8iw3t7wi0m.cloudfront.net/DATABLITZ_SESSION_1_Murty_ALL_COMBINED.mp4" target="_blank" rel="noopener">Data Blitz Session 1</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/DATABLITZ_SESSION_2_Johnson_ALL_COMBINED.mp4" target="_blank" rel="noopener">Data Blitz Session 2</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/DATABLITZ_SESSION_3_Berryhill_ALL_COMBINED.mp4" target="_blank" rel="noopener">Data Blitz Session 3</a></p><p><strong>Day 2</strong><br>You could check the conference details from <a href="https://www.cogneurosociety.org/schedule/" target="_blank" rel="noopener">Program Page</a>. </p><p>Invited Symposium 2: <a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp2_Intro_Kayser.mp4" target="_blank" rel="noopener">Introduction</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp2_Talk1_Denison.mp4" target="_blank" rel="noopener">Talk 1</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp2_Talk2_Gershman.mp4" target="_blank" rel="noopener">Talk 2</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp2_Talk3_Noppeney.mp4" target="_blank" rel="noopener">Talk 3</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp2_Talk4_Kayser.mp4" target="_blank" rel="noopener">Talk 4</a></p><p><a href="http://d2jr8iw3t7wi0m.cloudfront.net/CNS01-DCC_Talk.mp4" target="_blank" rel="noopener">The Fred Kavli Distinguished Career Contributions in Cognitive Neuroscience Lecture, Hemispheric Organization for Visual Recognition, Marlene Behrmann</a></p><p>Symposiums</p><table><thead><tr><th>Symposium 1</th><th>Symposium 2</th><th>Symposium 3</th><th>Symposium 4</th></tr></thead><tbody><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp1_Intro_Voss.mp4" target="_blank" rel="noopener">Intro</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp2_INTRO_Farah.mp4" target="_blank" rel="noopener">Intro</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp3_Intro_Sharot.mp4" target="_blank" rel="noopener">Intro</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp4_Intro_Saygin.mp4" target="_blank" rel="noopener">Intro</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp1_Talk1_Hartwigsen.mp4" target="_blank" rel="noopener">Talk 1</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp2_Talk1_Thomason.mp4" target="_blank" rel="noopener">Talk 1</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp3_Talk1_Schulz.mp4" target="_blank" rel="noopener">Talk 1</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp4_Talk1_Dilks.mp4" target="_blank" rel="noopener">Talk 1</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp1_Talk2_Kahnt.mp4" target="_blank" rel="noopener">Talk 2</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp2_Talk2_LUBY.mp4" target="_blank" rel="noopener">Talk 2</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp3_Talk2_Bassett-update.mp4" target="_blank" rel="noopener">Talk 2</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp4_Talk2_Cusack.mp4" target="_blank" rel="noopener">Talk 2</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp1_Talk3_Fox.mp4" target="_blank" rel="noopener">Talk 3</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp2_Talk3_Nusslock.mp4" target="_blank" rel="noopener">Talk 3</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp3_Talk3_ Bromberg-Martin.mp4" target="_blank" rel="noopener">Talk 3</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp4_Talk3_Saygin (1%29.mp4" target="_blank" rel="noopener">Talk 3</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp1_Talk4_Voss.mp4" target="_blank" rel="noopener">Talk 4</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp2_Talk4_Kim.mp4" target="_blank" rel="noopener">Talk 4</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp3_Talk4_CogliatiDezza.mp4" target="_blank" rel="noopener">Talk 4</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp4_Talk4_Bedny.mp4" target="_blank" rel="noopener">Talk 4</a></td></tr></tbody></table><p><strong>Day 3</strong><br>You could check the conference details from <a href="https://www.cogneurosociety.org/schedule/" target="_blank" rel="noopener">Program Page</a>. </p><p>Symposiums</p><table><thead><tr><th>Symposium 5</th><th>Symposium 6</th><th>Symposium 7</th><th>Symposium 8</th></tr></thead><tbody><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp5_Intro_Schechtman.mp4" target="_blank" rel="noopener">Intro</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp6_Intro_Horowitz-Kraus.mp4" target="_blank" rel="noopener">Intro</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp7_Intro_Turner.mp4" target="_blank" rel="noopener">Intro</a></td><td>See Talk 1</td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp5_Talk1_Zaghloul.mp4" target="_blank" rel="noopener">Talk 1</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp6_Talk1_Horowitz-Kraus.mp4" target="_blank" rel="noopener">Talk 1</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp7_Talk1_Frank.mp4" target="_blank" rel="noopener">Talk 1</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp8_Intro_Talk1_ Coutanche.mp4" target="_blank" rel="noopener">Talk 1</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp5_Talk2_Petzka.mp4" target="_blank" rel="noopener">Talk 2</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp6_Talk2_ Gaab.mp4" target="_blank" rel="noopener">Talk 2</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp7_Talk2_Howard.mp4" target="_blank" rel="noopener">Talk 2</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp8_Talk2_Baker.mp4" target="_blank" rel="noopener">Talk 2</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp5_Talk3_Liu.mp4" target="_blank" rel="noopener">Talk 3</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp6_Talk3_Skeide.mp4" target="_blank" rel="noopener">Talk 3</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp7_Talk3_Love.mp4" target="_blank" rel="noopener">Talk 3</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp8_Talk3_Ryan.mp4" target="_blank" rel="noopener">Talk 3</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp5_Talk4_Cohen.mp4" target="_blank" rel="noopener">Talk 4</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp6_Talk4_Lyytinen.mp4" target="_blank" rel="noopener">Talk 4</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp7_Talk4_Turner.mp4" target="_blank" rel="noopener">Talk 4</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp8_Talk4_Barense.mp4" target="_blank" rel="noopener">Talk 4</a></td></tr><tr><td>-</td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp6_Talk5_Vanderauwera.mp4" target="_blank" rel="noopener">Talk 5</a></td><td>-</td><td>-</td></tr></tbody></table><p>Young Investigator Award: <a href="http://d2jr8iw3t7wi0m.cloudfront.net/YIA_Intro_plus_Talk1_Harley.mp4" target="_blank" rel="noopener">YIA 1</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/YIA_Talk2_Gershman.mp4" target="_blank" rel="noopener">YIA 2</a></p><p>Special Session: <a href="http://d2jr8iw3t7wi0m.cloudfront.net/Special_Intro_Levine.mp4" target="_blank" rel="noopener">Introduction</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/Special_Talk1_Vaidya.mp4" target="_blank" rel="noopener">Talk 1</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/Special_Talk2_Gilboa.mp4" target="_blank" rel="noopener">Talk 2</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/Special_Talk3_Vallesi.mp4" target="_blank" rel="noopener">Talk 3</a> | <a href="http://d2jr8iw3t7wi0m.cloudfront.net/Special_Talk4_Rosenbaum.mp4" target="_blank" rel="noopener">Talk 4</a></p><p><strong>Day 4</strong><br>You could check the conference details from <a href="https://www.cogneurosociety.org/schedule/" target="_blank" rel="noopener">Program Page</a>. </p><p>Invited Symposium</p><table><thead><tr><th>Invited Symposium 3</th><th>Invited Symposium 4</th></tr></thead><tbody><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp3_Intro_LaBar.mp4" target="_blank" rel="noopener">Intro</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp4_Intro_Sallet.mp4" target="_blank" rel="noopener">Intro</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp3_Talk1_LaBar.mp4" target="_blank" rel="noopener">Talk 1</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp4_Talk1_Grossman.mp4" target="_blank" rel="noopener">Talk 1</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp3_Talk2_Wager.mp4" target="_blank" rel="noopener">Talk 2</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp4_Talk2_Sallet.mp4" target="_blank" rel="noopener">Talk 2</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp3_Talk3_Keltner.mp4" target="_blank" rel="noopener">Talk 3</a></td><td>[Talk 3]</td></tr><tr><td>[Talk 4]</td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/InvitedSymp4_Talk4_Konofagou.mp4" target="_blank" rel="noopener">Talk 4</a></td></tr></tbody></table><p>[George A. Miller Prize in Cognitive Neuroscience Lecture, Nancy Kanwisher]</p><p>Symposiums</p><table><thead><tr><th>Symposium 9</th><th>Symposium 10</th><th>Symposium 11</th></tr></thead><tbody><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp9_Intro_Margulies.mp4" target="_blank" rel="noopener">Intro</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp10_Intro_Ngo.mp4" target="_blank" rel="noopener">Intro</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp11_Intro_Freud.mp4" target="_blank" rel="noopener">Intro</a></td></tr><tr><td>[Talk 1]</td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp10_Talk1_Ngo.mp4" target="_blank" rel="noopener">Talk 1</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp11_Talk1_Freud.mp4" target="_blank" rel="noopener">Talk 1</a></td></tr><tr><td>[Talk 2]</td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp10_Talk2_Zeithamova.mp4" target="_blank" rel="noopener">Talk 2</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp11_Talk2_Striem-Amit.mp4" target="_blank" rel="noopener">Talk 2</a></td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp9_Talk3_Murray.mp4" target="_blank" rel="noopener">Talk 3</a></td><td>[Talk 3]</td><td>[Talk 3]</td></tr><tr><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp9_Talk4_Smallwood.mp4" target="_blank" rel="noopener">Talk 4</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp10_Talk4_Polyn.mp4" target="_blank" rel="noopener">Talk 4</a></td><td><a href="http://d2jr8iw3t7wi0m.cloudfront.net/Symp11_Talk4_Mahon.mp4" target="_blank" rel="noopener">Talk 4</a></td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;This is a collection of talks from this week’s CNS virtual conference. There are many fantastic talks. Hope the links would keep working 
      
    
    </summary>
    
      <category term="Xs" scheme="http://conxz.net/categories/Xs/"/>
    
    
      <category term="cognitive neuroscience" scheme="http://conxz.net/tags/cognitive-neuroscience/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="virtual conference" scheme="http://conxz.net/tags/virtual-conference/"/>
    
  </entry>
  
  <entry>
    <title>空间导航脑网络和S100B基因</title>
    <link href="http://conxz.net/2020/02/25/spatial-navigation-network-s100b/"/>
    <id>http://conxz.net/2020/02/25/spatial-navigation-network-s100b/</id>
    <published>2020-02-25T22:25:39.000Z</published>
    <updated>2020-02-25T22:43:33.858Z</updated>
    
    <content type="html"><![CDATA[<p>工作原因，最近需要把两篇以前发表的文章的摘要翻译为中文，顺手贴过来一份。这两篇文章都是关于人类空间导航脑网络的。</p><ul><li><p>Kong, X. Z., Wang, X., Pu, Y., Huang, L., Hao, X., Zhen, Z., &amp; Liu, J. (2017). <a href="https://link.springer.com/article/10.1007/s00429-016-1243-8" target="_blank" rel="noopener">Human navigation network: the intrinsic functional organization and behavioral relevance</a>. Brain Structure and Function, 222(2), 749-764.</p><p>  关键词： <code>空间导航</code> <code>导航网络</code> <code>功能连接</code> <code>个体差异</code> <code>脑连接组</code></p><p>  空间导航是一项至关重要的认知能力。已有研究发现人脑中有多个区域参与导航相关的任务，但是，我们对于这些脑区如何交互，并作为一个功能网络支持灵活的导航行为还知之甚少。本研究采用一项新的研究方法，整合了神经影像元分析和大样本脑功能连接和行为学数据。具体而言，首先，我们结合大尺度神经影像元分析和静息态功能磁共振成像，构建了每一名被试的空间导航脑网络。然后，我们系统考察了导航网络的多种拓扑属性，其中包括小世界、模块化和核心节点。最后，我们基于一组健康年轻成人样本考察了这些拓扑属性的行为学意义。我们发现，导航网络整体上呈现明显的小世界属性和模块化组织特征。更重要的是，我们发现导航网络的小世界和模块化属性的提高与更好的导航能力有关。最后，我们发现右侧压后皮层是导航网络中的核心节点，且该脑区更高的中介度与更好的导航能力显著相关。该研究对于理解导航网络的组织结构提供了新的视角。此外，研究结果表明，该研究方法在研究人脑中功能网络，及其与老化和脑疾病的行为和功能障碍的关系等方面存在潜在应用价值。</p></li><li><p>Kong, X. Z., Song, Y., Zhen, Z., &amp; Liu, J. (2017). <a href="https://academic.oup.com/cercor/article/27/2/1326/3056269" target="_blank" rel="noopener">Genetic variation in S100B modulates neural processing of visual scenes in Han Chinese</a>. Cerebral Cortex, 27(2), 1326-1336.</p><p>  关键词：<code>空间导航</code> <code>S100B</code> <code>遗传</code> <code>基因表达</code> <code>空间导航</code></p><p>  空间导航对于人和动物的生存和生活都至关重要。已有动物研究发现，S100B基因与小鼠的空间导航表现存在因果关系。但是，目前影响人类导航及其神经基础的遗传因素仍不清楚。本研究首次揭示了S100B基因参与调节人类导航相关脑活动。具体而言，首先，我们采用一项新的整合方法，发现人类大脑中S100B基因表达的空间模式与空间导航相关的大脑激活模式显著相关。此外，在一组健康年轻成人的样本中，我们发现S100B基因单核苷酸多态性调节了压后皮质和海马旁回脑区的场景选择性激活。最后，血清S100B蛋白水平中介了S100B基因与压后皮层场景选择性激活的关系。这项研究为理解人类空间导航的神经遗传机制提供了新的视角，同时，提供了一种发现认知功能相关候选基因的新方法。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;工作原因，最近需要把两篇以前发表的文章的摘要翻译为中文，顺手贴过来一份。这两篇文章都是关于人类空间导航脑网络的。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Kong, X. Z., Wang, X., Pu, Y., Huang, L., Hao, X., Zhen, Z., &amp;am
      
    
    </summary>
    
      <category term="BrainResearch" scheme="http://conxz.net/categories/BrainResearch/"/>
    
    
      <category term="gene" scheme="http://conxz.net/tags/gene/"/>
    
      <category term="navigation" scheme="http://conxz.net/tags/navigation/"/>
    
      <category term="navigation network" scheme="http://conxz.net/tags/navigation-network/"/>
    
      <category term="S100B" scheme="http://conxz.net/tags/S100B/"/>
    
  </entry>
  
  <entry>
    <title>脑影像遗传学：语言脑功能网络的基因表达相关</title>
    <link href="http://conxz.net/2020/01/31/Gene-Expression-and-Language-Network/"/>
    <id>http://conxz.net/2020/01/31/Gene-Expression-and-Language-Network/</id>
    <published>2020-01-31T22:37:06.000Z</published>
    <updated>2020-01-31T23:17:03.106Z</updated>
    
    <content type="html"><![CDATA[<p>先放全文信息：<br>Kong, X., Tzourio-Mazoyer, N., Joliot, M., Fedorenko, E., Liu, J., Fisher, S.E., Francks, C.(2020). Gene Expression Correlates of the Cortical Network Underlying Sentence Processing. Neurobiology of Language. Advance publication. <a href="https://doi.org/10.1162/nol_a_00004" target="_blank" rel="noopener">https://doi.org/10.1162/nol_a_00004</a></p><p>关键词：<code>语言</code> <code>脑网络</code> <code>功能网络</code> <code>基因表达</code> <code>神经发展</code> <code>自闭症</code></p><p>脑影像遗传学研究通过整合不同成像模态脑影像数据和遗传学数据，探索脑结构/功能与遗传变量之间的潜在关联，进而帮助我们了解、认识不同认知功能和相关脑疾病的遗传基础和发展规律。通常情况下，脑影像遗传学研究基于个体差异方法将来自同一批被试的脑影像数据和基因表型数据相关联。目前，研究者已经发表了一些脑影像遗传学的研究。但是，目前该领域仍然面临着样本量限制、多重比较校正和单个基因位点效应偏小等关键问题。<a id="more"></a><br>近年来，研究者开始在研究方法上探索新的可能性：将死后的脑组织的局部脑区基因表达量与另一组被试的脑影像数据进行关联。采用类似的研究方法，研究者发表了一系列关于脑结构/功能组织特征和脑疾病的研究成果，比如，研究发现，局部脑区的基因表达模式与静息状态下的功能连接、白质结构连接、以及精神分裂症和自闭症等脑疾病相关的脑连接异常存在关联。该方法基于一个必要的假定：基于一组死后的脑组织数据得到的局部基因表达模式具有足够的代表性，以足够与另一组被试的脑影像数据进行关联分析。<br>我们的这项研究便受到了这些研究的启发。与已有研究不同的是，我们关注的是一个更贴近认知神经科学的问题：核心认知功能的遗传和分析机制是什么？在该研究中，我们重点关注一项人类特有的能力 - 语言。已有研究显示，语言相关的认知能力具有很高的遗传度，另外，在语义理解任务下的脑活动也受到遗传因素的控制。目前，研究者已经发现，FOXP2等少数基因可能语言相关的疾病有关。但是，语言能力相关的个体差异的大部分可遗传变异并不能被这些基因解释，而这些基因也不可能在缺少与其他大量基因交互的情况下完成支撑复杂语言功能的脑网络的创建和维持。<br><img src="/images/post_images/lang1.png" alt="Schematic of the computation pipeline"><br>为了进一步揭示语言脑网络的遗传和分子机制，在这篇研究中，我们系统整合了任务fMRI数据、基于大数据的脑影像元分析数据、静息态功能连接和基因表达图谱数据。具体而言，我们的研究对象是负责高级语言功能的左半脑的颞叶和额叶脑网络。首先，我们基于任务fMRI数据定义左半脑参与句子加工的皮层脑区；为了确保不同定义方法的稳定性和可扩展性，我们采用了三个独立的数据集和定义方法。然后，基于两个独立数据集的静息态数据，我们计算得到了这些功能特异脑区之间的功能连接网络。同时，我们基于Allen脑图谱数据计算这些功能特异脑区之间的基因表达相似性模式，并与相应的功能连接网络进行关联分析。此外，我们考察了单个基因在该脑-基因关联中的贡献，并基于此识别出一组贡献指标一致高的基因。最后，通过一系列生物信息学分析，我们进一步探索了该组基因的功能意义和表达特异性，以及其在自闭症、精神分裂症和智力等方面的可能贡献。<br><img src="/images/post_images/lang2.png" alt="Functional and transcriptomic networks"><br>结果发现，语言脑功能网络的基因表达相似性模式与功能连接网络模式显著相关，即，基因表达模式相似的脑区往往呈现较强的功能连接；而且，在不同的语言脑网络定义策略下可以观察到类似的脑-基因关联。同时，我们识别了可能与语言脑功能网络内功能连接相关的一组基因；进一步的生物信息学分析显示，这一组基因参与了神经发育和肌动蛋白相关功能，且与自闭症（通常涉及语言交流障碍）呈现显著富集关联。<br><img src="/images/post_images/lang3.png" alt="The consensus set of genes"><br>综上，我们首次报告了语言脑功能网络的基因表达相关；并识别了一组可能参与语言脑功能网络的发展和维持的基因；这一组基因可能在语言障碍等相关脑疾病的形成过程中扮演了重要角色。这是一个探索性的项目，在未来的研究中我们将开展进一步的验证和深入，相关研究结果可以帮助我们认识语言脑功能网络和相关脑疾病的遗传基础。同时，该项目提出并采用的整合方法为研究其他复杂认知功能提供了新的途径。</p><p>Kong, X.Z., Tzourio-Mazoyer, N., Joliot, M., Fedorenko, E., Liu, J., Fisher, S.E. and Francks, C., 2019. Gene expression correlates of the cortical network underlying sentence processing. Neurobiology of Language, (Just Accepted), pp.1-53.<br>Kong, X.Z., Song, Y., Zhen, Z. and Liu, J., 2017. Genetic variation in S100B modulates neural processing of visual scenes in Han Chinese. Cerebral Cortex, 27(2), pp.1326-1336.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;先放全文信息：&lt;br&gt;Kong, X., Tzourio-Mazoyer, N., Joliot, M., Fedorenko, E., Liu, J., Fisher, S.E., Francks, C.(2020). Gene Expression Correlates of the Cortical Network Underlying Sentence Processing. Neurobiology of Language. Advance publication. &lt;a href=&quot;https://doi.org/10.1162/nol_a_00004&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://doi.org/10.1162/nol_a_00004&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;关键词：&lt;code&gt;语言&lt;/code&gt; &lt;code&gt;脑网络&lt;/code&gt; &lt;code&gt;功能网络&lt;/code&gt; &lt;code&gt;基因表达&lt;/code&gt; &lt;code&gt;神经发展&lt;/code&gt; &lt;code&gt;自闭症&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;脑影像遗传学研究通过整合不同成像模态脑影像数据和遗传学数据，探索脑结构/功能与遗传变量之间的潜在关联，进而帮助我们了解、认识不同认知功能和相关脑疾病的遗传基础和发展规律。通常情况下，脑影像遗传学研究基于个体差异方法将来自同一批被试的脑影像数据和基因表型数据相关联。目前，研究者已经发表了一些脑影像遗传学的研究。但是，目前该领域仍然面临着样本量限制、多重比较校正和单个基因位点效应偏小等关键问题。
    
    </summary>
    
      <category term="BrainResearch" scheme="http://conxz.net/categories/BrainResearch/"/>
    
    
      <category term="language" scheme="http://conxz.net/tags/language/"/>
    
      <category term="language network" scheme="http://conxz.net/tags/language-network/"/>
    
      <category term="gene expression" scheme="http://conxz.net/tags/gene-expression/"/>
    
      <category term="imaging genetics" scheme="http://conxz.net/tags/imaging-genetics/"/>
    
  </entry>
  
  <entry>
    <title>替换文本数据中的Tab为空格</title>
    <link href="http://conxz.net/2020/01/27/tab2space/"/>
    <id>http://conxz.net/2020/01/27/tab2space/</id>
    <published>2020-01-27T19:18:34.000Z</published>
    <updated>2020-01-27T19:32:25.965Z</updated>
    
    <content type="html"><![CDATA[<p>存储数据的文本文件中常用空格、Tab、逗号或分号等作为分隔符。一些常用的数据分析工具可能仅接受这些分隔符中的一种，这时便需要将其他分隔符的数据转换为相应工具接受的数据格式。类似的数据准备工作也是实际数据分析工作中相当耗精力的部分。<br>下面是针对Tab转空格问题的两个方便的解决方案。</p><ul><li>方法1. sed是常用的方式，可以灵活指定需要替换的内容和目标内容。<br><code>sed -i “s/\t/    /g” filename</code></li><li>方法2. expand提供了一个方便的替换Tab为空格的工具。<br><code>expand -t 1 filename</code></li></ul><p><code>Usage: expand [OPTION]… [FILE]…<br>Convert tabs in each FILE to spaces, writing to standard output.<br>With no FILE, or when FILE is -, read standard input.<br>Mandatory arguments to long options are mandatory for short options too.<br>  -i, –initial       do not convert tabs after non blanks<br>  -t, –tabs=NUMBER   have tabs NUMBER characters apart, not 8<br>  -t, –tabs=LIST     use comma separated list of explicit tab positions<br>      –help     display this help and exit<br>      –version  output version information and exit<br></code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;存储数据的文本文件中常用空格、Tab、逗号或分号等作为分隔符。一些常用的数据分析工具可能仅接受这些分隔符中的一种，这时便需要将其他分隔符的数据转换为相应工具接受的数据格式。类似的数据准备工作也是实际数据分析工作中相当耗精力的部分。&lt;br&gt;下面是针对Tab转空格问题的两个方便
      
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="linux" scheme="http://conxz.net/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>Presentation Learning Day 3</title>
    <link href="http://conxz.net/2020/01/14/Presentation-Learning-Day-3/"/>
    <id>http://conxz.net/2020/01/14/Presentation-Learning-Day-3/</id>
    <published>2020-01-13T23:31:52.000Z</published>
    <updated>2020-01-13T23:37:53.718Z</updated>
    
    <content type="html"><![CDATA[<p>Everybody<br>Welcome to xx. And welcome to the xx<br>My name is xx xx. I am the xxx of the organization of xx</p><p>xx is a really amazing place to host the meeting. and it’s really quite suitable.<br>xxx played a major role in early medicine and neuroscience, in many ways,  </p><p>it’s also hard to believe that it’s been xx years since the first xxx conference in xx.<br>at that time, it really was just a conference. In the second meeting in xxx, it was decided to become a organization.<br>Just in the last year, we decided to change to a society.<br>so really it has been serve as an evolution over time.<br>I attended the boston meeting, but I could go to xx cos I was a poor graduate student. so wasn’t able to afford it. <a id="more"></a></p><p>but just to give you a sense what was happening xx years ago.<br>xx had just broken xx; xx was just over xx; xxx was released; jave script was first intraduced we are still using; xxx was first announced. xx has just started.<br>in many ways, I cann’t believe that it’s been that long, but that does not seem like that it was that long. </p><p>I encourage you to look at some of the blocks and some activities about what has evolved throughout the xx years in this particular meeting.<br>we have a really wonderful program I hope you could agree.<br>some of our keynotes are xxx</p><p>Thanks to the program committee chaired by xx who work very hard to put these together.<br>Thanks to the xx for keeping track for everything, and doing so much.<br>Thanks to you for your attendance.<br>Without further to do, I will introduce xx who will talk about xxx </p><p>Reference<br><a href="https://www.pathlms.com/ohbm/courses/12238/sections/15844/video_presentations/137861" target="_blank" rel="noopener">https://www.pathlms.com/ohbm/courses/12238/sections/15844/video_presentations/137861</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Everybody&lt;br&gt;Welcome to xx. And welcome to the xx&lt;br&gt;My name is xx xx. I am the xxx of the organization of xx&lt;/p&gt;
&lt;p&gt;xx is a really amazing place to host the meeting. and it’s really quite suitable.&lt;br&gt;xxx played a major role in early medicine and neuroscience, in many ways,  &lt;/p&gt;
&lt;p&gt;it’s also hard to believe that it’s been xx years since the first xxx conference in xx.&lt;br&gt;at that time, it really was just a conference. In the second meeting in xxx, it was decided to become a organization.&lt;br&gt;Just in the last year, we decided to change to a society.&lt;br&gt;so really it has been serve as an evolution over time.&lt;br&gt;I attended the boston meeting, but I could go to xx cos I was a poor graduate student. so wasn’t able to afford it.
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="conference" scheme="http://conxz.net/tags/conference/"/>
    
      <category term="presentation" scheme="http://conxz.net/tags/presentation/"/>
    
      <category term="learning" scheme="http://conxz.net/tags/learning/"/>
    
  </entry>
  
  <entry>
    <title>pytorch入门例子3：模型训练和测试</title>
    <link href="http://conxz.net/2020/01/10/pytorch-example-3/"/>
    <id>http://conxz.net/2020/01/10/pytorch-example-3/</id>
    <published>2020-01-10T22:43:50.000Z</published>
    <updated>2020-01-10T23:31:26.536Z</updated>
    
    <content type="html"><![CDATA[<p>CIFAR10训练集50,000<br>CIFAR10测试集10,000<br>图片+标签</p><p>像下面的neural network，不用GPU也可以很好地完成训练。这个模型和<a href="http://conxz.net/2020/01/09/pytorch-example-2/">之前的例子</a>类似。<a id="more"></a></p><pre>import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1 = nn.Conv2d(3, 6, 5)        self.pool = nn.MaxPool2d(2, 2)        self.conv2 = nn.Conv2d(6, 16, 5)        self.fc1 = nn.Linear(16 * 5 * 5, 120)        self.fc2 = nn.Linear(120, 84)        self.fc3 = nn.Linear(84, 10)    def forward(self, x):        x = self.pool(F.relu(self.conv1(x)))        x = self.pool(F.relu(self.conv2(x)))        x = x.view(-1, 16 * 5 * 5)        x = F.relu(self.fc1(x))        x = F.relu(self.fc2(x))        x = self.fc3(x)        return xnet = Net()</pre><p>完成训练之后，可以将模型状态保存，以备下一次直接使用。</p><pre>PATH = './cifar_net.pth'torch.save(net.state_dict(), PATH)</pre><p>读取之前保存的模型状态，并测试新数据。</p><pre>net = Net()net.load_state_dict(torch.load(PATH))outputs = net(new_images)_, predicted = torch.max(outputs, 1) # 取最大值对应的label</pre><p>Source<br><a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" target="_blank" rel="noopener">DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CIFAR10训练集50,000&lt;br&gt;CIFAR10测试集10,000&lt;br&gt;图片+标签&lt;/p&gt;
&lt;p&gt;像下面的neural network，不用GPU也可以很好地完成训练。这个模型和&lt;a href=&quot;http://conxz.net/2020/01/09/pytorch-example-2/&quot;&gt;之前的例子&lt;/a&gt;类似。
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="pytorch" scheme="http://conxz.net/tags/pytorch/"/>
    
      <category term="machine learning" scheme="http://conxz.net/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>pytorch入门例子2</title>
    <link href="http://conxz.net/2020/01/09/pytorch-example-2/"/>
    <id>http://conxz.net/2020/01/09/pytorch-example-2/</id>
    <published>2020-01-09T22:30:26.000Z</published>
    <updated>2020-01-09T22:51:48.637Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个略复杂的入门例子，涵盖了一个典型神经网络的训练过程。</p><pre><code>import torch.nn as nnimport torch.nn.functional as F# Define the network structureclass Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1 = nn.Conv2d(1,6,3) # Convolutions        self.conv2 = nn.Conv2d(6,16,3)        self.fc1 = nn.Linear(16*6*6,120) # Full connections        self.fc2 = nn.Linear(120,84)        self.fc3 = nn.Linear(84, 10)    def forward(self, x):        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))        x = F.max_pool2d(F.relu(self.conv2(x)), 2)        x = x.view(-1, self.num_flat_features(x))        x = F.relu(self.fc1(x)) # rectified linear unit        x = F.relu(self.fc2(x))        x = self.fc3(x)        return x    def num_flat_features(self, x):        size = x.size()[1:]        num_features = 1        for s in size:            num_features *=s        return num_featuresnet = Net()print(net)<a id="more"></a># Processing inputs and calling backwardinput = torch.randn(1,1,32,32)out = net(input)print(out)net.zero_grad()out.backward(torch.randn(1,10))# Computing the lossoutput = net(input)target = torch.randn(10)target = target.view(1,-1)criterion = nn.MSELoss()loss = criterion(output, target)print(loss)# Backpropnet.zero_grad()print('conv1.bias.grad before backward')print(net.conv1.bias.grad)loss.backward()print('conv1.bias.grad after backward')print(net.conv1.bias.grad)# Updating the weights of the network# weight = weight - learning_rate * gradientlearning_rate = 0.01for f in net.parameters():    f.data.sub_(f.grad.data*learning_rate)# torch.optimimport torch.optim as optimoptimizer = option.SGD(net.parameters(), lr=0.01)optimizer = optim.SGD(net.parameters(), lr=0.01)optimizer.zero_grad()output = net(input)loss = criterion(output, target)loss.backward()optimizer.step()</code></pre><p>Source<br><a href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html" target="_blank" rel="noopener">DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一个略复杂的入门例子，涵盖了一个典型神经网络的训练过程。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
import torch.nn as nn
import torch.nn.functional as F

# Define the network structure
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1,6,3) # Convolutions
        self.conv2 = nn.Conv2d(6,16,3)
        self.fc1 = nn.Linear(16*6*6,120) # Full connections
        self.fc2 = nn.Linear(120,84)
        self.fc3 = nn.Linear(84, 10)
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x)) # rectified linear unit
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *=s
        return num_features

net = Net()
print(net)
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="pytorch" scheme="http://conxz.net/tags/pytorch/"/>
    
      <category term="machine learning" scheme="http://conxz.net/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>一个pytorch入门例子</title>
    <link href="http://conxz.net/2020/01/08/a-pytorch-example/"/>
    <id>http://conxz.net/2020/01/08/a-pytorch-example/</id>
    <published>2020-01-08T22:12:41.000Z</published>
    <updated>2020-01-09T18:26:15.430Z</updated>
    
    <content type="html"><![CDATA[<pre><code>import torchfrom torch.autograd import Variabledtype = torch.FloatTensorN, D_in, H, D_out = 64, 1000, 100, 10 # one input layer, one hidden layer, and one output layer<a id="more"></a>x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)learning_rate = 1e-6for t in range(500):    y_pred = x.mm(w1).clamp(min=0).mm(w2)    loss = (y_pred - y).pow(2).sum()    print(t, loss.data)    loss.backward()    w1.data -= learning_rate * w1.grad    w2.data -= learning_rate * w2.grad    w1.grad.zero_()    w2.grad.zero_()</code></pre><p>输出<br><code><br>0 tensor(33538672.)<br>1 tensor(29973312.)<br>2 tensor(26784652.)<br>3 tensor(21361500.)<br>4 tensor(14865291.)<br>5 tensor(9206818.)<br>6 tensor(5481059.)<br>7 tensor(3352937.5000)<br>8 tensor(2212013.7500)<br>9 tensor(1584447.7500)<br>10 tensor(1214588.1250)<br>11 tensor(975241.6250)<br>12 tensor(806804.3750)<br>13 tensor(680432.1875)<br>14 tensor(580979.7500)<br>15 tensor(500418.2188)<br>16 tensor(433949.5000)<br>17 tensor(378533.2500)<br>18 tensor(331744.8125)<br>19 tensor(292014.9375)<br>20 tensor(258002.2969)<br>21 tensor(228759.7031)<br>22 tensor(203502.3438)<br>23 tensor(181617.4062)<br>24 tensor(162530.6094)<br>25 tensor(145835.1406)<br>26 tensor(131164.5469)<br>27 tensor(118248.6328)<br>28 tensor(106880.9688)<br>29 tensor(96805.8125)<br>30 tensor(87843.5078)<br>31 tensor(79855.7891)<br>32 tensor(72728.5000)<br>33 tensor(66353.7422)<br>34 tensor(60627.9375)<br>35 tensor(55480.1055)<br>36 tensor(50842.4727)<br>37 tensor(46652.8438)<br>38 tensor(42859.6172)<br>39 tensor(39420.3984)<br>40 tensor(36297.3594)<br>41 tensor(33456.6836)<br>42 tensor(30868.9805)<br>43 tensor(28508.7754)<br>44 tensor(26352.9551)<br>45 tensor(24381.9219)<br>46 tensor(22576.9590)<br>47 tensor(20924.1289)<br>48 tensor(19406.6504)<br>49 tensor(18014.0859)<br>50 tensor(16734.3945)<br>51 tensor(15556.9463)<br>52 tensor(14473.6260)<br>53 tensor(13474.7432)<br>54 tensor(12552.1865)<br>55 tensor(11700.5293)<br>56 tensor(10912.8838)<br>57 tensor(10183.5830)<br>58 tensor(9508.0732)<br>59 tensor(8882.0479)<br>60 tensor(8301.2988)<br>61 tensor(7762.2920)<br>62 tensor(7261.7388)<br>63 tensor(6796.4380)<br>64 tensor(6363.9053)<br>65 tensor(5961.3506)<br>66 tensor(5586.3672)<br>67 tensor(5237.0176)<br>68 tensor(4911.4233)<br>69 tensor(4607.7842)<br>70 tensor(4324.3721)<br>71 tensor(4059.8486)<br>72 tensor(3812.7903)<br>73 tensor(3581.8992)<br>74 tensor(3366.1370)<br>75 tensor(3164.2825)<br>76 tensor(2975.8660)<br>77 tensor(2799.4905)<br>78 tensor(2634.3201)<br>79 tensor(2479.5688)<br>80 tensor(2334.5366)<br>81 tensor(2198.5542)<br>82 tensor(2070.9956)<br>83 tensor(1951.3154)<br>84 tensor(1838.9900)<br>85 tensor(1733.5266)<br>86 tensor(1634.4674)<br>87 tensor(1541.3926)<br>88 tensor(1453.9283)<br>89 tensor(1371.7056)<br>90 tensor(1294.3995)<br>91 tensor(1221.7031)<br>92 tensor(1153.3300)<br>93 tensor(1088.9634)<br>94 tensor(1028.3733)<br>95 tensor(971.3359)<br>96 tensor(917.6345)<br>97 tensor(867.0400)<br>98 tensor(819.3739)<br>99 tensor(774.4464)<br>100 tensor(732.1039)<br>101 tensor(692.1805)<br>102 tensor(654.5535)<br>103 tensor(619.0535)<br>104 tensor(585.5612)<br>105 tensor(553.9610)<br>106 tensor(524.1429)<br>107 tensor(495.9940)<br>108 tensor(469.4165)<br>109 tensor(444.3282)<br>110 tensor(420.6277)<br>111 tensor(398.2485)<br>112 tensor(377.1102)<br>113 tensor(357.1321)<br>114 tensor(338.2508)<br>115 tensor(320.4093)<br>116 tensor(303.5409)<br>117 tensor(287.5944)<br>118 tensor(272.5143)<br>119 tensor(258.2510)<br>120 tensor(244.7672)<br>121 tensor(232.0098)<br>122 tensor(219.9384)<br>123 tensor(208.5144)<br>124 tensor(197.7036)<br>125 tensor(187.4775)<br>126 tensor(177.7916)<br>127 tensor(168.6223)<br>128 tensor(159.9440)<br>129 tensor(151.7250)<br>130 tensor(143.9390)<br>131 tensor(136.5644)<br>132 tensor(129.5799)<br>133 tensor(122.9632)<br>134 tensor(116.6942)<br>135 tensor(110.7556)<br>136 tensor(105.1254)<br>137 tensor(99.7922)<br>138 tensor(94.7351)<br>139 tensor(89.9417)<br>140 tensor(85.3960)<br>141 tensor(81.0888)<br>142 tensor(77.0021)<br>143 tensor(73.1286)<br>144 tensor(69.4550)<br>145 tensor(65.9725)<br>146 tensor(62.6662)<br>147 tensor(59.5297)<br>148 tensor(56.5552)<br>149 tensor(53.7328)<br>150 tensor(51.0556)<br>151 tensor(48.5134)<br>152 tensor(46.1019)<br>153 tensor(43.8134)<br>154 tensor(41.6410)<br>155 tensor(39.5785)<br>156 tensor(37.6204)<br>157 tensor(35.7611)<br>158 tensor(33.9956)<br>159 tensor(32.3195)<br>160 tensor(30.7282)<br>161 tensor(29.2167)<br>162 tensor(27.7806)<br>163 tensor(26.4171)<br>164 tensor(25.1230)<br>165 tensor(23.8926)<br>166 tensor(22.7236)<br>167 tensor(21.6127)<br>168 tensor(20.5574)<br>169 tensor(19.5545)<br>170 tensor(18.6020)<br>171 tensor(17.6969)<br>172 tensor(16.8359)<br>173 tensor(16.0185)<br>174 tensor(15.2415)<br>175 tensor(14.5024)<br>176 tensor(13.8001)<br>177 tensor(13.1326)<br>178 tensor(12.4976)<br>179 tensor(11.8940)<br>180 tensor(11.3202)<br>181 tensor(10.7745)<br>182 tensor(10.2554)<br>183 tensor(9.7622)<br>184 tensor(9.2926)<br>185 tensor(8.8464)<br>186 tensor(8.4218)<br>187 tensor(8.0179)<br>188 tensor(7.6338)<br>189 tensor(7.2685)<br>190 tensor(6.9206)<br>191 tensor(6.5901)<br>192 tensor(6.2753)<br>193 tensor(5.9762)<br>194 tensor(5.6914)<br>195 tensor(5.4201)<br>196 tensor(5.1624)<br>197 tensor(4.9167)<br>198 tensor(4.6833)<br>199 tensor(4.4609)<br>200 tensor(4.2493)<br>201 tensor(4.0482)<br>202 tensor(3.8562)<br>203 tensor(3.6738)<br>204 tensor(3.5002)<br>205 tensor(3.3344)<br>206 tensor(3.1773)<br>207 tensor(3.0273)<br>208 tensor(2.8845)<br>209 tensor(2.7487)<br>210 tensor(2.6194)<br>211 tensor(2.4963)<br>212 tensor(2.3788)<br>213 tensor(2.2671)<br>214 tensor(2.1607)<br>215 tensor(2.0594)<br>216 tensor(1.9629)<br>217 tensor(1.8709)<br>218 tensor(1.7832)<br>219 tensor(1.6998)<br>220 tensor(1.6205)<br>221 tensor(1.5449)<br>222 tensor(1.4727)<br>223 tensor(1.4040)<br>224 tensor(1.3386)<br>225 tensor(1.2762)<br>226 tensor(1.2168)<br>227 tensor(1.1603)<br>228 tensor(1.1063)<br>229 tensor(1.0549)<br>230 tensor(1.0058)<br>231 tensor(0.9592)<br>232 tensor(0.9148)<br>233 tensor(0.8725)<br>234 tensor(0.8320)<br>235 tensor(0.7934)<br>236 tensor(0.7568)<br>237 tensor(0.7219)<br>238 tensor(0.6885)<br>239 tensor(0.6568)<br>240 tensor(0.6264)<br>241 tensor(0.5976)<br>242 tensor(0.5700)<br>243 tensor(0.5438)<br>244 tensor(0.5188)<br>245 tensor(0.4949)<br>246 tensor(0.4722)<br>247 tensor(0.4504)<br>248 tensor(0.4298)<br>249 tensor(0.4101)<br>250 tensor(0.3913)<br>251 tensor(0.3734)<br>252 tensor(0.3562)<br>253 tensor(0.3400)<br>254 tensor(0.3244)<br>255 tensor(0.3096)<br>256 tensor(0.2955)<br>257 tensor(0.2820)<br>258 tensor(0.2691)<br>259 tensor(0.2568)<br>260 tensor(0.2452)<br>261 tensor(0.2340)<br>262 tensor(0.2234)<br>263 tensor(0.2132)<br>264 tensor(0.2035)<br>265 tensor(0.1943)<br>266 tensor(0.1855)<br>267 tensor(0.1771)<br>268 tensor(0.1690)<br>269 tensor(0.1614)<br>270 tensor(0.1541)<br>271 tensor(0.1471)<br>272 tensor(0.1404)<br>273 tensor(0.1341)<br>274 tensor(0.1280)<br>275 tensor(0.1222)<br>276 tensor(0.1167)<br>277 tensor(0.1115)<br>278 tensor(0.1064)<br>279 tensor(0.1016)<br>280 tensor(0.0971)<br>281 tensor(0.0927)<br>282 tensor(0.0886)<br>283 tensor(0.0846)<br>284 tensor(0.0808)<br>285 tensor(0.0772)<br>286 tensor(0.0737)<br>287 tensor(0.0704)<br>288 tensor(0.0673)<br>289 tensor(0.0642)<br>290 tensor(0.0614)<br>291 tensor(0.0586)<br>292 tensor(0.0560)<br>293 tensor(0.0535)<br>294 tensor(0.0511)<br>295 tensor(0.0488)<br>296 tensor(0.0467)<br>297 tensor(0.0446)<br>298 tensor(0.0426)<br>299 tensor(0.0407)<br>300 tensor(0.0389)<br>301 tensor(0.0372)<br>302 tensor(0.0355)<br>303 tensor(0.0340)<br>304 tensor(0.0325)<br>305 tensor(0.0310)<br>306 tensor(0.0297)<br>307 tensor(0.0284)<br>308 tensor(0.0271)<br>309 tensor(0.0259)<br>310 tensor(0.0248)<br>311 tensor(0.0237)<br>312 tensor(0.0226)<br>313 tensor(0.0217)<br>314 tensor(0.0207)<br>315 tensor(0.0198)<br>316 tensor(0.0189)<br>317 tensor(0.0181)<br>318 tensor(0.0173)<br>319 tensor(0.0166)<br>320 tensor(0.0158)<br>321 tensor(0.0152)<br>322 tensor(0.0145)<br>323 tensor(0.0139)<br>324 tensor(0.0133)<br>325 tensor(0.0127)<br>326 tensor(0.0122)<br>327 tensor(0.0116)<br>328 tensor(0.0111)<br>329 tensor(0.0107)<br>330 tensor(0.0102)<br>331 tensor(0.0098)<br>332 tensor(0.0094)<br>333 tensor(0.0090)<br>334 tensor(0.0086)<br>335 tensor(0.0082)<br>336 tensor(0.0079)<br>337 tensor(0.0075)<br>338 tensor(0.0072)<br>339 tensor(0.0069)<br>340 tensor(0.0066)<br>341 tensor(0.0064)<br>342 tensor(0.0061)<br>343 tensor(0.0059)<br>344 tensor(0.0056)<br>345 tensor(0.0054)<br>346 tensor(0.0052)<br>347 tensor(0.0050)<br>348 tensor(0.0048)<br>349 tensor(0.0046)<br>350 tensor(0.0044)<br>351 tensor(0.0042)<br>352 tensor(0.0040)<br>353 tensor(0.0039)<br>354 tensor(0.0037)<br>355 tensor(0.0036)<br>356 tensor(0.0034)<br>357 tensor(0.0033)<br>358 tensor(0.0032)<br>359 tensor(0.0031)<br>360 tensor(0.0029)<br>361 tensor(0.0028)<br>362 tensor(0.0027)<br>363 tensor(0.0026)<br>364 tensor(0.0025)<br>365 tensor(0.0024)<br>366 tensor(0.0023)<br>367 tensor(0.0022)<br>368 tensor(0.0022)<br>369 tensor(0.0021)<br>370 tensor(0.0020)<br>371 tensor(0.0019)<br>372 tensor(0.0019)<br>373 tensor(0.0018)<br>374 tensor(0.0017)<br>375 tensor(0.0017)<br>376 tensor(0.0016)<br>377 tensor(0.0016)<br>378 tensor(0.0015)<br>379 tensor(0.0015)<br>380 tensor(0.0014)<br>381 tensor(0.0014)<br>382 tensor(0.0013)<br>383 tensor(0.0013)<br>384 tensor(0.0012)<br>385 tensor(0.0012)<br>386 tensor(0.0011)<br>387 tensor(0.0011)<br>388 tensor(0.0011)<br>389 tensor(0.0010)<br>390 tensor(0.0010)<br>391 tensor(0.0010)<br>392 tensor(0.0009)<br>393 tensor(0.0009)<br>394 tensor(0.0009)<br>395 tensor(0.0009)<br>396 tensor(0.0008)<br>397 tensor(0.0008)<br>398 tensor(0.0008)<br>399 tensor(0.0008)<br>400 tensor(0.0007)<br>401 tensor(0.0007)<br>402 tensor(0.0007)<br>403 tensor(0.0007)<br>404 tensor(0.0006)<br>405 tensor(0.0006)<br>406 tensor(0.0006)<br>407 tensor(0.0006)<br>408 tensor(0.0006)<br>409 tensor(0.0006)<br>410 tensor(0.0005)<br>411 tensor(0.0005)<br>412 tensor(0.0005)<br>413 tensor(0.0005)<br>414 tensor(0.0005)<br>415 tensor(0.0005)<br>416 tensor(0.0005)<br>417 tensor(0.0004)<br>418 tensor(0.0004)<br>419 tensor(0.0004)<br>420 tensor(0.0004)<br>421 tensor(0.0004)<br>422 tensor(0.0004)<br>423 tensor(0.0004)<br>424 tensor(0.0004)<br>425 tensor(0.0004)<br>426 tensor(0.0004)<br>427 tensor(0.0003)<br>428 tensor(0.0003)<br>429 tensor(0.0003)<br>430 tensor(0.0003)<br>431 tensor(0.0003)<br>432 tensor(0.0003)<br>433 tensor(0.0003)<br>434 tensor(0.0003)<br>435 tensor(0.0003)<br>436 tensor(0.0003)<br>437 tensor(0.0003)<br>438 tensor(0.0003)<br>439 tensor(0.0003)<br>440 tensor(0.0003)<br>441 tensor(0.0002)<br>442 tensor(0.0002)<br>443 tensor(0.0002)<br>444 tensor(0.0002)<br>445 tensor(0.0002)<br>446 tensor(0.0002)<br>447 tensor(0.0002)<br>448 tensor(0.0002)<br>449 tensor(0.0002)<br>450 tensor(0.0002)<br>451 tensor(0.0002)<br>452 tensor(0.0002)<br>453 tensor(0.0002)<br>454 tensor(0.0002)<br>455 tensor(0.0002)<br>456 tensor(0.0002)<br>457 tensor(0.0002)<br>458 tensor(0.0002)<br>459 tensor(0.0002)<br>460 tensor(0.0002)<br>461 tensor(0.0002)<br>462 tensor(0.0002)<br>463 tensor(0.0002)<br>464 tensor(0.0001)<br>465 tensor(0.0001)<br>466 tensor(0.0001)<br>467 tensor(0.0001)<br>468 tensor(0.0001)<br>469 tensor(0.0001)<br>470 tensor(0.0001)<br>471 tensor(0.0001)<br>472 tensor(0.0001)<br>473 tensor(0.0001)<br>474 tensor(0.0001)<br>475 tensor(0.0001)<br>476 tensor(0.0001)<br>477 tensor(0.0001)<br>478 tensor(0.0001)<br>479 tensor(0.0001)<br>480 tensor(0.0001)<br>481 tensor(0.0001)<br>482 tensor(0.0001)<br>483 tensor(0.0001)<br>484 tensor(0.0001)<br>485 tensor(0.0001)<br>486 tensor(9.8671e-05)<br>487 tensor(9.6656e-05)<br>488 tensor(9.4918e-05)<br>489 tensor(9.3419e-05)<br>490 tensor(9.1719e-05)<br>491 tensor(9.0300e-05)<br>492 tensor(8.8702e-05)<br>493 tensor(8.7077e-05)<br>494 tensor(8.5830e-05)<br>495 tensor(8.4661e-05)<br>496 tensor(8.3026e-05)<br>497 tensor(8.1507e-05)<br>498 tensor(8.0135e-05)<br>499 tensor(7.8957e-05)<br></code></p><p>Reference<br><a href="https://github.com/llSourcell/pytorch_in_5_minutes" target="_blank" rel="noopener">https://github.com/llSourcell/pytorch_in_5_minutes</a></p>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;
import torch
from torch.autograd import Variable

dtype = torch.FloatTensor
N, D_in, H, D_out = 64, 1000, 100, 10 
# one input layer, one hidden layer, and one output layer
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="pytorch" scheme="http://conxz.net/tags/pytorch/"/>
    
      <category term="machine learning" scheme="http://conxz.net/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Presentation Learning Day 2</title>
    <link href="http://conxz.net/2020/01/08/presentation-learning-day-2/"/>
    <id>http://conxz.net/2020/01/08/presentation-learning-day-2/</id>
    <published>2020-01-07T23:19:51.000Z</published>
    <updated>2020-01-13T23:37:29.367Z</updated>
    
    <content type="html"><![CDATA[<p>hello and welcome to xxx<br>I am just going to briefly touch upon what this xx will be about. and also I want to mention that xxx<br>so what is this xx, what isn’t this xx<br>I have presented some of these talks to the labs that I work in locally. and there were definitely folks in the audience who did not have xx experience.<br>I think they still got something out of it. they built their understanding.<br>so it is still useful if you’re completely new. but it’s going to be more useful for those of you who’ve been running xxx.<br><a id="more"></a><br>but either way, I will give you a shot and see what you get out of it.<br>I’m not going to start from like the basics in xx textbook necessarily. I am focusing on sort of these aha moments I’ve had along the way as I’ve been working with xx, and trying to figure things out.<br>That’s the stuff I want to share with you because it’s not obvious.<br>so the first thing I want to talk about will be xx<br>if you haven’t heard about it, don’t worry about it. I will explain what it is.<br>if you have, I just want to explain what it is, and why it’s good.<br>then the next section ..<br>I will ask you in the audience for some examples that you might want to share.<br>and at last, I hope to cover .xxx<br>but it turns out that this is  a pretty tricky topic in xxx<br>I’m hoping to walk me a way through that and digest it.<br>so that’s it. it’s really all I have to say.<br>my voice is a little hoarse because I have a cold. but hopefully that will clear up as xx goes.<br>anyway, so let’s get started. </p><p>I’m gonna start with a quick xx review.<br>primer motivation here is just to set up some notation which I can use to build upon for xx.<br>so other than that , the goal of this is just quickly review xx<br>But I am not going to getting into the nitty-gritty.<br>and the most important things I want to take ways from this are xx<br>I will do my best to keep equations at a minimum, but I really do need just a couple to get through this.<br>I will go over them many many time. hopefully the repetition will help.<br>hopefully that will help pull together the entire picture.<br>and quickly I’m getting over a cold so I apologize for my voice. but doing my best hopefully I won’t cough at all.<br>that’s it.<br>the best place for questions about xx is the Facebook group ..<br>I do try to address questions<br>so thanks a lot for your time and have a nice day. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;hello and welcome to xxx&lt;br&gt;I am just going to briefly touch upon what this xx will be about. and also I want to mention that xxx&lt;br&gt;so what is this xx, what isn’t this xx&lt;br&gt;I have presented some of these talks to the labs that I work in locally. and there were definitely folks in the audience who did not have xx experience.&lt;br&gt;I think they still got something out of it. they built their understanding.&lt;br&gt;so it is still useful if you’re completely new. but it’s going to be more useful for those of you who’ve been running xxx.&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="conference" scheme="http://conxz.net/tags/conference/"/>
    
      <category term="presentation" scheme="http://conxz.net/tags/presentation/"/>
    
      <category term="learning" scheme="http://conxz.net/tags/learning/"/>
    
  </entry>
  
  <entry>
    <title>Presentation Learning Day 1</title>
    <link href="http://conxz.net/2020/01/07/presentation-learning-day-1/"/>
    <id>http://conxz.net/2020/01/07/presentation-learning-day-1/</id>
    <published>2020-01-06T23:23:46.000Z</published>
    <updated>2020-01-13T23:37:44.151Z</updated>
    
    <content type="html"><![CDATA[<p>My final words is xxx<br>The future is very exciting. It takes all excitement and passion to explore the future.<br>I wish the future forum great success.<br>… beyond what we can see, what we can feel. </p><p>And this is the talk he’s going to give. And I would like to invite you to welcome xxx. </p><p>Thanks xx for that very nice and warm introduction.<br>Actually I feel quite insecure standing here facing the audience because this is probably the first time I am giving a scientific talk in four months.<br>This is unusual you know for a scientist.<br>I think this might be the first time in my life to give such a talk after this long period of silence in science or in presentation.<br>I am hoping by spending next ten years in science I can do something that I truelly will feel proud of my life in science.<br>So for the next 40 mins or so I’m going to tell a story that began to unfold xx<br>As shown here in this slide, is a diagram I took from the PNAS paper published from xxx.<br>we all know the central dogma or information flow in living or living organisms on earth very well.<br>it flows from genetic materials DNA to RNA then eventually to life executing proteins.<br>DNA –Transcription—&gt; RNA –Translation—&gt; Protein</p><p><dna replication=""><br>For transcription and translation, both processes are quite ordered. you can even call it one dimensional search.<br>that’s of course not one-dimensional per se. But you can imagine that is the case.<br>because in the first step transcription what you need is to have genomic DNA transcribed to pre-mRNA in a one-to-one relationship. One DNA base to one RNA base.<br>that is executed by RNA polymerase.<br>In the third step, protein translation what you need to do is for every three bases of mRNA, triplet codon, you have one amino acid specified. So again it is in a way one-dimensional information flow. three to one.<br>so before I describe xx, I’d like to call your attention to the xxx.<br>So I know I’m spending a lot of time on introduction. but I think the value of my talk is really embedded in introduction.<br>as you will see structure in the ends explains just my introduction.<br>So the next slide, this slide, describes essentially all that I want to tell this audience. so bear with me for a couple of minutes.<br>the upper left corner describes again xxx</dna></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;My final words is xxx&lt;br&gt;The future is very exciting. It takes all excitement and passion to explore the future.&lt;br&gt;I wish the future for
      
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="conference" scheme="http://conxz.net/tags/conference/"/>
    
      <category term="presentation" scheme="http://conxz.net/tags/presentation/"/>
    
      <category term="learning" scheme="http://conxz.net/tags/learning/"/>
    
  </entry>
  
  <entry>
    <title>命令行后台执行</title>
    <link href="http://conxz.net/2020/01/06/execute-cmdline-in-the-backgroud/"/>
    <id>http://conxz.net/2020/01/06/execute-cmdline-in-the-backgroud/</id>
    <published>2020-01-06T21:51:43.000Z</published>
    <updated>2020-01-06T22:01:33.189Z</updated>
    
    <content type="html"><![CDATA[<p>关键词：nohup 后台执行<br>Keywords: nohup background excute stop</p><p>常用的脑影像数据分析和遗传数据分析工具往往采用命令行的方式，用户通过Terminal执行命令行以完成相关数据分析，这种方式可以满足通常情况的需求。在一些特别的情况下，你可能会需要将命令行提交到后台执行，以避免一些意外的情况：</p><ol><li>通常情况下，Terminal和执行的命令是绑定的，即如果在执行程序过程中意外关闭的执行该程序的Terminal，改程序的执行会一起终止。</li><li>通过Terminal访问服务器，在服务器上执行程序时，如果意外出现网络中断，相应的程序也会因此而终止。<a id="more"></a></li></ol><p>Linux中的nohup命令提供了一个很好的解决方案，即将程序提交到后台执行，即使出现上述意外，程序依旧会照常执行。比如这里要执行一个Python程序，通常的方式是采用下面的命令行<br><code>python s1.extract_ts.py</code><br>如果采用这种方式提交，Terminal关闭后，程序执行会被终止。</p><p>通过下面的方式可以采用nohup提交程序到后台执行：<br><code>nohup python s1.extract_ts.py &amp;</code><br>这样执行该命令行后，即便关闭Terminal或远程访问服务器的网络中断，程序执行会照常继续。<br>也可以通过下面的命令将该程序执行过程中的output保存到一个文本文件中<br><code>nohup python s1.extract_ts.py &gt; nohup.log &amp;</code><br>这样，程序执行过程中的output会保存到这个log文件中；而且这个保存是实时的，因此可以通过查看该log文件的内容确定程序运行的到那个阶段，或是否有报错。</p><p>在一些情况下，你可能会发现通过nohup提交的程序可能有问题，需要停掉该程序。可以通过下面的命令，首先查看相应程序的PID，然后将其杀掉。<br><code>ps -ef | grep &quot;s1.extract_ts.py&quot;</code><br><code>kill &lt;PID&gt;</code></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关键词：nohup 后台执行&lt;br&gt;Keywords: nohup background excute stop&lt;/p&gt;
&lt;p&gt;常用的脑影像数据分析和遗传数据分析工具往往采用命令行的方式，用户通过Terminal执行命令行以完成相关数据分析，这种方式可以满足通常情况的需求。在一些特别的情况下，你可能会需要将命令行提交到后台执行，以避免一些意外的情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通常情况下，Terminal和执行的命令是绑定的，即如果在执行程序过程中意外关闭的执行该程序的Terminal，改程序的执行会一起终止。&lt;/li&gt;
&lt;li&gt;通过Terminal访问服务器，在服务器上执行程序时，如果意外出现网络中断，相应的程序也会因此而终止。
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="linux" scheme="http://conxz.net/tags/linux/"/>
    
      <category term="nohup" scheme="http://conxz.net/tags/nohup/"/>
    
  </entry>
  
  <entry>
    <title>十年</title>
    <link href="http://conxz.net/2020/01/02/2010s/"/>
    <id>http://conxz.net/2020/01/02/2010s/</id>
    <published>2020-01-02T19:34:25.000Z</published>
    <updated>2020-01-02T21:05:20.097Z</updated>
    
    <content type="html"><![CDATA[<p>十年，总不免让人觉得有些特别；2010年代匆匆过去，也不免引发一些思考。</p><p>2010年，我开始攻读博士学位。9月份是正式入学的时间，然而那时我已经进实验室参与研究项目近一年。由于是非心理学科班出身，对我而言，很多事情都是从零开始，更多的时候是给实验室师兄师姐打下手，比如：看被试、做被试。不过通过这些参与和平时的组会（实验室的组会真是一个重要的学习渠道），潜移默化中还是对心理学和认知神经科学的专业名词、实验设计、数据采集、常用统计分析有了一些理解。我更多的兴趣在脑影像数据分析，期初的梦想是基于多元统计和机器学习手段实现《阿凡达》中的类似人机交互（当时还是太年轻）。实验室Z老师带我们学习脑成像原理学习、多元统计、计算神经科学和脑影像分析方法，在这个过程中获得了很多的训练，给以后的工作打下了必要的基础。就这样慢慢对认知神经科学的研究问题和手段有了越来越清晰的认识。2016年顺利获得博士学位，博士学位论文被评为“北京师范大学优秀博士学位论文”，为博士学习阶段画上一个完美的句号。</p><p>2016年毕业后便开始了在荷兰Nijmegen马普所的研究工作，时间飞快，现在已3年有余。非常感激能有机会加入到现在的实验室，可以接触到更大的数据集和更多的合作者，并开展了一系列脑影像遗传学和多中心合作的研究。希望在接下来不到一年的时间里，可以顺利完成手上的项目。</p><p>从2010年开始到现在，在脑影像研究领域已经从业十年。有一种说法是，<em>要在任何领域成为大师，一般需要约10年的艰苦努力</em>。十年过去，深知离“大师”的距离还很遥远，脚下的路还很长。新年伊始，想想新的十年的必然和未知，希望一切顺利！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;十年，总不免让人觉得有些特别；2010年代匆匆过去，也不免引发一些思考。&lt;/p&gt;
&lt;p&gt;2010年，我开始攻读博士学位。9月份是正式入学的时间，然而那时我已经进实验室参与研究项目近一年。由于是非心理学科班出身，对我而言，很多事情都是从零开始，更多的时候是给实验室师兄师姐打下
      
    
    </summary>
    
      <category term="Xs" scheme="http://conxz.net/categories/Xs/"/>
    
    
      <category term="life" scheme="http://conxz.net/tags/life/"/>
    
      <category term="2010s" scheme="http://conxz.net/tags/2010s/"/>
    
  </entry>
  
  <entry>
    <title>Google AdSense多账号问题解决方案</title>
    <link href="http://conxz.net/2019/12/26/fix-multple-google-adsense-account-issues/"/>
    <id>http://conxz.net/2019/12/26/fix-multple-google-adsense-account-issues/</id>
    <published>2019-12-26T17:37:46.000Z</published>
    <updated>2019-12-26T18:46:32.088Z</updated>
    
    <content type="html"><![CDATA[<p>原则上Google限制同一个用户仅可拥有一个AdSense账号。如果在以往尝试使用不同的gmail邮箱多次注册Google AdSense账号，通常会碰到多账号问题，即类似<code>You have an adsense that already exists</code>的问题。Google官方给的解决方案是登录AdSense账号后，选择取消相应的账号。但是，如果用户多次申请的账号都未通过审核，用户是不可能通过登录相应的AdSense账号来完成相关账号的取消的。于是，便陷入了一个死循环的状态：由于多账号问题无法通过审核&lt;—&gt;由于未通过审核无法取消申请账号。</p><p>经过一些周折，找到一个间接的解决方案，这里记录备查。<a id="more"></a></p><p>解决方案的基本逻辑是，开通Google AdSense必须在Google账号（比如gmail）中绑定支付方式；如果直接删除支付方式，便可以连带Google AdSense账户一起删除。具体而言，</p><ul><li>登录Google账号，进入My Account界面</li><li>选择支付和订阅Payments &amp; subscriptions，在支付方法Payment methods中进入支付方式管理Manage payment methods</li><li>在页面左侧选择设置Settings，之后就可以在页面最下方看到关闭支付信息Close payment profile链接</li><li>点击后，根据提示填写相关信息，即可。</li><li>在操作成功后，gmail邮箱会受到两个支付信息关闭的邮件，其中一个便是提示Google AdSense取消成功。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原则上Google限制同一个用户仅可拥有一个AdSense账号。如果在以往尝试使用不同的gmail邮箱多次注册Google AdSense账号，通常会碰到多账号问题，即类似&lt;code&gt;You have an adsense that already exists&lt;/code&gt;的问题。Google官方给的解决方案是登录AdSense账号后，选择取消相应的账号。但是，如果用户多次申请的账号都未通过审核，用户是不可能通过登录相应的AdSense账号来完成相关账号的取消的。于是，便陷入了一个死循环的状态：由于多账号问题无法通过审核&amp;lt;—&amp;gt;由于未通过审核无法取消申请账号。&lt;/p&gt;
&lt;p&gt;经过一些周折，找到一个间接的解决方案，这里记录备查。
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="blog" scheme="http://conxz.net/tags/blog/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
  </entry>
  
  <entry>
    <title>添加Google AdSense到Hexo博客</title>
    <link href="http://conxz.net/2019/12/25/google-adsense-add-to-hexo/"/>
    <id>http://conxz.net/2019/12/25/google-adsense-add-to-hexo/</id>
    <published>2019-12-25T16:51:52.000Z</published>
    <updated>2019-12-28T20:50:20.762Z</updated>
    
    <content type="html"><![CDATA[<p>最近费了一些周折，终于解决了困扰已久的<code>You already have an existing AdSense account</code>问题。Google AdSense通过了审核。下面记录一下添加Google AdSense代码到基于Hexo博客的解决方案，一是备查，二是没准可以帮到新手。</p><p>Hexo博客，使用了maupassant模板。如果是别的模板，解决方案应该也可以参考。</p><a id="more"></a><p>首先在Hexo的_config.yml文件中添加下面一行(注意替换自己的AdSense ID)：<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">google_adsense:</span> ca-pub<span class="number">-7680017147908727</span></span><br></pre></td></tr></table></figure></p><p>进入manupassant模板目录themes/maupassant，在layout/_partial目录中可以看到一系列子模块文件。找到head.pug，添加下面的代码。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> config.google_adsense</span><br><span class="line">    script(<span class="attribute">data-ad-client</span>=config.google_adsense, async <span class="attribute">src</span>=<span class="string">'https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js'</span>)</span><br></pre></td></tr></table></figure></p><p>调试，完工。</p><hr><p>2019年12月28日更新手动指定位置添加广告模块内容。</p><p>以上为Google提供的Auto ads服务，即Google自动确定广告展示的位置和尺度，初步测试该自动方式仍然存在一定的局限性，通常会导致页面博客页面混乱。下面是更为常规的方案，即用户自己指定广告展示的位置和尺寸。</p><p>用户需要通过Google Adsense的By ad unit根据需求创建广告模块，获取代码。然后将代码添加到页面的相应位置。比如，如果想要在Hexo maupassant博客文章的末尾添加广告，便可以参考下面的代码将相关代码添加到layout/post.pug最后的位置（注意根据自己的代码修改相关信息）。添加到其他位置也可以参考下面的代码。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> theme.show_ad_unit_post == <span class="literal">true</span></span><br><span class="line">  script(async <span class="attribute">src</span>=<span class="string">'https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js'</span>)</span><br><span class="line">  ins.adsbygoogle(<span class="attribute">style</span>=<span class="string">'display:block'</span>, <span class="attribute">data-ad-client</span>=<span class="string">'ca-pub-7680017147908727'</span>, <span class="attribute">data-ad-slot</span>=<span class="string">'2051716958'</span>, <span class="attribute">data-ad-format</span>=<span class="string">'auto'</span>, <span class="attribute">data-full-width-responsive</span>=<span class="string">'true'</span>)</span><br><span class="line">  script.</span><br><span class="line">      (adsbygoogle = window.adsbygoogle || []).push(&#123;&#125;);</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近费了一些周折，终于解决了困扰已久的&lt;code&gt;You already have an existing AdSense account&lt;/code&gt;问题。Google AdSense通过了审核。下面记录一下添加Google AdSense代码到基于Hexo博客的解决方案，一是备查，二是没准可以帮到新手。&lt;/p&gt;
&lt;p&gt;Hexo博客，使用了maupassant模板。如果是别的模板，解决方案应该也可以参考。&lt;/p&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="blog" scheme="http://conxz.net/tags/blog/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="google adsense" scheme="http://conxz.net/tags/google-adsense/"/>
    
  </entry>
  
  <entry>
    <title>我的黑洞计划：刻画强迫症中的脑不对称性异常</title>
    <link href="http://conxz.net/2019/06/04/asymOCD/"/>
    <id>http://conxz.net/2019/06/04/asymOCD/</id>
    <published>2019-06-04T20:05:37.000Z</published>
    <updated>2020-01-31T22:40:47.510Z</updated>
    
    <content type="html"><![CDATA[<p>先放论文信息，方便查阅原文。<br>Kong, Xiang-Zhen, et al. “Mapping Cortical and Subcortical Asymmetry in Obsessive-Compulsive Disorder: Findings from the ENIGMA Consortium.” Biological Psychiatry. <a href="https://doi.org/10.1016/j.biopsych.2019.04.022" target="_blank" rel="noopener">DOI</a> | <a href="https://pure.mpg.de/rest/items/item_3053214_9/component/file_3053215/content" target="_blank" rel="noopener">全文链接</a></p><p>这是我完成的第二个ENIGMA项目，是偏侧化工作组和强迫症工作组的合作项目。这个项目涉及来自全球16个国家的46个数据集：16个儿童和青少年样本（501病例+439健康对照）和30个成人样本（1777病例+1654健康对照）。我们得到近140名研究者的贡献和支持，通过多中心合作研究，描绘了强迫症与脑结构偏侧化之间的初步关联。</p><p><img src="/images/post_images/asymocd.png" alt="脑结构不对称性与强迫症多中心合作"></p><p>下面是一个中文摘要。<br><a id="more"></a><br>强迫症通常会呈现出偏侧化的脑功能异常。但是，我们还不清楚脑结构不对称性是否在强迫症中呈现异常模式。该研究旨在基于多中心合作和大样本数据，刻画强迫症中的脑结构不对称性模式。具体而言，我们分析了来自ENIGMA强迫症工作组的16个儿童/青少年数据集（501病例、439健康对照）和30个成人数据集（1777病例、1654健康对照）。这些数据集包括皮下结构的体积、皮层脑区的厚度和面积等结构测量，这些参数由统一的图像分析和质量控制流程产生。我们考察了强迫症中可能的脑不对称性异常。同时，对疾病和用药状态与脑结构不对称性之间的关联多了探索。结果显示，在儿童/青少年组，强迫症呈现了丘脑（Thalamus）和苍白球（Pallidum）体积不对称性显著差异。进一步的分析显示，这些不对称性差异可能与强迫症的用药状态、严重程度、焦虑或抑郁并发症存在关联。在成人组没有发现显著差异。综上，数据显示，在儿童/青少年群体中，强迫症与皮下结构的不对称性异常存在一定的关联，而这些异常并未呈现在成人群体中。这些差异可能反映了强迫症的神经发育过程的异常。</p><p><img src="/images/post_images/asymocd2.png" alt="脑结构不对称性与强迫症"></p><p>多中心合作在该项目中扮演了重要的角色。在最近的另一篇文章中，笔者试着从多中心合作的视角，就多中心合作研究模式在开展可重复的心理与脑科学研究中的应用和发展，以及应用过程中需要注意的问题做了一点分享。希望国内心理与脑科学同行，尤其是年轻研究者加强多中心合作研究相关的方法学训练，以更开放的心态联合起来，开展稳健、可重复的心理与脑科学研究。</p><p>孔祥祯. “多中心合作和可重复的心理与脑科学研究.” 心理技术与应用 7.5 (2019): 297-304.  <a href="http://www.xljsyyy.com/CN/10.16842/j.cnki.issn2095-5588.2019.05.004" target="_blank" rel="noopener">http://www.xljsyyy.com/CN/10.16842/j.cnki.issn2095-5588.2019.05.004</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;先放论文信息，方便查阅原文。&lt;br&gt;Kong, Xiang-Zhen, et al. “Mapping Cortical and Subcortical Asymmetry in Obsessive-Compulsive Disorder: Findings from the ENIGMA Consortium.” Biological Psychiatry. &lt;a href=&quot;https://doi.org/10.1016/j.biopsych.2019.04.022&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DOI&lt;/a&gt; | &lt;a href=&quot;https://pure.mpg.de/rest/items/item_3053214_9/component/file_3053215/content&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;全文链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这是我完成的第二个ENIGMA项目，是偏侧化工作组和强迫症工作组的合作项目。这个项目涉及来自全球16个国家的46个数据集：16个儿童和青少年样本（501病例+439健康对照）和30个成人样本（1777病例+1654健康对照）。我们得到近140名研究者的贡献和支持，通过多中心合作研究，描绘了强迫症与脑结构偏侧化之间的初步关联。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/post_images/asymocd.png&quot; alt=&quot;脑结构不对称性与强迫症多中心合作&quot;&gt;&lt;/p&gt;
&lt;p&gt;下面是一个中文摘要。&lt;br&gt;
    
    </summary>
    
      <category term="BrainResearch" scheme="http://conxz.net/categories/BrainResearch/"/>
    
    
      <category term="brain asymmetry" scheme="http://conxz.net/tags/brain-asymmetry/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="collaborative team research" scheme="http://conxz.net/tags/collaborative-team-research/"/>
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>脑科学相关SCI Top期刊_2018</title>
    <link href="http://conxz.net/2019/01/13/scitop2018/"/>
    <id>http://conxz.net/2019/01/13/scitop2018/</id>
    <published>2019-01-13T19:40:11.000Z</published>
    <updated>2019-01-13T20:32:58.026Z</updated>
    
    <content type="html"><![CDATA[<p>近日，最新的中科院JCR期刊分区发布，其中关于期刊的分区和是否为Top与去年大致相同，不过还是发生了一些小的变化。比如，Nature Communications和PNAS被划分为2区期刊，其中Nature Communications不在作为Top期刊，PNAS作为2区Top期刊；Human Brain Mapping划分为2区非Top期刊。</p><p>下面是脑科学（神经科学、认知神经科学和神经影像）相关同行通常会提到的期刊的最新信息。</p><p><img src="/images/post_images/scitop.jpg" alt="SCI Top 期刊" title="SCI Top 期刊"><br><a id="more"></a></p><h3 id="期刊名称-影响因子-Top期刊-OA期刊"><a href="#期刊名称-影响因子-Top期刊-OA期刊" class="headerlink" title="期刊名称 影响因子 Top期刊 OA期刊"></a>期刊名称 影响因子 Top期刊 OA期刊</h3><p>Nature 41.577 1区Top 非OA<br>Science 41.058 1区Top 非OA</p><p>Nature Neuroscience 19.912 1区Top 非OA<br>Neuron 14.319 1区Top 非OA</p><p><em>Nature Communications 12.353 2区非TOP OA</em><br>PNAS 9.504 2区Top 非OA<br>Current Biology 9.251 1区Top 非OA<br>Brain 10.848 1区Top 非OA<br>PLOS Biology 9.163 1区Top OA</p><p>Cerebral Cortex 6.308 1区Top 非OA<br>eLife 7.616 1区Top OA<br>Journal of Neuroscience 5.971 2区Top 非OA</p><p>NeuroImage 5.426 2区Top 非OA<br><em>Human Brain Mapping 4.927 2区非Top 非OA</em><br>Brain Structure &amp; Function 4.231 2区Top 非OA<br>Cortex 4.907 2区Top 非OA</p><p>Nature Reviews Neuroscience 32.635 1区Top 非OA<br>Trends in Cognitive Science 15.557 1区Top 非OA<br>Behavioral and Brain Science 15.071 1区Top 非OA<br>Trends in Neurosciences 11.439 1区Top 非OA<br>Neuroscience &amp; Biobehavioral Reviews 8.037 1区Top 非OA<br>Neuroscientist 7.461 1区Top 非OA</p><p>JAMA Psychiatry 16.642 1区Top 非OA<br>Molecular Psychiatry 11.640 1区Top 非OA<br>Biological Psychiatry 11.984 1区Top 非OA<br>Lancet Psychiatry 15.233 1区Top 非OA<br>Molecular Neurodegeneration 6.426 1区Top OA<br>Neuropsychopharmacology 6.544 1区Top 非OA</p><p><em>National Science Review 9.408 2区非Top 非OA</em><br>Annual Review of Neuroscience 14.675 1区Top 非OA<br>Progress in Neurobiology 14.163 1区Top 非OA</p><p><em>Current Opinion in Neurobiology 6.541 2区非Top 非OA</em><br>Nature Genetics 27.125 1区Top 非OA<br>PLoS Genetics 5.540 2区Top OA<br>Neuropharmacology 4.249 2区Top 非OA</p><p>Annual Review of Psychology 22.774 1区Top 非OA<br>Psychological Bulletin 13.250 1区Top 非OA<br>Annual Review of Clinical Psychology 13.278 1区Top 非OA<br>Psychological Review 7.230 1区Top 非OA</p><p>Diabetes Care 13.397 1区Top 非OA<br>Stroke 6.239 2区Top 非OA<br>Pain 5.559 2区Top 非OA<br>Sleep Medicine Reviews 10.602 1区Top 非OA</p><p>此外，Psychological Science是很好的期刊，影响因子从去年的5.667提升到今年6.128，由于只属SSCI期刊，并不在中科院分区范围。</p><p>你可能对<a href="http://conxz.net/2017/11/08/scitop/">去年的期刊分区总结</a>和<a href="http://conxz.net/2018/07/06/journalsci2017/">另一篇相关的总结</a>感兴趣。</p><p>数据来源：<a href="http://www.letpub.com.cn/index.php?page=journalapp" target="_blank" rel="noopener">http://www.letpub.com.cn/index.php?page=journalapp</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近日，最新的中科院JCR期刊分区发布，其中关于期刊的分区和是否为Top与去年大致相同，不过还是发生了一些小的变化。比如，Nature Communications和PNAS被划分为2区期刊，其中Nature Communications不在作为Top期刊，PNAS作为2区Top期刊；Human Brain Mapping划分为2区非Top期刊。&lt;/p&gt;
&lt;p&gt;下面是脑科学（神经科学、认知神经科学和神经影像）相关同行通常会提到的期刊的最新信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/post_images/scitop.jpg&quot; alt=&quot;SCI Top 期刊&quot; title=&quot;SCI Top 期刊&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="publication" scheme="http://conxz.net/tags/publication/"/>
    
  </entry>
  
  <entry>
    <title>记第一个Shiny应用obsBrain</title>
    <link href="http://conxz.net/2018/12/27/obsBrainApp/"/>
    <id>http://conxz.net/2018/12/27/obsBrainApp/</id>
    <published>2018-12-27T20:05:11.000Z</published>
    <updated>2018-12-27T20:48:35.712Z</updated>
    
    <content type="html"><![CDATA[<p>Shiny是一项RStudio开发支持的交互式网页技术，基于此技术，可以用R语言相对轻松地实现交互式网页应用。由于其轻便、易学和交互式特点，该技术尤其适用于在学术发表的同时，交互式呈现数据科学分析结果，以方便读者更好地查看和理解研究方法和研究结果。<br>在以往自己的数据计算中，Python占了主导。不过从2016年下半年到现在的实验室之后，更多的时候采用R完成数据计算，深知其便捷性。期间对Shiny也有一些接触，不过属“点头之交”：大致晓得其基本功能，但没来得及深入学习。于是，趁着圣诞和新年假期，具体学了一下Shiny应用的实现，并结合目前的研究兴趣得到的第一个应用。<br><img src="/images/post_images/obsbrain.png" alt="obsBrain"><br><a id="more"></a><br>在这个应用中主要实现了一下几个功能：</p><ul><li>可视化人脑基因表达的空间分布</li><li>汇集和展示ENIGMA多中心合作项目在多个研究中的主要结果（并呈现其与基因表达的空间相关分析结果）</li><li>提供一个方便使用的可视化工具</li></ul><p>所有这些功能均基于FreeSurfer提供的Desikan–Killiany图谱（半脑分为34个脑区），这也是目前ENIGMA多中心合作项目使用最多的脑分割图谱。暂且将其命名为obsBrain，全称为Observatory of Brain。<br>该应用目前已发布到网络，可以通过如下链接访问:<br><a href="https://conxz.shinyapps.io/obsbrain/" target="_blank" rel="noopener">https://conxz.shinyapps.io/obsbrain/</a><br>此外，所有数据准备和具体应用实现相关代码和数据均已发布在GitHub，可以通过如下链接访问:<br><a href="https://github.com/Conxz/obsBrain" target="_blank" rel="noopener">https://github.com/Conxz/obsBrain</a></p><p>关于该应用的更多细节，可以参见README.md文件。同时欢迎感兴趣的同行联系交流（联系方式见README.md）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Shiny是一项RStudio开发支持的交互式网页技术，基于此技术，可以用R语言相对轻松地实现交互式网页应用。由于其轻便、易学和交互式特点，该技术尤其适用于在学术发表的同时，交互式呈现数据科学分析结果，以方便读者更好地查看和理解研究方法和研究结果。&lt;br&gt;在以往自己的数据计算中，Python占了主导。不过从2016年下半年到现在的实验室之后，更多的时候采用R完成数据计算，深知其便捷性。期间对Shiny也有一些接触，不过属“点头之交”：大致晓得其基本功能，但没来得及深入学习。于是，趁着圣诞和新年假期，具体学了一下Shiny应用的实现，并结合目前的研究兴趣得到的第一个应用。&lt;br&gt;&lt;img src=&quot;/images/post_images/obsbrain.png&quot; alt=&quot;obsBrain&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="R" scheme="http://conxz.net/tags/R/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="shiny app" scheme="http://conxz.net/tags/shiny-app/"/>
    
  </entry>
  
  <entry>
    <title>研究前沿论文先睹为快</title>
    <link href="http://conxz.net/2018/10/15/paper-preview/"/>
    <id>http://conxz.net/2018/10/15/paper-preview/</id>
    <published>2018-10-15T20:09:44.000Z</published>
    <updated>2018-11-01T22:20:37.422Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个“快”时代，科学研究也不例外。以心理和脑科学研究学术发表为例，在过去几年，越来越多的研究者选择将科研论文在正式发表之前，先以预印本Preprint的形式上传到Preprint平台上。采用这方式，科研成果往往可以提前1年，甚至更长时间让领域同行公开获取，一方面加快科研成果的流通交流，促进领域发展；同时，也有利于确立研究成果的首发权。目前被领域相对认可的Preprint平台（和中国的Preprint平台）见文后列表。</p><p>笔者注意到，一些期刊开始向读者提供一项免费的“先睹为快”服务，即在作者同意的情况下，将处在审稿中Under Review的论文提供给读者公开获取。<a id="more"></a></p><p>其中一个例子为Nature Communications。Nature Communications是开放获取期刊中的佼佼者，在开放获取期刊备受争议的今天，<a href="http://conxz.net/2018/07/06/journalsci2017/">该期刊以12分左右的影响因子，独树一帜，备受追捧</a>。不过，这一期刊的不足之处是版面费贵到爆，单篇搞到5000多美刀。目前，该期刊提供一个名为“Under Consideration”论文列表服务。读者可以通过这一列表，查看目前处于该期刊审稿状态的论文信息。值得注意的是，该期刊仅提供列表和基本信息，作者如果选择这一服务，需要首先将论文上传到领域公认的Preprint平台，以便读者下载全文。感兴趣的研究者可以通过这一服务对目前处在审稿状态的论文先睹为快。该列表链接为<a href="https://nature-research-under-consideration.nature.com/" target="_blank" rel="noopener">Nature Communications Under Consideration</a></p><p>此外，Cell系列的期刊也提供了类似的服务，并命名为Cell Press Sneak Peek，名字堪称生动形象。该服务通过Preprint平台SSRN提供，并涵盖了Cell系列耳熟能详的期刊，包括Neuron，Cell，Current Biology和Cell Report等。读者可以通过该服务提前获取目前处在审稿状态的论文信息。注意，是否选择将论文加入该列表，取决于作者的选择，因此，这一列表只是部分处在审稿状态的论文。该服务的链接为<a href="https://papers.ssrn.com/sol3/Jeljour_results.cfm?form_name=journalBrowse&amp;journal_id=3184889" target="_blank" rel="noopener">Cell Press Sneak Peek</a></p><p><a href="http://preprint.space/underreview" target="_blank" rel="noopener">Preprint.Space</a>也提供了一个列表，整合了包括Sneak Peek和其他一些期刊正在Under Review的论文，包括GigaScience和PeerJ等。</p><p><strong>心理与脑科学相关领域认可的Preprint平台</strong></p><ul><li><a href="https://arxiv.org/" target="_blank" rel="noopener">arXiv</a>, <a href="https://arxiv.org/" target="_blank" rel="noopener">https://arxiv.org/</a></li><li><a href="http://www.biorxiv.org/" target="_blank" rel="noopener">bioRxiv</a>, <a href="http://www.biorxiv.org/" target="_blank" rel="noopener">http://www.biorxiv.org/</a></li><li><a href="https://psyarxiv.com/" target="_blank" rel="noopener">PsyArXiv</a>, <a href="https://psyarxiv.com/" target="_blank" rel="noopener">https://psyarxiv.com/</a></li><li><a href="https://peerj.com/preprints-search/" target="_blank" rel="noopener">PeerJ Preprints</a>, <a href="https://peerj.com/preprints-search/" target="_blank" rel="noopener">https://peerj.com/preprints-search/</a></li><li><a href="https://osf.io/preprints" target="_blank" rel="noopener">OSF Preprints</a>, <a href="https://osf.io/preprints" target="_blank" rel="noopener">https://osf.io/preprints</a></li><li><a href="https://www.preprints.org/" target="_blank" rel="noopener">Preprints</a>, <a href="https://www.preprints.org/" target="_blank" rel="noopener">https://www.preprints.org/</a></li><li><a href="https://www.ssrn.com/en/" target="_blank" rel="noopener">SSRN</a>, <a href="https://www.ssrn.com/en/" target="_blank" rel="noopener">https://www.ssrn.com/en/</a></li></ul><p><strong>中国Preprint平台</strong></p><ul><li>中国科学院科技论文预发布平台 <a href="http://chinaxiv.org/" target="_blank" rel="noopener">ChinaXiv</a>, <a href="http://chinaxiv.org/" target="_blank" rel="noopener">http://chinaxiv.org/</a></li><li>中国心理学预印本平台 <a href="http://psych.chinaxiv.org/" target="_blank" rel="noopener">PsyChinaXiv</a>, <a href="http://psych.chinaxiv.org/" target="_blank" rel="noopener">http://psych.chinaxiv.org/</a></li><li>国家科技图书文献中心 <a href="http://prep.istic.ac.cn/" target="_blank" rel="noopener">中国预印本服务系统</a>, <a href="http://prep.istic.ac.cn/" target="_blank" rel="noopener">http://prep.istic.ac.cn/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一个“快”时代，科学研究也不例外。以心理和脑科学研究学术发表为例，在过去几年，越来越多的研究者选择将科研论文在正式发表之前，先以预印本Preprint的形式上传到Preprint平台上。采用这方式，科研成果往往可以提前1年，甚至更长时间让领域同行公开获取，一方面加快科研成果的流通交流，促进领域发展；同时，也有利于确立研究成果的首发权。目前被领域相对认可的Preprint平台（和中国的Preprint平台）见文后列表。&lt;/p&gt;
&lt;p&gt;笔者注意到，一些期刊开始向读者提供一项免费的“先睹为快”服务，即在作者同意的情况下，将处在审稿中Under Review的论文提供给读者公开获取。
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
      <category term="publication" scheme="http://conxz.net/tags/publication/"/>
    
      <category term="neuroscience" scheme="http://conxz.net/tags/neuroscience/"/>
    
  </entry>
  
  <entry>
    <title>脑科学期刊最新影响因子和中美差距</title>
    <link href="http://conxz.net/2018/07/06/journalsci2017/"/>
    <id>http://conxz.net/2018/07/06/journalsci2017/</id>
    <published>2018-07-06T21:18:59.000Z</published>
    <updated>2018-07-07T17:58:08.229Z</updated>
    
    <content type="html"><![CDATA[<p>近日，最新的学术期刊影响因子（基于2015-2017年3年的期刊文章引用数据）发布，虽然大家一再强调，要淡化影响因子在科研评估中的份量，但是<strong>每年影响因子的起伏就好像股票的跌涨，还是牵动着众多研究者的心</strong>。<br>新的影响因子系统还提供了引用贡献最多的文章排名、国家或地区排名，以及大学的排名，可以看到很多有意思的信息（比如，在科学研究方面，中国大陆发展迅猛，但中美差距还很大（巨大！）。一方面要加大科研投入，同时可能还要韬光养晦）。下面是一些脑科学相关（包括神经科学、认知神经科学和神经影像，以及一些综合期刊）期刊的最新影响因子信息。</p><ul><li><strong>Nature</strong>，最新影响因子41.577，略升。贡献最大的文章是LeCun和Hinton的文章Deep Learning，引用1336次。过去几年深度学习大火，算是意料之中。中国大陆（426）位居第4，在美国（3095）、英国和德国之后。贡献最多的大学机构有：加州大学系统、哈佛大学、霍华德休斯、MIT和斯坦福，德国马普所随其后，可见美国大学机构的优势。</li><li><strong>Science</strong>，最新影响因子41.058，增长明显。贡献最大的文章主要来自生命科学领域。文章来源和Nature类似，依次为美国（3252）、英国、德国和中国大陆（360）。前五的大学依旧是上述几所美国的大学机构。</li><li><strong>Nature Neuroscience</strong>，稳步提升，最新19.912，离20越来越近。贡献最大的文章除了single cell sequencing和transcritomics，一篇fMRI的文章名列前5：Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity。稿源方面，瑞士和法国超越中国大陆（50），进入前5。美国（563）依旧远超第二的英国（99）。</li><li><strong>Neuron</strong>，最新14.318，略升。引用前5关键词Parkinson’s Disease/Aging/Autism以及Coherence和Transcriptional Differences。国家排名为美国（1133）、德国（170）、英国、瑞士和法国，中国大陆（68）在加拿大和日本之后。稿源前5为加州大学系统、霍华德休斯、哈佛、斯坦福和伦敦大学，马普系统排第8。</li><li><strong>Nature Communications</strong>，Nature旗下的OA期刊，最新影响因子12.353。引用前5没有脑影像相关文章。稿源数量中国大陆排进前5，依次为美国（5721）、中国大陆（2058）、德国、英国和法国。中科院系统仅次于美国加州大学系统和法国科学研究院。</li><li><strong>PNAS</strong>，最新9.504。引用贡献最大的文章为那篇引起众多关注的Cluster Failure。稿源排名美国（7891）、英国、德国和中国大陆（1105）。</li><li><strong>Current Biology</strong>，最新9.251。稿源前5为美国（1231）、英国、德国、法国和澳大利亚，中国位居第十（98）。</li><li><strong>Brain</strong>，最新为10.840。文章关键词Alzheimer’s disease和Parkinson’s disease。美国（433）第一，中国大陆位居瑞士（63）之后，无缘前十。</li><li><strong>PLOS Biology</strong>，最新为9.163。关于reproducibility in preclinical research讨论的文章排进前5。国家或地区排名依次为美国（429）、英国、德国、法国和加拿大，中国大陆（42）排在第8。</li><li><strong>Cerebral Cortex</strong>，最新6.308，与8分俱乐部渐行渐远。brain parcellation是重要关键词，此外，前5文章中中国研究者占据两席，分别是来自中科院自动化所蒋田仔老师课题组的Brainnetome Atlas和北师大贺永老师课题组的Alzheimer’s disease和脑网络相关研究。国家或地区排名，美国（544）、德国、英国、加拿大和中国大陆（96）。</li><li><strong>eLife</strong>，最新7.616。生命科学的文章贡献最大。国家或地区排名，美国（2293）、英国、德国、法国和中国大陆（219）。</li><li><strong>Journal of Neuroscience</strong>，最新5.970。来自隔壁大学Radboud University Nijmegen的文章Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Ventral Stream排进前5。美国排名第一2170，中国第七188，差距明显。</li></ul><p>–脑影像期刊</p><ul><li><strong>NeuroImage</strong>，最新5.426。关键词head motion，前5中有3篇文章重点关注扫描中的head motion问题。稿源排名美国（1161）第一，中国（167）第七。</li><li><strong>Human Brain Mapping</strong>，最新4.927，有所回升。关键词Mild Cognitive Impairment/Parkinson’s disease/Major Depressive disorder，以及Parcellation。国家地区排名美国（501）、德国、中国大陆（158）、英国和加拿大。依旧没有中国大陆大学机构排进前10。</li><li><strong>Brain Structure &amp; Function</strong>，最新4.231。关键词social anxiety disorder/AD/MCI/social interaction。国家地区排名，美国（266）、德国、法国、英国、西班牙和中国大陆（55）。</li><li>Cortex，最新4.907，回升。美国（229）排名第一，中国大陆在苏格兰（42）之后，没有排进前十。</li></ul><p>–综述类</p><ul><li><strong>Nature Reviews Neuroscience</strong>，32.635。关键词Alzheimer’s disease/function and dysfunction/mindfulness meditation/brain disorders/fear and anxiety。国家地区排名，美国（122）、英国和德国，中国（6）列第九，不及意大利和西班牙。</li><li><strong>Trends in Cognitive Science</strong>，15.557。关键词working memory/decision model/statistical learning/memory/mental imagery。美国（197）第一，中国大陆(less than 11）未进前十。</li><li><strong>Behavioral and Brain Science</strong>，15.071。美国（407）第一，中国大陆（小于15）未进前十。</li><li><strong>Trends in Neurosciences</strong>，11.439。美国（147）第一，中国第9，位列西班牙（9）之后。</li><li><strong>Neuroscience &amp; Biobehavioral Reviews</strong>，8.037。美国（302）第一，中国大陆（52）第8，位居意大利之后。</li><li><strong>National Science Review</strong>，9.408。中国大陆（209）第一，其次为美国（68），澳大利亚、德国和英国。贡献最多的院校机构为中科院系统、北大、清华和中科大。</li><li>Annual Review of Neuroscience，14.675。Marcus Raichle牛的The Brain’s Default Mode Network荣登榜首。美国（54）第一，中国大陆（1）第九。</li><li>Progress in Neurobiology，最新14.162。美国（77）第一，中国大陆（17）第五。</li><li>Current Opinion in Neurobiology，最新6.541。美国（282）第一，中国大陆（小于11）未进前十。</li><li>Neuroscientist，7.461。美国（71）第一，中国大陆（10）第5，位居意大利之后。</li></ul><p>– 精神疾病期刊</p><ul><li><strong>JAMA Psychiatry</strong>，16.642。美国（512）第一，中国大陆（19）和西班牙、意大利并列第十。</li><li><strong>Molecular Psychiatry</strong>，11.640。两篇来自ENIGMA的paper位列前5。美国（394）第一，中国（45）第九。</li><li><strong>Biological Psychiatry</strong>，11.982。美国（2101）第一，中国大陆（66）第九。</li><li><strong>Lancet Psychiatry</strong>，最新15.233。美国（331）第一，中国大陆（less than 23）未进前十。</li><li>Molecular Neurodegeneration，6.426。前五为美国（125）、中国大陆（41）、英国/德国、西班牙。</li><li>Neuropsychopharmacology，6.544。关键词Stress/Anxiety/Depression/Social deficits/Autism。美国（2377）第一，中国大陆（40）第九。</li><li>PLoS Genetics，5.540。国家地区排名，美国（1244）、英国、德国、中国大陆（217）和法国。</li><li>Neuropharmacology，4.249。美国（545）第一，中国（150）第二。</li></ul><p>– 心理学相关</p><ul><li>Annual Review of Psychology，22.774。Olaf Sporns的Modualr Brain Networks位列第四。国家地区排名，美国（69）第一，中国大陆（1）第九。</li><li>Psychological Bulletin，13.250。美国（88）第一，中国大陆（小于4）未进前十。</li><li>Annual Review of Clinical Psychology，13.278。美国（51）第一，中国大陆（小于1）未进前十。</li><li>Psychological Review，7.230。美国（68）第一，中国大陆（小于4）未进前十。</li><li>Psychological Science，6.128。美国（385）第一，中国大陆（18）和苏格兰并列第八。</li></ul><p>– <strong>新晋期刊</strong></p><ul><li><strong>Science Advances 第一个影响因子 11.511。美国（904）第一，中国大陆（252）位居第二</strong>。</li></ul><p>– 其他期刊：</p><ul><li>Neuroscience Bulletin，3.155。中国（215）第一，美国（41）第二。</li><li>PeerJ，一个新的OA综合期刊。自2014年有影响因子以来，其影响因子一直维持在2.1+，5年影响因子有上升趋势，从最初的2.112升到今年的2.469。文章来源主要是USA（1,135），远超第二名的China Mainland（486）和第三的England（375）。</li><li>NeuroReport，一个有历史的神经科学期刊，影响因子一直不高，最新为1.266，投稿相对容易。稿源主要是China Mainland（261），其次是USA、Japan和South Koren。China Mainland大学中文章贡献最多的西安交通大学XI’AN JIAOTONG UNIVERSITY和重庆医科大学CHONGQING MEDICAL UNIVERSITY，北师大、浙大和中科院系统紧随其后。</li></ul><p><strong>中国大陆在个别期刊的贡献赶上并超越美国，而其中除国产牛刊National Science Review外，其他多为网上为人诟病的“水刊”，值得国人深思。</strong></p><ul><li>National Science Review，9.408。国产期刊！中国大陆（209）第一，其次为美国（68），澳大利亚、德国和英国。贡献最多的院校机构为中科院系统、北大、清华和中科大。</li><li><em>Scientific Reports</em>，4.122。中国大陆（19,861）第一，美国（14,610）第二。稿源主要来自中科院系统、上海交通大学、浙大和北大。</li><li><em>PLos ONE</em>，2.766。美国（20,935）第一，中国大陆（12,321）第二。稿源主要来自中科院系统。</li><li><em>Medicine</em>，2.028。中国大陆（4510）第一，随后为韩国（1073），台湾（1061）和美国（707）。稿源前十有四川大学、中国医学科学院、首都医科大学、浙大和中山大学（以及几所台湾的单位）。</li><li><em>Oncology Letters</em>，1.664。中国大陆（3232）第一，随后为日本（502）、美国（187）和韩国（162）。稿源前十院校是山东大学、浙大、吉林大学、郑州大学、上海交通大学、首都医科大学、中南大学、中山大学、复旦大学和四川大学。</li><li>Oncology Research，3.143。中国大陆第一（257），美国第二（13），日本第三（9）。稿源前十院校是西安交通大学、吉林大学、郑州大学、中南大学、河南大学、南京医科大学、第四军医大学、河北大学、哈尔滨医科大学、西安医科大学、中山大学和华南医科大学。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;近日，最新的学术期刊影响因子（基于2015-2017年3年的期刊文章引用数据）发布，虽然大家一再强调，要淡化影响因子在科研评估中的份量，但是&lt;strong&gt;每年影响因子的起伏就好像股票的跌涨，还是牵动着众多研究者的心&lt;/strong&gt;。&lt;br&gt;新的影响因子系统还提供了引用贡
      
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>多中心合作与脑科学研究 由最近一篇文章想到的</title>
    <link href="http://conxz.net/2018/05/19/collaborative-team-research/"/>
    <id>http://conxz.net/2018/05/19/collaborative-team-research/</id>
    <published>2018-05-19T09:46:00.000Z</published>
    <updated>2018-05-19T11:27:54.282Z</updated>
    
    <content type="html"><![CDATA[<p>按照惯例，先放上论文的信息，方便查阅，也请多多指教。<br>Kong, X., Mathias, S. R., Guadalupe, T., ENIGMA Laterality Working Group, Glahn, D. C., Franke, B., Crivello, F., Tzourio-Mazoyer, N., Fisher, S. E., Thompson, P. M., &amp; Francks, C. (2018). Mapping Cortical Brain Asymmetry in 17,141 Healthy Individuals Worldwide via the ENIGMA Consortium. Proceedings of the National Academy of Sciences of the United States of America. Advance online publication. <a href="https://doi.org/10.1073/pnas.1718418115" target="_blank" rel="noopener">doi:10.1073/pnas.1718418115</a></p><p><img src="/images/post_images/pnassites.jpg" alt="脑皮层偏侧化研究中的多中心"><br><a id="more"></a><br>论文主要通过多中心合作的研究模式，汇集了来自全球99个数据集的17000+个健康脑结构影像数据，以刻画人脑结构的不对称性；文中同时考察了这种不对称性的个体差异，以及这种个体差异与年龄、性别、利手，以及遗传因素之间的关联。文中具体描述了一些有意思的发现，可能对今后关于脑功能偏侧化和脑结构不对称性之间关联，以及脑不对性的遗传基础等研究可以提供一些有用的信息；同时，这一研究提供了一个健康样本在群体水平的脑结构偏侧化模式，对于今后脑疾病相关研究可以提供参考信息。</p><p>很高兴这篇论文最近被PNAS接收，从去年十月底投稿，到半月前接收，差不多正好是6个月的时间。审稿过程相对顺利，中间对文章可能存在的问题做了一些补充和回复，非常感激编辑和5位审稿人对文章的欣赏和认可。这里不好透露审稿意见原文，这里仅提及一点，即，<strong>多中心合作的研究模式</strong>。</p><p><img src="/images/post_images/multisites.jpg" alt="多中心合作"></p><p>说到<strong>多中心合作</strong>，我觉得不得不提及最近总会被提及的<strong>可重复性问题</strong>。关于可重复性问题，个人认为这一问题的根本原因并不是伪造数据，选择性报告结果或p-hacking（虽然这种现象真的存在，但不是主流）。更根本的原因应该是样本量与真实效应量之间的不对等，即研究问题的真实效应量往往很小，在小样本量的研究中得到的（统计显著的）结果往往是对效应量的高估，甚至假阳性；归结到一个词，就是统计效力（statistical power）问题。以常用的效应量Cohen’s d为例，在两组样本真实差异的效应量为0.3时，两组样本的分布有接近90%的重合，可以想象在这种情况下，如果仅从每一组中抽取少量的样本，得到的组间差异会呈现怎样一副图景（关于效应量的解释，推荐这个网页工具<a href="http://rpsychologist.com/d3/cohend/" target="_blank" rel="noopener">Interpreting Cohen’s d effect size</a>）。</p><p><strong>多中心合作</strong>的研究模式可能有以下几点优势：</p><ul><li>在单个中心资源有限的情况下，针对特定研究问题可以有更大的样本量</li><li>可以更稳定更全面的考察感兴趣效应，以及这一效应在不同数据集之间的变异</li><li>数据互通有无，充分利用资源：比如，可能有些数据A实验室有，但是A实验室并不感兴趣，但是这些数据可能对B实验室的研究问题极为重要</li><li>研究方法互通有无，使研究更全面：比如，B实验室可以提供A实验室目前并不熟悉的分析方法，可以让数据分析更全面</li><li>结果讨论相互补充，使讨论更深入：比如，B实验室可能从A实验室不熟悉的视角提供对结果的不同解读</li></ul><p>这里仅列举几例，多中心合作的优势绝不止这几点。当然多中心合作也存在一些潜在的问题和约束，比如数据质量控制问题，比如数据共享中的隐私保护问题，比如数据分享中的约束可能导致的特定研究无法深入的问题，等等。个人认为这些问题基本都可以通过人为努力尽量避免，即使特定情况下无法避免，基于大样本的多中心合作的研究结果也是对现有研究模式的强有力的补充。</p><p>最近在思考基于中国的资源成立类似多中心合作的联盟的可能性（比如以“<strong>脑与个体差异</strong>”为主题），也和几位同行做了一些交流，总体是可行的（文后附了国内现有的多中心合作项目）。大致模式可以如下：</p><ul><li>单个中心不需要事先共享数据，仅需要提供自己已经采集的数据，测量和样本信息，比如脑影像数据模态、行为测量等</li><li>研究者提出研究问题，并明确需要的测量和数据要求，比如脑影像数据测量指标和行为测量名称</li><li>其他研究者采用自愿加入模式，对感兴趣的研究问题自愿选择是否加入研究项目</li><li>各个中心定期更新自有数据的信息</li><li>成果署名采用国际惯例，主要研究者决定第一作者，通讯作者和资深作者，其他所有贡献者作为共同作者（根据贡献大小或姓氏拼音排名）</li><li>平台起初仅限内部共享，组织内部共享信息</li><li>项目初期可以以邮件列表的形式开展，通过收集研究想法和数据需求–&gt;发布信息到邮件列表中各研究者–&gt;研究者直接联系并参与项目–&gt;文章写作和发表等流程实现；当然如果能有基金支持，可以形成一个去中心化的网络合作平台</li></ul><p>欢迎感兴趣的同行一起交流学习。</p><hr><p>附：目前我所知的国内的多中心合作研究，欢迎补充。</p><ul><li>中科院心理所（左西年老师）、北师大、杭州师大、中科院自动化所、南京大学、首都医科大学等和国外机构合作的关于脑功能连接组的重测数据集<br>Zuo, Xi-Nian, et al. “An open science resource for establishing reliability and reproducibility in functional connectomics.” Scientific data 1 (2014): 140049.</li><li>复旦大学（冯建峰老师）、西南大学（邱江老师）和国外大学合作的关于抑郁症脑功能异常的研究<br>Cheng, Wei, et al. “Medial reward and lateral non-reward orbitofrontal cortex circuits change in opposite directions in depression.” Brain 139.12 (2016): 3296-3309.</li><li>中科院心理所（严超赣老师）、国内多所大学（或附属医院）和国外研究机构合作的关于抑郁症静息态功能磁共振的多中心研究<br>Yan, Chao-Gan, et al. “Reduced but not Enhanced Default Mode Network Functional Connectivity in Major Depressive Disorder: Evidence from 25 Cohorts in the REST-meta-MDD Project.” bioRxiv (2018): 321745.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;按照惯例，先放上论文的信息，方便查阅，也请多多指教。&lt;br&gt;Kong, X., Mathias, S. R., Guadalupe, T., ENIGMA Laterality Working Group, Glahn, D. C., Franke, B., Crivello, F., Tzourio-Mazoyer, N., Fisher, S. E., Thompson, P. M., &amp;amp; Francks, C. (2018). Mapping Cortical Brain Asymmetry in 17,141 Healthy Individuals Worldwide via the ENIGMA Consortium. Proceedings of the National Academy of Sciences of the United States of America. Advance online publication. &lt;a href=&quot;https://doi.org/10.1073/pnas.1718418115&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;doi:10.1073/pnas.1718418115&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/post_images/pnassites.jpg&quot; alt=&quot;脑皮层偏侧化研究中的多中心&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="collaborative team research" scheme="http://conxz.net/tags/collaborative-team-research/"/>
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
  </entry>
  
</feed>
