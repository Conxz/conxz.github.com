<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小孔成像</title>
  
  <subtitle>Kong Brain Observatory</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://conxz.net/"/>
  <updated>2020-01-10T23:31:26.536Z</updated>
  <id>http://conxz.net/</id>
  
  <author>
    <name>Xiangzhen Kong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>pytorch入门例子3：模型训练和测试</title>
    <link href="http://conxz.net/2020/01/10/pytorch-example-3/"/>
    <id>http://conxz.net/2020/01/10/pytorch-example-3/</id>
    <published>2020-01-10T22:43:50.000Z</published>
    <updated>2020-01-10T23:31:26.536Z</updated>
    
    <content type="html"><![CDATA[<p>CIFAR10训练集50,000<br>CIFAR10测试集10,000<br>图片+标签</p><p>像下面的neural network，不用GPU也可以很好地完成训练。这个模型和<a href="http://conxz.net/2020/01/09/pytorch-example-2/">之前的例子</a>类似。<a id="more"></a></p><pre>import torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1 = nn.Conv2d(3, 6, 5)        self.pool = nn.MaxPool2d(2, 2)        self.conv2 = nn.Conv2d(6, 16, 5)        self.fc1 = nn.Linear(16 * 5 * 5, 120)        self.fc2 = nn.Linear(120, 84)        self.fc3 = nn.Linear(84, 10)    def forward(self, x):        x = self.pool(F.relu(self.conv1(x)))        x = self.pool(F.relu(self.conv2(x)))        x = x.view(-1, 16 * 5 * 5)        x = F.relu(self.fc1(x))        x = F.relu(self.fc2(x))        x = self.fc3(x)        return xnet = Net()</pre><p>完成训练之后，可以将模型状态保存，以备下一次直接使用。</p><pre>PATH = './cifar_net.pth'torch.save(net.state_dict(), PATH)</pre><p>读取之前保存的模型状态，并测试新数据。</p><pre>net = Net()net.load_state_dict(torch.load(PATH))outputs = net(new_images)_, predicted = torch.max(outputs, 1) # 取最大值对应的label</pre><p>Source<br><a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html" target="_blank" rel="noopener">DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;CIFAR10训练集50,000&lt;br&gt;CIFAR10测试集10,000&lt;br&gt;图片+标签&lt;/p&gt;
&lt;p&gt;像下面的neural network，不用GPU也可以很好地完成训练。这个模型和&lt;a href=&quot;http://conxz.net/2020/01/09/pytorch-example-2/&quot;&gt;之前的例子&lt;/a&gt;类似。
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="pytorch" scheme="http://conxz.net/tags/pytorch/"/>
    
      <category term="machine learning" scheme="http://conxz.net/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>pytorch入门例子2</title>
    <link href="http://conxz.net/2020/01/09/pytorch-example-2/"/>
    <id>http://conxz.net/2020/01/09/pytorch-example-2/</id>
    <published>2020-01-09T22:30:26.000Z</published>
    <updated>2020-01-09T22:51:48.637Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个略复杂的入门例子，涵盖了一个典型神经网络的训练过程。</p><pre><code>import torch.nn as nnimport torch.nn.functional as F# Define the network structureclass Net(nn.Module):    def __init__(self):        super(Net, self).__init__()        self.conv1 = nn.Conv2d(1,6,3) # Convolutions        self.conv2 = nn.Conv2d(6,16,3)        self.fc1 = nn.Linear(16*6*6,120) # Full connections        self.fc2 = nn.Linear(120,84)        self.fc3 = nn.Linear(84, 10)    def forward(self, x):        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))        x = F.max_pool2d(F.relu(self.conv2(x)), 2)        x = x.view(-1, self.num_flat_features(x))        x = F.relu(self.fc1(x)) # rectified linear unit        x = F.relu(self.fc2(x))        x = self.fc3(x)        return x    def num_flat_features(self, x):        size = x.size()[1:]        num_features = 1        for s in size:            num_features *=s        return num_featuresnet = Net()print(net)<a id="more"></a># Processing inputs and calling backwardinput = torch.randn(1,1,32,32)out = net(input)print(out)net.zero_grad()out.backward(torch.randn(1,10))# Computing the lossoutput = net(input)target = torch.randn(10)target = target.view(1,-1)criterion = nn.MSELoss()loss = criterion(output, target)print(loss)# Backpropnet.zero_grad()print('conv1.bias.grad before backward')print(net.conv1.bias.grad)loss.backward()print('conv1.bias.grad after backward')print(net.conv1.bias.grad)# Updating the weights of the network# weight = weight - learning_rate * gradientlearning_rate = 0.01for f in net.parameters():    f.data.sub_(f.grad.data*learning_rate)# torch.optimimport torch.optim as optimoptimizer = option.SGD(net.parameters(), lr=0.01)optimizer = optim.SGD(net.parameters(), lr=0.01)optimizer.zero_grad()output = net(input)loss = criterion(output, target)loss.backward()optimizer.step()</code></pre><p>Source<br><a href="https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html" target="_blank" rel="noopener">DEEP LEARNING WITH PYTORCH: A 60 MINUTE BLITZ</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一个略复杂的入门例子，涵盖了一个典型神经网络的训练过程。&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
import torch.nn as nn
import torch.nn.functional as F

# Define the network structure
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1,6,3) # Convolutions
        self.conv2 = nn.Conv2d(6,16,3)
        self.fc1 = nn.Linear(16*6*6,120) # Full connections
        self.fc2 = nn.Linear(120,84)
        self.fc3 = nn.Linear(84, 10)
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(-1, self.num_flat_features(x))
        x = F.relu(self.fc1(x)) # rectified linear unit
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
    def num_flat_features(self, x):
        size = x.size()[1:]
        num_features = 1
        for s in size:
            num_features *=s
        return num_features

net = Net()
print(net)
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="pytorch" scheme="http://conxz.net/tags/pytorch/"/>
    
      <category term="machine learning" scheme="http://conxz.net/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>一个pytorch入门例子</title>
    <link href="http://conxz.net/2020/01/08/a-pytorch-example/"/>
    <id>http://conxz.net/2020/01/08/a-pytorch-example/</id>
    <published>2020-01-08T22:12:41.000Z</published>
    <updated>2020-01-09T18:26:15.430Z</updated>
    
    <content type="html"><![CDATA[<pre><code>import torchfrom torch.autograd import Variabledtype = torch.FloatTensorN, D_in, H, D_out = 64, 1000, 100, 10 # one input layer, one hidden layer, and one output layer<a id="more"></a>x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)learning_rate = 1e-6for t in range(500):    y_pred = x.mm(w1).clamp(min=0).mm(w2)    loss = (y_pred - y).pow(2).sum()    print(t, loss.data)    loss.backward()    w1.data -= learning_rate * w1.grad    w2.data -= learning_rate * w2.grad    w1.grad.zero_()    w2.grad.zero_()</code></pre><p>输出<br><code><br>0 tensor(33538672.)<br>1 tensor(29973312.)<br>2 tensor(26784652.)<br>3 tensor(21361500.)<br>4 tensor(14865291.)<br>5 tensor(9206818.)<br>6 tensor(5481059.)<br>7 tensor(3352937.5000)<br>8 tensor(2212013.7500)<br>9 tensor(1584447.7500)<br>10 tensor(1214588.1250)<br>11 tensor(975241.6250)<br>12 tensor(806804.3750)<br>13 tensor(680432.1875)<br>14 tensor(580979.7500)<br>15 tensor(500418.2188)<br>16 tensor(433949.5000)<br>17 tensor(378533.2500)<br>18 tensor(331744.8125)<br>19 tensor(292014.9375)<br>20 tensor(258002.2969)<br>21 tensor(228759.7031)<br>22 tensor(203502.3438)<br>23 tensor(181617.4062)<br>24 tensor(162530.6094)<br>25 tensor(145835.1406)<br>26 tensor(131164.5469)<br>27 tensor(118248.6328)<br>28 tensor(106880.9688)<br>29 tensor(96805.8125)<br>30 tensor(87843.5078)<br>31 tensor(79855.7891)<br>32 tensor(72728.5000)<br>33 tensor(66353.7422)<br>34 tensor(60627.9375)<br>35 tensor(55480.1055)<br>36 tensor(50842.4727)<br>37 tensor(46652.8438)<br>38 tensor(42859.6172)<br>39 tensor(39420.3984)<br>40 tensor(36297.3594)<br>41 tensor(33456.6836)<br>42 tensor(30868.9805)<br>43 tensor(28508.7754)<br>44 tensor(26352.9551)<br>45 tensor(24381.9219)<br>46 tensor(22576.9590)<br>47 tensor(20924.1289)<br>48 tensor(19406.6504)<br>49 tensor(18014.0859)<br>50 tensor(16734.3945)<br>51 tensor(15556.9463)<br>52 tensor(14473.6260)<br>53 tensor(13474.7432)<br>54 tensor(12552.1865)<br>55 tensor(11700.5293)<br>56 tensor(10912.8838)<br>57 tensor(10183.5830)<br>58 tensor(9508.0732)<br>59 tensor(8882.0479)<br>60 tensor(8301.2988)<br>61 tensor(7762.2920)<br>62 tensor(7261.7388)<br>63 tensor(6796.4380)<br>64 tensor(6363.9053)<br>65 tensor(5961.3506)<br>66 tensor(5586.3672)<br>67 tensor(5237.0176)<br>68 tensor(4911.4233)<br>69 tensor(4607.7842)<br>70 tensor(4324.3721)<br>71 tensor(4059.8486)<br>72 tensor(3812.7903)<br>73 tensor(3581.8992)<br>74 tensor(3366.1370)<br>75 tensor(3164.2825)<br>76 tensor(2975.8660)<br>77 tensor(2799.4905)<br>78 tensor(2634.3201)<br>79 tensor(2479.5688)<br>80 tensor(2334.5366)<br>81 tensor(2198.5542)<br>82 tensor(2070.9956)<br>83 tensor(1951.3154)<br>84 tensor(1838.9900)<br>85 tensor(1733.5266)<br>86 tensor(1634.4674)<br>87 tensor(1541.3926)<br>88 tensor(1453.9283)<br>89 tensor(1371.7056)<br>90 tensor(1294.3995)<br>91 tensor(1221.7031)<br>92 tensor(1153.3300)<br>93 tensor(1088.9634)<br>94 tensor(1028.3733)<br>95 tensor(971.3359)<br>96 tensor(917.6345)<br>97 tensor(867.0400)<br>98 tensor(819.3739)<br>99 tensor(774.4464)<br>100 tensor(732.1039)<br>101 tensor(692.1805)<br>102 tensor(654.5535)<br>103 tensor(619.0535)<br>104 tensor(585.5612)<br>105 tensor(553.9610)<br>106 tensor(524.1429)<br>107 tensor(495.9940)<br>108 tensor(469.4165)<br>109 tensor(444.3282)<br>110 tensor(420.6277)<br>111 tensor(398.2485)<br>112 tensor(377.1102)<br>113 tensor(357.1321)<br>114 tensor(338.2508)<br>115 tensor(320.4093)<br>116 tensor(303.5409)<br>117 tensor(287.5944)<br>118 tensor(272.5143)<br>119 tensor(258.2510)<br>120 tensor(244.7672)<br>121 tensor(232.0098)<br>122 tensor(219.9384)<br>123 tensor(208.5144)<br>124 tensor(197.7036)<br>125 tensor(187.4775)<br>126 tensor(177.7916)<br>127 tensor(168.6223)<br>128 tensor(159.9440)<br>129 tensor(151.7250)<br>130 tensor(143.9390)<br>131 tensor(136.5644)<br>132 tensor(129.5799)<br>133 tensor(122.9632)<br>134 tensor(116.6942)<br>135 tensor(110.7556)<br>136 tensor(105.1254)<br>137 tensor(99.7922)<br>138 tensor(94.7351)<br>139 tensor(89.9417)<br>140 tensor(85.3960)<br>141 tensor(81.0888)<br>142 tensor(77.0021)<br>143 tensor(73.1286)<br>144 tensor(69.4550)<br>145 tensor(65.9725)<br>146 tensor(62.6662)<br>147 tensor(59.5297)<br>148 tensor(56.5552)<br>149 tensor(53.7328)<br>150 tensor(51.0556)<br>151 tensor(48.5134)<br>152 tensor(46.1019)<br>153 tensor(43.8134)<br>154 tensor(41.6410)<br>155 tensor(39.5785)<br>156 tensor(37.6204)<br>157 tensor(35.7611)<br>158 tensor(33.9956)<br>159 tensor(32.3195)<br>160 tensor(30.7282)<br>161 tensor(29.2167)<br>162 tensor(27.7806)<br>163 tensor(26.4171)<br>164 tensor(25.1230)<br>165 tensor(23.8926)<br>166 tensor(22.7236)<br>167 tensor(21.6127)<br>168 tensor(20.5574)<br>169 tensor(19.5545)<br>170 tensor(18.6020)<br>171 tensor(17.6969)<br>172 tensor(16.8359)<br>173 tensor(16.0185)<br>174 tensor(15.2415)<br>175 tensor(14.5024)<br>176 tensor(13.8001)<br>177 tensor(13.1326)<br>178 tensor(12.4976)<br>179 tensor(11.8940)<br>180 tensor(11.3202)<br>181 tensor(10.7745)<br>182 tensor(10.2554)<br>183 tensor(9.7622)<br>184 tensor(9.2926)<br>185 tensor(8.8464)<br>186 tensor(8.4218)<br>187 tensor(8.0179)<br>188 tensor(7.6338)<br>189 tensor(7.2685)<br>190 tensor(6.9206)<br>191 tensor(6.5901)<br>192 tensor(6.2753)<br>193 tensor(5.9762)<br>194 tensor(5.6914)<br>195 tensor(5.4201)<br>196 tensor(5.1624)<br>197 tensor(4.9167)<br>198 tensor(4.6833)<br>199 tensor(4.4609)<br>200 tensor(4.2493)<br>201 tensor(4.0482)<br>202 tensor(3.8562)<br>203 tensor(3.6738)<br>204 tensor(3.5002)<br>205 tensor(3.3344)<br>206 tensor(3.1773)<br>207 tensor(3.0273)<br>208 tensor(2.8845)<br>209 tensor(2.7487)<br>210 tensor(2.6194)<br>211 tensor(2.4963)<br>212 tensor(2.3788)<br>213 tensor(2.2671)<br>214 tensor(2.1607)<br>215 tensor(2.0594)<br>216 tensor(1.9629)<br>217 tensor(1.8709)<br>218 tensor(1.7832)<br>219 tensor(1.6998)<br>220 tensor(1.6205)<br>221 tensor(1.5449)<br>222 tensor(1.4727)<br>223 tensor(1.4040)<br>224 tensor(1.3386)<br>225 tensor(1.2762)<br>226 tensor(1.2168)<br>227 tensor(1.1603)<br>228 tensor(1.1063)<br>229 tensor(1.0549)<br>230 tensor(1.0058)<br>231 tensor(0.9592)<br>232 tensor(0.9148)<br>233 tensor(0.8725)<br>234 tensor(0.8320)<br>235 tensor(0.7934)<br>236 tensor(0.7568)<br>237 tensor(0.7219)<br>238 tensor(0.6885)<br>239 tensor(0.6568)<br>240 tensor(0.6264)<br>241 tensor(0.5976)<br>242 tensor(0.5700)<br>243 tensor(0.5438)<br>244 tensor(0.5188)<br>245 tensor(0.4949)<br>246 tensor(0.4722)<br>247 tensor(0.4504)<br>248 tensor(0.4298)<br>249 tensor(0.4101)<br>250 tensor(0.3913)<br>251 tensor(0.3734)<br>252 tensor(0.3562)<br>253 tensor(0.3400)<br>254 tensor(0.3244)<br>255 tensor(0.3096)<br>256 tensor(0.2955)<br>257 tensor(0.2820)<br>258 tensor(0.2691)<br>259 tensor(0.2568)<br>260 tensor(0.2452)<br>261 tensor(0.2340)<br>262 tensor(0.2234)<br>263 tensor(0.2132)<br>264 tensor(0.2035)<br>265 tensor(0.1943)<br>266 tensor(0.1855)<br>267 tensor(0.1771)<br>268 tensor(0.1690)<br>269 tensor(0.1614)<br>270 tensor(0.1541)<br>271 tensor(0.1471)<br>272 tensor(0.1404)<br>273 tensor(0.1341)<br>274 tensor(0.1280)<br>275 tensor(0.1222)<br>276 tensor(0.1167)<br>277 tensor(0.1115)<br>278 tensor(0.1064)<br>279 tensor(0.1016)<br>280 tensor(0.0971)<br>281 tensor(0.0927)<br>282 tensor(0.0886)<br>283 tensor(0.0846)<br>284 tensor(0.0808)<br>285 tensor(0.0772)<br>286 tensor(0.0737)<br>287 tensor(0.0704)<br>288 tensor(0.0673)<br>289 tensor(0.0642)<br>290 tensor(0.0614)<br>291 tensor(0.0586)<br>292 tensor(0.0560)<br>293 tensor(0.0535)<br>294 tensor(0.0511)<br>295 tensor(0.0488)<br>296 tensor(0.0467)<br>297 tensor(0.0446)<br>298 tensor(0.0426)<br>299 tensor(0.0407)<br>300 tensor(0.0389)<br>301 tensor(0.0372)<br>302 tensor(0.0355)<br>303 tensor(0.0340)<br>304 tensor(0.0325)<br>305 tensor(0.0310)<br>306 tensor(0.0297)<br>307 tensor(0.0284)<br>308 tensor(0.0271)<br>309 tensor(0.0259)<br>310 tensor(0.0248)<br>311 tensor(0.0237)<br>312 tensor(0.0226)<br>313 tensor(0.0217)<br>314 tensor(0.0207)<br>315 tensor(0.0198)<br>316 tensor(0.0189)<br>317 tensor(0.0181)<br>318 tensor(0.0173)<br>319 tensor(0.0166)<br>320 tensor(0.0158)<br>321 tensor(0.0152)<br>322 tensor(0.0145)<br>323 tensor(0.0139)<br>324 tensor(0.0133)<br>325 tensor(0.0127)<br>326 tensor(0.0122)<br>327 tensor(0.0116)<br>328 tensor(0.0111)<br>329 tensor(0.0107)<br>330 tensor(0.0102)<br>331 tensor(0.0098)<br>332 tensor(0.0094)<br>333 tensor(0.0090)<br>334 tensor(0.0086)<br>335 tensor(0.0082)<br>336 tensor(0.0079)<br>337 tensor(0.0075)<br>338 tensor(0.0072)<br>339 tensor(0.0069)<br>340 tensor(0.0066)<br>341 tensor(0.0064)<br>342 tensor(0.0061)<br>343 tensor(0.0059)<br>344 tensor(0.0056)<br>345 tensor(0.0054)<br>346 tensor(0.0052)<br>347 tensor(0.0050)<br>348 tensor(0.0048)<br>349 tensor(0.0046)<br>350 tensor(0.0044)<br>351 tensor(0.0042)<br>352 tensor(0.0040)<br>353 tensor(0.0039)<br>354 tensor(0.0037)<br>355 tensor(0.0036)<br>356 tensor(0.0034)<br>357 tensor(0.0033)<br>358 tensor(0.0032)<br>359 tensor(0.0031)<br>360 tensor(0.0029)<br>361 tensor(0.0028)<br>362 tensor(0.0027)<br>363 tensor(0.0026)<br>364 tensor(0.0025)<br>365 tensor(0.0024)<br>366 tensor(0.0023)<br>367 tensor(0.0022)<br>368 tensor(0.0022)<br>369 tensor(0.0021)<br>370 tensor(0.0020)<br>371 tensor(0.0019)<br>372 tensor(0.0019)<br>373 tensor(0.0018)<br>374 tensor(0.0017)<br>375 tensor(0.0017)<br>376 tensor(0.0016)<br>377 tensor(0.0016)<br>378 tensor(0.0015)<br>379 tensor(0.0015)<br>380 tensor(0.0014)<br>381 tensor(0.0014)<br>382 tensor(0.0013)<br>383 tensor(0.0013)<br>384 tensor(0.0012)<br>385 tensor(0.0012)<br>386 tensor(0.0011)<br>387 tensor(0.0011)<br>388 tensor(0.0011)<br>389 tensor(0.0010)<br>390 tensor(0.0010)<br>391 tensor(0.0010)<br>392 tensor(0.0009)<br>393 tensor(0.0009)<br>394 tensor(0.0009)<br>395 tensor(0.0009)<br>396 tensor(0.0008)<br>397 tensor(0.0008)<br>398 tensor(0.0008)<br>399 tensor(0.0008)<br>400 tensor(0.0007)<br>401 tensor(0.0007)<br>402 tensor(0.0007)<br>403 tensor(0.0007)<br>404 tensor(0.0006)<br>405 tensor(0.0006)<br>406 tensor(0.0006)<br>407 tensor(0.0006)<br>408 tensor(0.0006)<br>409 tensor(0.0006)<br>410 tensor(0.0005)<br>411 tensor(0.0005)<br>412 tensor(0.0005)<br>413 tensor(0.0005)<br>414 tensor(0.0005)<br>415 tensor(0.0005)<br>416 tensor(0.0005)<br>417 tensor(0.0004)<br>418 tensor(0.0004)<br>419 tensor(0.0004)<br>420 tensor(0.0004)<br>421 tensor(0.0004)<br>422 tensor(0.0004)<br>423 tensor(0.0004)<br>424 tensor(0.0004)<br>425 tensor(0.0004)<br>426 tensor(0.0004)<br>427 tensor(0.0003)<br>428 tensor(0.0003)<br>429 tensor(0.0003)<br>430 tensor(0.0003)<br>431 tensor(0.0003)<br>432 tensor(0.0003)<br>433 tensor(0.0003)<br>434 tensor(0.0003)<br>435 tensor(0.0003)<br>436 tensor(0.0003)<br>437 tensor(0.0003)<br>438 tensor(0.0003)<br>439 tensor(0.0003)<br>440 tensor(0.0003)<br>441 tensor(0.0002)<br>442 tensor(0.0002)<br>443 tensor(0.0002)<br>444 tensor(0.0002)<br>445 tensor(0.0002)<br>446 tensor(0.0002)<br>447 tensor(0.0002)<br>448 tensor(0.0002)<br>449 tensor(0.0002)<br>450 tensor(0.0002)<br>451 tensor(0.0002)<br>452 tensor(0.0002)<br>453 tensor(0.0002)<br>454 tensor(0.0002)<br>455 tensor(0.0002)<br>456 tensor(0.0002)<br>457 tensor(0.0002)<br>458 tensor(0.0002)<br>459 tensor(0.0002)<br>460 tensor(0.0002)<br>461 tensor(0.0002)<br>462 tensor(0.0002)<br>463 tensor(0.0002)<br>464 tensor(0.0001)<br>465 tensor(0.0001)<br>466 tensor(0.0001)<br>467 tensor(0.0001)<br>468 tensor(0.0001)<br>469 tensor(0.0001)<br>470 tensor(0.0001)<br>471 tensor(0.0001)<br>472 tensor(0.0001)<br>473 tensor(0.0001)<br>474 tensor(0.0001)<br>475 tensor(0.0001)<br>476 tensor(0.0001)<br>477 tensor(0.0001)<br>478 tensor(0.0001)<br>479 tensor(0.0001)<br>480 tensor(0.0001)<br>481 tensor(0.0001)<br>482 tensor(0.0001)<br>483 tensor(0.0001)<br>484 tensor(0.0001)<br>485 tensor(0.0001)<br>486 tensor(9.8671e-05)<br>487 tensor(9.6656e-05)<br>488 tensor(9.4918e-05)<br>489 tensor(9.3419e-05)<br>490 tensor(9.1719e-05)<br>491 tensor(9.0300e-05)<br>492 tensor(8.8702e-05)<br>493 tensor(8.7077e-05)<br>494 tensor(8.5830e-05)<br>495 tensor(8.4661e-05)<br>496 tensor(8.3026e-05)<br>497 tensor(8.1507e-05)<br>498 tensor(8.0135e-05)<br>499 tensor(7.8957e-05)<br></code></p><p>Reference<br><a href="https://github.com/llSourcell/pytorch_in_5_minutes" target="_blank" rel="noopener">https://github.com/llSourcell/pytorch_in_5_minutes</a></p>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;
import torch
from torch.autograd import Variable

dtype = torch.FloatTensor
N, D_in, H, D_out = 64, 1000, 100, 10 
# one input layer, one hidden layer, and one output layer
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="pytorch" scheme="http://conxz.net/tags/pytorch/"/>
    
      <category term="machine learning" scheme="http://conxz.net/tags/machine-learning/"/>
    
  </entry>
  
  <entry>
    <title>Presentation Learning Day 2</title>
    <link href="http://conxz.net/2020/01/08/presentation-learning-day-2/"/>
    <id>http://conxz.net/2020/01/08/presentation-learning-day-2/</id>
    <published>2020-01-07T23:19:51.000Z</published>
    <updated>2020-01-07T23:22:49.897Z</updated>
    
    <content type="html"><![CDATA[<p>hello and welcome to xxx<br>I am just going to briefly touch upon what this xx will be about. and also I want to mention that xxx<br>so what is this xx, what isn’t this xx<br>I have presented some of these talks to the labs that I work in locally. and there were definitely folks in the audience who did not have xx experience.<br>I think they still got something out of it. they built their understanding.<br>so it is still useful if you’re completely new. but it’s going to be more useful for those of you who’ve been running xxx.<br><a id="more"></a><br>but either way, I will give you a shot and see what you get out of it.<br>I’m not going to start from like the basics in xx textbook necessarily. I am focusing on sort of these aha moments I’ve had along the way as I’ve been working with xx, and trying to figure things out.<br>That’s the stuff I want to share with you because it’s not obvious.<br>so the first thing I want to talk about will be xx<br>if you haven’t heard about it, don’t worry about it. I will explain what it is.<br>if you have, I just want to explain what it is, and why it’s good.<br>then the next section ..<br>I will ask you in the audience for some examples that you might want to share.<br>and at last, I hope to cover .xxx<br>but it turns out that this is  a pretty tricky topic in xxx<br>I’m hoping to walk me a way through that and digest it.<br>so that’s it. it’s really all I have to say.<br>my voice is a little hoarse because I have a cold. but hopefully that will clear up as xx goes.<br>anyway, so let’s get started. </p><p>I’m gonna start with a quick xx review.<br>primer motivation here is just to set up some notation which I can use to build upon for xx.<br>so other than that , the goal of this is just quickly review xx<br>But I am not going to getting into the nitty-gritty.<br>and the most important things I want to take ways from this are xx<br>I will do my best to keep equations at a minimum, but I really do need just a couple to get through this.<br>I will go over them many many time. hopefully the repetition will help.<br>hopefully that will help pull together the entire picture.<br>and quickly I’m getting over a cold so I apologize for my voice. but doing my best hopefully I won’t cough at all.<br>that’s it.<br>the best place for questions about xx is the Facebook group ..<br>I do try to address questions<br>so thanks a lot for your time and have a nice day. </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;hello and welcome to xxx&lt;br&gt;I am just going to briefly touch upon what this xx will be about. and also I want to mention that xxx&lt;br&gt;so what is this xx, what isn’t this xx&lt;br&gt;I have presented some of these talks to the labs that I work in locally. and there were definitely folks in the audience who did not have xx experience.&lt;br&gt;I think they still got something out of it. they built their understanding.&lt;br&gt;so it is still useful if you’re completely new. but it’s going to be more useful for those of you who’ve been running xxx.&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="publication" scheme="http://conxz.net/tags/publication/"/>
    
      <category term="conference" scheme="http://conxz.net/tags/conference/"/>
    
      <category term="learning" scheme="http://conxz.net/tags/learning/"/>
    
  </entry>
  
  <entry>
    <title>Presentation Learning Day 1</title>
    <link href="http://conxz.net/2020/01/07/presentation-learning-day-1/"/>
    <id>http://conxz.net/2020/01/07/presentation-learning-day-1/</id>
    <published>2020-01-06T23:23:46.000Z</published>
    <updated>2020-01-06T23:26:23.644Z</updated>
    
    <content type="html"><![CDATA[<p>My final words is xxx<br>The future is very exciting. It takes all excitement and passion to explore the future.<br>I wish the future forum great success.<br>… beyond what we can see, what we can feel. </p><p>And this is the talk he’s going to give. And I would like to invite you to welcome xxx. </p><p>Thanks xx for that very nice and warm introduction.<br>Actually I feel quite insecure standing here facing the audience because this is probably the first time I am giving a scientific talk in four months.<br>This is unusual you know for a scientist.<br>I think this might be the first time in my life to give such a talk after this long period of silence in science or in presentation.<br>I am hoping by spending next ten years in science I can do something that I truelly will feel proud of my life in science.<br>So for the next 40 mins or so I’m going to tell a story that began to unfold xx<br>As shown here in this slide, is a diagram I took from the PNAS paper published from xxx.<br>we all know the central dogma or information flow in living or living organisms on earth very well.<br>it flows from genetic materials DNA to RNA then eventually to life executing proteins.<br>DNA –Transcription—&gt; RNA –Translation—&gt; Protein</p><p><dna replication=""><br>For transcription and translation, both processes are quite ordered. you can even call it one dimensional search.<br>that’s of course not one-dimensional per se. But you can imagine that is the case.<br>because in the first step transcription what you need is to have genomic DNA transcribed to pre-mRNA in a one-to-one relationship. One DNA base to one RNA base.<br>that is executed by RNA polymerase.<br>In the third step, protein translation what you need to do is for every three bases of mRNA, triplet codon, you have one amino acid specified. So again it is in a way one-dimensional information flow. three to one.<br>so before I describe xx, I’d like to call your attention to the xxx.<br>So I know I’m spending a lot of time on introduction. but I think the value of my talk is really embedded in introduction.<br>as you will see structure in the ends explains just my introduction.<br>So the next slide, this slide, describes essentially all that I want to tell this audience. so bear with me for a couple of minutes.<br>the upper left corner describes again xxx</dna></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;My final words is xxx&lt;br&gt;The future is very exciting. It takes all excitement and passion to explore the future.&lt;br&gt;I wish the future for
      
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="publication" scheme="http://conxz.net/tags/publication/"/>
    
      <category term="conference" scheme="http://conxz.net/tags/conference/"/>
    
      <category term="learning" scheme="http://conxz.net/tags/learning/"/>
    
  </entry>
  
  <entry>
    <title>命令行后台执行</title>
    <link href="http://conxz.net/2020/01/06/execute-cmdline-in-the-backgroud/"/>
    <id>http://conxz.net/2020/01/06/execute-cmdline-in-the-backgroud/</id>
    <published>2020-01-06T21:51:43.000Z</published>
    <updated>2020-01-06T22:01:33.189Z</updated>
    
    <content type="html"><![CDATA[<p>关键词：nohup 后台执行<br>Keywords: nohup background excute stop</p><p>常用的脑影像数据分析和遗传数据分析工具往往采用命令行的方式，用户通过Terminal执行命令行以完成相关数据分析，这种方式可以满足通常情况的需求。在一些特别的情况下，你可能会需要将命令行提交到后台执行，以避免一些意外的情况：</p><ol><li>通常情况下，Terminal和执行的命令是绑定的，即如果在执行程序过程中意外关闭的执行该程序的Terminal，改程序的执行会一起终止。</li><li>通过Terminal访问服务器，在服务器上执行程序时，如果意外出现网络中断，相应的程序也会因此而终止。<a id="more"></a></li></ol><p>Linux中的nohup命令提供了一个很好的解决方案，即将程序提交到后台执行，即使出现上述意外，程序依旧会照常执行。比如这里要执行一个Python程序，通常的方式是采用下面的命令行<br><code>python s1.extract_ts.py</code><br>如果采用这种方式提交，Terminal关闭后，程序执行会被终止。</p><p>通过下面的方式可以采用nohup提交程序到后台执行：<br><code>nohup python s1.extract_ts.py &amp;</code><br>这样执行该命令行后，即便关闭Terminal或远程访问服务器的网络中断，程序执行会照常继续。<br>也可以通过下面的命令将该程序执行过程中的output保存到一个文本文件中<br><code>nohup python s1.extract_ts.py &gt; nohup.log &amp;</code><br>这样，程序执行过程中的output会保存到这个log文件中；而且这个保存是实时的，因此可以通过查看该log文件的内容确定程序运行的到那个阶段，或是否有报错。</p><p>在一些情况下，你可能会发现通过nohup提交的程序可能有问题，需要停掉该程序。可以通过下面的命令，首先查看相应程序的PID，然后将其杀掉。<br><code>ps -ef | grep &quot;s1.extract_ts.py&quot;</code><br><code>kill &lt;PID&gt;</code></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关键词：nohup 后台执行&lt;br&gt;Keywords: nohup background excute stop&lt;/p&gt;
&lt;p&gt;常用的脑影像数据分析和遗传数据分析工具往往采用命令行的方式，用户通过Terminal执行命令行以完成相关数据分析，这种方式可以满足通常情况的需求。在一些特别的情况下，你可能会需要将命令行提交到后台执行，以避免一些意外的情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通常情况下，Terminal和执行的命令是绑定的，即如果在执行程序过程中意外关闭的执行该程序的Terminal，改程序的执行会一起终止。&lt;/li&gt;
&lt;li&gt;通过Terminal访问服务器，在服务器上执行程序时，如果意外出现网络中断，相应的程序也会因此而终止。
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="linux" scheme="http://conxz.net/tags/linux/"/>
    
      <category term="nohup" scheme="http://conxz.net/tags/nohup/"/>
    
  </entry>
  
  <entry>
    <title>十年</title>
    <link href="http://conxz.net/2020/01/02/2010s/"/>
    <id>http://conxz.net/2020/01/02/2010s/</id>
    <published>2020-01-02T19:34:25.000Z</published>
    <updated>2020-01-02T21:05:20.097Z</updated>
    
    <content type="html"><![CDATA[<p>十年，总不免让人觉得有些特别；2010年代匆匆过去，也不免引发一些思考。</p><p>2010年，我开始攻读博士学位。9月份是正式入学的时间，然而那时我已经进实验室参与研究项目近一年。由于是非心理学科班出身，对我而言，很多事情都是从零开始，更多的时候是给实验室师兄师姐打下手，比如：看被试、做被试。不过通过这些参与和平时的组会（实验室的组会真是一个重要的学习渠道），潜移默化中还是对心理学和认知神经科学的专业名词、实验设计、数据采集、常用统计分析有了一些理解。我更多的兴趣在脑影像数据分析，期初的梦想是基于多元统计和机器学习手段实现《阿凡达》中的类似人机交互（当时还是太年轻）。实验室Z老师带我们学习脑成像原理学习、多元统计、计算神经科学和脑影像分析方法，在这个过程中获得了很多的训练，给以后的工作打下了必要的基础。就这样慢慢对认知神经科学的研究问题和手段有了越来越清晰的认识。2016年顺利获得博士学位，博士学位论文被评为“北京师范大学优秀博士学位论文”，为博士学习阶段画上一个完美的句号。</p><p>2016年毕业后便开始了在荷兰Nijmegen马普所的研究工作，时间飞快，现在已3年有余。非常感激能有机会加入到现在的实验室，可以接触到更大的数据集和更多的合作者，并开展了一系列脑影像遗传学和多中心合作的研究。希望在接下来不到一年的时间里，可以顺利完成手上的项目。</p><p>从2010年开始到现在，在脑影像研究领域已经从业十年。有一种说法是，<em>要在任何领域成为大师，一般需要约10年的艰苦努力</em>。十年过去，深知离“大师”的距离还很遥远，脚下的路还很长。新年伊始，想想新的十年的必然和未知，希望一切顺利！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;十年，总不免让人觉得有些特别；2010年代匆匆过去，也不免引发一些思考。&lt;/p&gt;
&lt;p&gt;2010年，我开始攻读博士学位。9月份是正式入学的时间，然而那时我已经进实验室参与研究项目近一年。由于是非心理学科班出身，对我而言，很多事情都是从零开始，更多的时候是给实验室师兄师姐打下
      
    
    </summary>
    
      <category term="Xs" scheme="http://conxz.net/categories/Xs/"/>
    
    
      <category term="life" scheme="http://conxz.net/tags/life/"/>
    
      <category term="2010s" scheme="http://conxz.net/tags/2010s/"/>
    
  </entry>
  
  <entry>
    <title>Google AdSense多账号问题解决方案</title>
    <link href="http://conxz.net/2019/12/26/fix-multple-google-adsense-account-issues/"/>
    <id>http://conxz.net/2019/12/26/fix-multple-google-adsense-account-issues/</id>
    <published>2019-12-26T17:37:46.000Z</published>
    <updated>2019-12-26T18:46:32.088Z</updated>
    
    <content type="html"><![CDATA[<p>原则上Google限制同一个用户仅可拥有一个AdSense账号。如果在以往尝试使用不同的gmail邮箱多次注册Google AdSense账号，通常会碰到多账号问题，即类似<code>You have an adsense that already exists</code>的问题。Google官方给的解决方案是登录AdSense账号后，选择取消相应的账号。但是，如果用户多次申请的账号都未通过审核，用户是不可能通过登录相应的AdSense账号来完成相关账号的取消的。于是，便陷入了一个死循环的状态：由于多账号问题无法通过审核&lt;—&gt;由于未通过审核无法取消申请账号。</p><p>经过一些周折，找到一个间接的解决方案，这里记录备查。<a id="more"></a></p><p>解决方案的基本逻辑是，开通Google AdSense必须在Google账号（比如gmail）中绑定支付方式；如果直接删除支付方式，便可以连带Google AdSense账户一起删除。具体而言，</p><ul><li>登录Google账号，进入My Account界面</li><li>选择支付和订阅Payments &amp; subscriptions，在支付方法Payment methods中进入支付方式管理Manage payment methods</li><li>在页面左侧选择设置Settings，之后就可以在页面最下方看到关闭支付信息Close payment profile链接</li><li>点击后，根据提示填写相关信息，即可。</li><li>在操作成功后，gmail邮箱会受到两个支付信息关闭的邮件，其中一个便是提示Google AdSense取消成功。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;原则上Google限制同一个用户仅可拥有一个AdSense账号。如果在以往尝试使用不同的gmail邮箱多次注册Google AdSense账号，通常会碰到多账号问题，即类似&lt;code&gt;You have an adsense that already exists&lt;/code&gt;的问题。Google官方给的解决方案是登录AdSense账号后，选择取消相应的账号。但是，如果用户多次申请的账号都未通过审核，用户是不可能通过登录相应的AdSense账号来完成相关账号的取消的。于是，便陷入了一个死循环的状态：由于多账号问题无法通过审核&amp;lt;—&amp;gt;由于未通过审核无法取消申请账号。&lt;/p&gt;
&lt;p&gt;经过一些周折，找到一个间接的解决方案，这里记录备查。
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="blog" scheme="http://conxz.net/tags/blog/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
  </entry>
  
  <entry>
    <title>添加Google AdSense到Hexo博客</title>
    <link href="http://conxz.net/2019/12/25/google-adsense-add-to-hexo/"/>
    <id>http://conxz.net/2019/12/25/google-adsense-add-to-hexo/</id>
    <published>2019-12-25T16:51:52.000Z</published>
    <updated>2019-12-28T20:50:20.762Z</updated>
    
    <content type="html"><![CDATA[<p>最近费了一些周折，终于解决了困扰已久的<code>You already have an existing AdSense account</code>问题。Google AdSense通过了审核。下面记录一下添加Google AdSense代码到基于Hexo博客的解决方案，一是备查，二是没准可以帮到新手。</p><p>Hexo博客，使用了maupassant模板。如果是别的模板，解决方案应该也可以参考。</p><a id="more"></a><p>首先在Hexo的_config.yml文件中添加下面一行(注意替换自己的AdSense ID)：<br><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">google_adsense:</span> ca-pub<span class="number">-7680017147908727</span></span><br></pre></td></tr></table></figure></p><p>进入manupassant模板目录themes/maupassant，在layout/_partial目录中可以看到一系列子模块文件。找到head.pug，添加下面的代码。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> config.google_adsense</span><br><span class="line">    script(<span class="attribute">data-ad-client</span>=config.google_adsense, async <span class="attribute">src</span>=<span class="string">'https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js'</span>)</span><br></pre></td></tr></table></figure></p><p>调试，完工。</p><hr><p>2019年12月28日更新手动指定位置添加广告模块内容。</p><p>以上为Google提供的Auto ads服务，即Google自动确定广告展示的位置和尺度，初步测试该自动方式仍然存在一定的局限性，通常会导致页面博客页面混乱。下面是更为常规的方案，即用户自己指定广告展示的位置和尺寸。</p><p>用户需要通过Google Adsense的By ad unit根据需求创建广告模块，获取代码。然后将代码添加到页面的相应位置。比如，如果想要在Hexo maupassant博客文章的末尾添加广告，便可以参考下面的代码将相关代码添加到layout/post.pug最后的位置（注意根据自己的代码修改相关信息）。添加到其他位置也可以参考下面的代码。<br><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> theme.show_ad_unit_post == <span class="literal">true</span></span><br><span class="line">  script(async <span class="attribute">src</span>=<span class="string">'https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js'</span>)</span><br><span class="line">  ins.adsbygoogle(<span class="attribute">style</span>=<span class="string">'display:block'</span>, <span class="attribute">data-ad-client</span>=<span class="string">'ca-pub-7680017147908727'</span>, <span class="attribute">data-ad-slot</span>=<span class="string">'2051716958'</span>, <span class="attribute">data-ad-format</span>=<span class="string">'auto'</span>, <span class="attribute">data-full-width-responsive</span>=<span class="string">'true'</span>)</span><br><span class="line">  script.</span><br><span class="line">      (adsbygoogle = window.adsbygoogle || []).push(&#123;&#125;);</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近费了一些周折，终于解决了困扰已久的&lt;code&gt;You already have an existing AdSense account&lt;/code&gt;问题。Google AdSense通过了审核。下面记录一下添加Google AdSense代码到基于Hexo博客的解决方案，一是备查，二是没准可以帮到新手。&lt;/p&gt;
&lt;p&gt;Hexo博客，使用了maupassant模板。如果是别的模板，解决方案应该也可以参考。&lt;/p&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="blog" scheme="http://conxz.net/tags/blog/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="google adsense" scheme="http://conxz.net/tags/google-adsense/"/>
    
  </entry>
  
  <entry>
    <title>我的黑洞计划：刻画强迫症中的脑不对称性异常</title>
    <link href="http://conxz.net/2019/06/04/asymOCD/"/>
    <id>http://conxz.net/2019/06/04/asymOCD/</id>
    <published>2019-06-04T20:05:37.000Z</published>
    <updated>2019-12-28T21:07:34.204Z</updated>
    
    <content type="html"><![CDATA[<p>先放论文信息，方便查阅原文。<br>Kong, Xiang-Zhen, et al. “Mapping Cortical and Subcortical Asymmetry in Obsessive-Compulsive Disorder: Findings from the ENIGMA Consortium.” Biological Psychiatry. <a href="https://doi.org/10.1016/j.biopsych.2019.04.022" target="_blank" rel="noopener">DOI</a> | <a href="https://pure.mpg.de/rest/items/item_3053214_9/component/file_3053215/content" target="_blank" rel="noopener">全文链接</a></p><p>这是我完成的第二个ENIGMA项目，是偏侧化工作组和强迫症工作组的合作项目。这个项目涉及来自全球16个国家的46个数据集：16个儿童和青少年样本（501病例+439健康对照）和30个成人样本（1777病例+1654健康对照）。我们得到近140名研究者的贡献和支持，通过多中心合作研究，描绘了强迫症与脑结构偏侧化之间的初步关联。</p><p><img src="/images/post_images/asymocd.png" alt="脑结构不对称性与强迫症多中心合作"></p><p>下面是一个中文摘要。<br><a id="more"></a><br>强迫症通常会呈现出偏侧化的脑功能异常。但是，我们还不清楚脑结构不对称性是否在强迫症中呈现异常模式。该研究旨在基于多中心合作和大样本数据，刻画强迫症中的脑结构不对称性模式。具体而言，我们分析了来自ENIGMA强迫症工作组的16个儿童/青少年数据集（501病例、439健康对照）和30个成人数据集（1777病例、1654健康对照）。这些数据集包括皮下结构的体积、皮层脑区的厚度和面积等结构测量，这些参数由统一的图像分析和质量控制流程产生。我们考察了强迫症中可能的脑不对称性异常。同时，对疾病和用药状态与脑结构不对称性之间的关联多了探索。结果显示，在儿童/青少年组，强迫症呈现了丘脑（Thalamus）和苍白球（Pallidum）体积不对称性显著差异。进一步的分析显示，这些不对称性差异可能与强迫症的用药状态、严重程度、焦虑或抑郁并发症存在关联。在成人组没有发现显著差异。综上，数据显示，在儿童/青少年群体中，强迫症与皮下结构的不对称性异常存在一定的关联，而这些异常并未呈现在成人群体中。这些差异可能反映了强迫症的神经发育过程的异常。</p><p><img src="/images/post_images/asymocd2.png" alt="脑结构不对称性与强迫症"></p><p>多中心合作在该项目中扮演了重要的角色。在最近的另一篇文章中，笔者试着从多中心合作的视角，就多中心合作研究模式在开展可重复的心理与脑科学研究中的应用和发展，以及应用过程中需要注意的问题做了一点分享。希望国内心理与脑科学同行，尤其是年轻研究者加强多中心合作研究相关的方法学训练，以更开放的心态联合起来，开展稳健、可重复的心理与脑科学研究。</p><p>孔祥祯. “多中心合作和可重复的心理与脑科学研究.” 心理技术与应用 7.5 (2019): 297-304.  <a href="http://www.xljsyyy.com/CN/10.16842/j.cnki.issn2095-5588.2019.05.004" target="_blank" rel="noopener">http://www.xljsyyy.com/CN/10.16842/j.cnki.issn2095-5588.2019.05.004</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;先放论文信息，方便查阅原文。&lt;br&gt;Kong, Xiang-Zhen, et al. “Mapping Cortical and Subcortical Asymmetry in Obsessive-Compulsive Disorder: Findings from the ENIGMA Consortium.” Biological Psychiatry. &lt;a href=&quot;https://doi.org/10.1016/j.biopsych.2019.04.022&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;DOI&lt;/a&gt; | &lt;a href=&quot;https://pure.mpg.de/rest/items/item_3053214_9/component/file_3053215/content&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;全文链接&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这是我完成的第二个ENIGMA项目，是偏侧化工作组和强迫症工作组的合作项目。这个项目涉及来自全球16个国家的46个数据集：16个儿童和青少年样本（501病例+439健康对照）和30个成人样本（1777病例+1654健康对照）。我们得到近140名研究者的贡献和支持，通过多中心合作研究，描绘了强迫症与脑结构偏侧化之间的初步关联。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/post_images/asymocd.png&quot; alt=&quot;脑结构不对称性与强迫症多中心合作&quot;&gt;&lt;/p&gt;
&lt;p&gt;下面是一个中文摘要。&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="brain asymmetry" scheme="http://conxz.net/tags/brain-asymmetry/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="collaborative team research" scheme="http://conxz.net/tags/collaborative-team-research/"/>
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>脑科学相关SCI Top期刊_2018</title>
    <link href="http://conxz.net/2019/01/13/scitop2018/"/>
    <id>http://conxz.net/2019/01/13/scitop2018/</id>
    <published>2019-01-13T19:40:11.000Z</published>
    <updated>2019-01-13T20:32:58.026Z</updated>
    
    <content type="html"><![CDATA[<p>近日，最新的中科院JCR期刊分区发布，其中关于期刊的分区和是否为Top与去年大致相同，不过还是发生了一些小的变化。比如，Nature Communications和PNAS被划分为2区期刊，其中Nature Communications不在作为Top期刊，PNAS作为2区Top期刊；Human Brain Mapping划分为2区非Top期刊。</p><p>下面是脑科学（神经科学、认知神经科学和神经影像）相关同行通常会提到的期刊的最新信息。</p><p><img src="/images/post_images/scitop.jpg" alt="SCI Top 期刊" title="SCI Top 期刊"><br><a id="more"></a></p><h3 id="期刊名称-影响因子-Top期刊-OA期刊"><a href="#期刊名称-影响因子-Top期刊-OA期刊" class="headerlink" title="期刊名称 影响因子 Top期刊 OA期刊"></a>期刊名称 影响因子 Top期刊 OA期刊</h3><p>Nature 41.577 1区Top 非OA<br>Science 41.058 1区Top 非OA</p><p>Nature Neuroscience 19.912 1区Top 非OA<br>Neuron 14.319 1区Top 非OA</p><p><em>Nature Communications 12.353 2区非TOP OA</em><br>PNAS 9.504 2区Top 非OA<br>Current Biology 9.251 1区Top 非OA<br>Brain 10.848 1区Top 非OA<br>PLOS Biology 9.163 1区Top OA</p><p>Cerebral Cortex 6.308 1区Top 非OA<br>eLife 7.616 1区Top OA<br>Journal of Neuroscience 5.971 2区Top 非OA</p><p>NeuroImage 5.426 2区Top 非OA<br><em>Human Brain Mapping 4.927 2区非Top 非OA</em><br>Brain Structure &amp; Function 4.231 2区Top 非OA<br>Cortex 4.907 2区Top 非OA</p><p>Nature Reviews Neuroscience 32.635 1区Top 非OA<br>Trends in Cognitive Science 15.557 1区Top 非OA<br>Behavioral and Brain Science 15.071 1区Top 非OA<br>Trends in Neurosciences 11.439 1区Top 非OA<br>Neuroscience &amp; Biobehavioral Reviews 8.037 1区Top 非OA<br>Neuroscientist 7.461 1区Top 非OA</p><p>JAMA Psychiatry 16.642 1区Top 非OA<br>Molecular Psychiatry 11.640 1区Top 非OA<br>Biological Psychiatry 11.984 1区Top 非OA<br>Lancet Psychiatry 15.233 1区Top 非OA<br>Molecular Neurodegeneration 6.426 1区Top OA<br>Neuropsychopharmacology 6.544 1区Top 非OA</p><p><em>National Science Review 9.408 2区非Top 非OA</em><br>Annual Review of Neuroscience 14.675 1区Top 非OA<br>Progress in Neurobiology 14.163 1区Top 非OA</p><p><em>Current Opinion in Neurobiology 6.541 2区非Top 非OA</em><br>Nature Genetics 27.125 1区Top 非OA<br>PLoS Genetics 5.540 2区Top OA<br>Neuropharmacology 4.249 2区Top 非OA</p><p>Annual Review of Psychology 22.774 1区Top 非OA<br>Psychological Bulletin 13.250 1区Top 非OA<br>Annual Review of Clinical Psychology 13.278 1区Top 非OA<br>Psychological Review 7.230 1区Top 非OA</p><p>Diabetes Care 13.397 1区Top 非OA<br>Stroke 6.239 2区Top 非OA<br>Pain 5.559 2区Top 非OA<br>Sleep Medicine Reviews 10.602 1区Top 非OA</p><p>此外，Psychological Science是很好的期刊，影响因子从去年的5.667提升到今年6.128，由于只属SSCI期刊，并不在中科院分区范围。</p><p>你可能对<a href="http://conxz.net/2017/11/08/scitop/">去年的期刊分区总结</a>和<a href="http://conxz.net/2018/07/06/journalsci2017/">另一篇相关的总结</a>感兴趣。</p><p>数据来源：<a href="http://www.letpub.com.cn/index.php?page=journalapp" target="_blank" rel="noopener">http://www.letpub.com.cn/index.php?page=journalapp</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;近日，最新的中科院JCR期刊分区发布，其中关于期刊的分区和是否为Top与去年大致相同，不过还是发生了一些小的变化。比如，Nature Communications和PNAS被划分为2区期刊，其中Nature Communications不在作为Top期刊，PNAS作为2区Top期刊；Human Brain Mapping划分为2区非Top期刊。&lt;/p&gt;
&lt;p&gt;下面是脑科学（神经科学、认知神经科学和神经影像）相关同行通常会提到的期刊的最新信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/post_images/scitop.jpg&quot; alt=&quot;SCI Top 期刊&quot; title=&quot;SCI Top 期刊&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="publication" scheme="http://conxz.net/tags/publication/"/>
    
  </entry>
  
  <entry>
    <title>记第一个Shiny应用obsBrain</title>
    <link href="http://conxz.net/2018/12/27/obsBrainApp/"/>
    <id>http://conxz.net/2018/12/27/obsBrainApp/</id>
    <published>2018-12-27T20:05:11.000Z</published>
    <updated>2018-12-27T20:48:35.712Z</updated>
    
    <content type="html"><![CDATA[<p>Shiny是一项RStudio开发支持的交互式网页技术，基于此技术，可以用R语言相对轻松地实现交互式网页应用。由于其轻便、易学和交互式特点，该技术尤其适用于在学术发表的同时，交互式呈现数据科学分析结果，以方便读者更好地查看和理解研究方法和研究结果。<br>在以往自己的数据计算中，Python占了主导。不过从2016年下半年到现在的实验室之后，更多的时候采用R完成数据计算，深知其便捷性。期间对Shiny也有一些接触，不过属“点头之交”：大致晓得其基本功能，但没来得及深入学习。于是，趁着圣诞和新年假期，具体学了一下Shiny应用的实现，并结合目前的研究兴趣得到的第一个应用。<br><img src="/images/post_images/obsbrain.png" alt="obsBrain"><br><a id="more"></a><br>在这个应用中主要实现了一下几个功能：</p><ul><li>可视化人脑基因表达的空间分布</li><li>汇集和展示ENIGMA多中心合作项目在多个研究中的主要结果（并呈现其与基因表达的空间相关分析结果）</li><li>提供一个方便使用的可视化工具</li></ul><p>所有这些功能均基于FreeSurfer提供的Desikan–Killiany图谱（半脑分为34个脑区），这也是目前ENIGMA多中心合作项目使用最多的脑分割图谱。暂且将其命名为obsBrain，全称为Observatory of Brain。<br>该应用目前已发布到网络，可以通过如下链接访问:<br><a href="https://conxz.shinyapps.io/obsbrain/" target="_blank" rel="noopener">https://conxz.shinyapps.io/obsbrain/</a><br>此外，所有数据准备和具体应用实现相关代码和数据均已发布在GitHub，可以通过如下链接访问:<br><a href="https://github.com/Conxz/obsBrain" target="_blank" rel="noopener">https://github.com/Conxz/obsBrain</a></p><p>关于该应用的更多细节，可以参见README.md文件。同时欢迎感兴趣的同行联系交流（联系方式见README.md）。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Shiny是一项RStudio开发支持的交互式网页技术，基于此技术，可以用R语言相对轻松地实现交互式网页应用。由于其轻便、易学和交互式特点，该技术尤其适用于在学术发表的同时，交互式呈现数据科学分析结果，以方便读者更好地查看和理解研究方法和研究结果。&lt;br&gt;在以往自己的数据计算中，Python占了主导。不过从2016年下半年到现在的实验室之后，更多的时候采用R完成数据计算，深知其便捷性。期间对Shiny也有一些接触，不过属“点头之交”：大致晓得其基本功能，但没来得及深入学习。于是，趁着圣诞和新年假期，具体学了一下Shiny应用的实现，并结合目前的研究兴趣得到的第一个应用。&lt;br&gt;&lt;img src=&quot;/images/post_images/obsbrain.png&quot; alt=&quot;obsBrain&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="R" scheme="http://conxz.net/tags/R/"/>
    
      <category term="data science" scheme="http://conxz.net/tags/data-science/"/>
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="shiny app" scheme="http://conxz.net/tags/shiny-app/"/>
    
  </entry>
  
  <entry>
    <title>研究前沿论文先睹为快</title>
    <link href="http://conxz.net/2018/10/15/paper-preview/"/>
    <id>http://conxz.net/2018/10/15/paper-preview/</id>
    <published>2018-10-15T20:09:44.000Z</published>
    <updated>2018-11-01T22:20:37.422Z</updated>
    
    <content type="html"><![CDATA[<p>这是一个“快”时代，科学研究也不例外。以心理和脑科学研究学术发表为例，在过去几年，越来越多的研究者选择将科研论文在正式发表之前，先以预印本Preprint的形式上传到Preprint平台上。采用这方式，科研成果往往可以提前1年，甚至更长时间让领域同行公开获取，一方面加快科研成果的流通交流，促进领域发展；同时，也有利于确立研究成果的首发权。目前被领域相对认可的Preprint平台（和中国的Preprint平台）见文后列表。</p><p>笔者注意到，一些期刊开始向读者提供一项免费的“先睹为快”服务，即在作者同意的情况下，将处在审稿中Under Review的论文提供给读者公开获取。<a id="more"></a></p><p>其中一个例子为Nature Communications。Nature Communications是开放获取期刊中的佼佼者，在开放获取期刊备受争议的今天，<a href="http://conxz.net/2018/07/06/journalsci2017/">该期刊以12分左右的影响因子，独树一帜，备受追捧</a>。不过，这一期刊的不足之处是版面费贵到爆，单篇搞到5000多美刀。目前，该期刊提供一个名为“Under Consideration”论文列表服务。读者可以通过这一列表，查看目前处于该期刊审稿状态的论文信息。值得注意的是，该期刊仅提供列表和基本信息，作者如果选择这一服务，需要首先将论文上传到领域公认的Preprint平台，以便读者下载全文。感兴趣的研究者可以通过这一服务对目前处在审稿状态的论文先睹为快。该列表链接为<a href="https://nature-research-under-consideration.nature.com/" target="_blank" rel="noopener">Nature Communications Under Consideration</a></p><p>此外，Cell系列的期刊也提供了类似的服务，并命名为Cell Press Sneak Peek，名字堪称生动形象。该服务通过Preprint平台SSRN提供，并涵盖了Cell系列耳熟能详的期刊，包括Neuron，Cell，Current Biology和Cell Report等。读者可以通过该服务提前获取目前处在审稿状态的论文信息。注意，是否选择将论文加入该列表，取决于作者的选择，因此，这一列表只是部分处在审稿状态的论文。该服务的链接为<a href="https://papers.ssrn.com/sol3/Jeljour_results.cfm?form_name=journalBrowse&amp;journal_id=3184889" target="_blank" rel="noopener">Cell Press Sneak Peek</a></p><p><a href="http://preprint.space/underreview" target="_blank" rel="noopener">Preprint.Space</a>也提供了一个列表，整合了包括Sneak Peek和其他一些期刊正在Under Review的论文，包括GigaScience和PeerJ等。</p><p><strong>心理与脑科学相关领域认可的Preprint平台</strong></p><ul><li><a href="https://arxiv.org/" target="_blank" rel="noopener">arXiv</a>, <a href="https://arxiv.org/" target="_blank" rel="noopener">https://arxiv.org/</a></li><li><a href="http://www.biorxiv.org/" target="_blank" rel="noopener">bioRxiv</a>, <a href="http://www.biorxiv.org/" target="_blank" rel="noopener">http://www.biorxiv.org/</a></li><li><a href="https://psyarxiv.com/" target="_blank" rel="noopener">PsyArXiv</a>, <a href="https://psyarxiv.com/" target="_blank" rel="noopener">https://psyarxiv.com/</a></li><li><a href="https://peerj.com/preprints-search/" target="_blank" rel="noopener">PeerJ Preprints</a>, <a href="https://peerj.com/preprints-search/" target="_blank" rel="noopener">https://peerj.com/preprints-search/</a></li><li><a href="https://osf.io/preprints" target="_blank" rel="noopener">OSF Preprints</a>, <a href="https://osf.io/preprints" target="_blank" rel="noopener">https://osf.io/preprints</a></li><li><a href="https://www.preprints.org/" target="_blank" rel="noopener">Preprints</a>, <a href="https://www.preprints.org/" target="_blank" rel="noopener">https://www.preprints.org/</a></li><li><a href="https://www.ssrn.com/en/" target="_blank" rel="noopener">SSRN</a>, <a href="https://www.ssrn.com/en/" target="_blank" rel="noopener">https://www.ssrn.com/en/</a></li></ul><p><strong>中国Preprint平台</strong></p><ul><li>中国科学院科技论文预发布平台 <a href="http://chinaxiv.org/" target="_blank" rel="noopener">ChinaXiv</a>, <a href="http://chinaxiv.org/" target="_blank" rel="noopener">http://chinaxiv.org/</a></li><li>中国心理学预印本平台 <a href="http://psych.chinaxiv.org/" target="_blank" rel="noopener">PsyChinaXiv</a>, <a href="http://psych.chinaxiv.org/" target="_blank" rel="noopener">http://psych.chinaxiv.org/</a></li><li>国家科技图书文献中心 <a href="http://prep.istic.ac.cn/" target="_blank" rel="noopener">中国预印本服务系统</a>, <a href="http://prep.istic.ac.cn/" target="_blank" rel="noopener">http://prep.istic.ac.cn/</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一个“快”时代，科学研究也不例外。以心理和脑科学研究学术发表为例，在过去几年，越来越多的研究者选择将科研论文在正式发表之前，先以预印本Preprint的形式上传到Preprint平台上。采用这方式，科研成果往往可以提前1年，甚至更长时间让领域同行公开获取，一方面加快科研成果的流通交流，促进领域发展；同时，也有利于确立研究成果的首发权。目前被领域相对认可的Preprint平台（和中国的Preprint平台）见文后列表。&lt;/p&gt;
&lt;p&gt;笔者注意到，一些期刊开始向读者提供一项免费的“先睹为快”服务，即在作者同意的情况下，将处在审稿中Under Review的论文提供给读者公开获取。
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
      <category term="publication" scheme="http://conxz.net/tags/publication/"/>
    
      <category term="neuroscience" scheme="http://conxz.net/tags/neuroscience/"/>
    
  </entry>
  
  <entry>
    <title>脑科学期刊最新影响因子和中美差距</title>
    <link href="http://conxz.net/2018/07/06/journalsci2017/"/>
    <id>http://conxz.net/2018/07/06/journalsci2017/</id>
    <published>2018-07-06T21:18:59.000Z</published>
    <updated>2018-07-07T17:58:08.229Z</updated>
    
    <content type="html"><![CDATA[<p>近日，最新的学术期刊影响因子（基于2015-2017年3年的期刊文章引用数据）发布，虽然大家一再强调，要淡化影响因子在科研评估中的份量，但是<strong>每年影响因子的起伏就好像股票的跌涨，还是牵动着众多研究者的心</strong>。<br>新的影响因子系统还提供了引用贡献最多的文章排名、国家或地区排名，以及大学的排名，可以看到很多有意思的信息（比如，在科学研究方面，中国大陆发展迅猛，但中美差距还很大（巨大！）。一方面要加大科研投入，同时可能还要韬光养晦）。下面是一些脑科学相关（包括神经科学、认知神经科学和神经影像，以及一些综合期刊）期刊的最新影响因子信息。</p><ul><li><strong>Nature</strong>，最新影响因子41.577，略升。贡献最大的文章是LeCun和Hinton的文章Deep Learning，引用1336次。过去几年深度学习大火，算是意料之中。中国大陆（426）位居第4，在美国（3095）、英国和德国之后。贡献最多的大学机构有：加州大学系统、哈佛大学、霍华德休斯、MIT和斯坦福，德国马普所随其后，可见美国大学机构的优势。</li><li><strong>Science</strong>，最新影响因子41.058，增长明显。贡献最大的文章主要来自生命科学领域。文章来源和Nature类似，依次为美国（3252）、英国、德国和中国大陆（360）。前五的大学依旧是上述几所美国的大学机构。</li><li><strong>Nature Neuroscience</strong>，稳步提升，最新19.912，离20越来越近。贡献最大的文章除了single cell sequencing和transcritomics，一篇fMRI的文章名列前5：Functional connectome fingerprinting: identifying individuals using patterns of brain connectivity。稿源方面，瑞士和法国超越中国大陆（50），进入前5。美国（563）依旧远超第二的英国（99）。</li><li><strong>Neuron</strong>，最新14.318，略升。引用前5关键词Parkinson’s Disease/Aging/Autism以及Coherence和Transcriptional Differences。国家排名为美国（1133）、德国（170）、英国、瑞士和法国，中国大陆（68）在加拿大和日本之后。稿源前5为加州大学系统、霍华德休斯、哈佛、斯坦福和伦敦大学，马普系统排第8。</li><li><strong>Nature Communications</strong>，Nature旗下的OA期刊，最新影响因子12.353。引用前5没有脑影像相关文章。稿源数量中国大陆排进前5，依次为美国（5721）、中国大陆（2058）、德国、英国和法国。中科院系统仅次于美国加州大学系统和法国科学研究院。</li><li><strong>PNAS</strong>，最新9.504。引用贡献最大的文章为那篇引起众多关注的Cluster Failure。稿源排名美国（7891）、英国、德国和中国大陆（1105）。</li><li><strong>Current Biology</strong>，最新9.251。稿源前5为美国（1231）、英国、德国、法国和澳大利亚，中国位居第十（98）。</li><li><strong>Brain</strong>，最新为10.840。文章关键词Alzheimer’s disease和Parkinson’s disease。美国（433）第一，中国大陆位居瑞士（63）之后，无缘前十。</li><li><strong>PLOS Biology</strong>，最新为9.163。关于reproducibility in preclinical research讨论的文章排进前5。国家或地区排名依次为美国（429）、英国、德国、法国和加拿大，中国大陆（42）排在第8。</li><li><strong>Cerebral Cortex</strong>，最新6.308，与8分俱乐部渐行渐远。brain parcellation是重要关键词，此外，前5文章中中国研究者占据两席，分别是来自中科院自动化所蒋田仔老师课题组的Brainnetome Atlas和北师大贺永老师课题组的Alzheimer’s disease和脑网络相关研究。国家或地区排名，美国（544）、德国、英国、加拿大和中国大陆（96）。</li><li><strong>eLife</strong>，最新7.616。生命科学的文章贡献最大。国家或地区排名，美国（2293）、英国、德国、法国和中国大陆（219）。</li><li><strong>Journal of Neuroscience</strong>，最新5.970。来自隔壁大学Radboud University Nijmegen的文章Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Ventral Stream排进前5。美国排名第一2170，中国第七188，差距明显。</li></ul><p>–脑影像期刊</p><ul><li><strong>NeuroImage</strong>，最新5.426。关键词head motion，前5中有3篇文章重点关注扫描中的head motion问题。稿源排名美国（1161）第一，中国（167）第七。</li><li><strong>Human Brain Mapping</strong>，最新4.927，有所回升。关键词Mild Cognitive Impairment/Parkinson’s disease/Major Depressive disorder，以及Parcellation。国家地区排名美国（501）、德国、中国大陆（158）、英国和加拿大。依旧没有中国大陆大学机构排进前10。</li><li><strong>Brain Structure &amp; Function</strong>，最新4.231。关键词social anxiety disorder/AD/MCI/social interaction。国家地区排名，美国（266）、德国、法国、英国、西班牙和中国大陆（55）。</li><li>Cortex，最新4.907，回升。美国（229）排名第一，中国大陆在苏格兰（42）之后，没有排进前十。</li></ul><p>–综述类</p><ul><li><strong>Nature Reviews Neuroscience</strong>，32.635。关键词Alzheimer’s disease/function and dysfunction/mindfulness meditation/brain disorders/fear and anxiety。国家地区排名，美国（122）、英国和德国，中国（6）列第九，不及意大利和西班牙。</li><li><strong>Trends in Cognitive Science</strong>，15.557。关键词working memory/decision model/statistical learning/memory/mental imagery。美国（197）第一，中国大陆(less than 11）未进前十。</li><li><strong>Behavioral and Brain Science</strong>，15.071。美国（407）第一，中国大陆（小于15）未进前十。</li><li><strong>Trends in Neurosciences</strong>，11.439。美国（147）第一，中国第9，位列西班牙（9）之后。</li><li><strong>Neuroscience &amp; Biobehavioral Reviews</strong>，8.037。美国（302）第一，中国大陆（52）第8，位居意大利之后。</li><li><strong>National Science Review</strong>，9.408。中国大陆（209）第一，其次为美国（68），澳大利亚、德国和英国。贡献最多的院校机构为中科院系统、北大、清华和中科大。</li><li>Annual Review of Neuroscience，14.675。Marcus Raichle牛的The Brain’s Default Mode Network荣登榜首。美国（54）第一，中国大陆（1）第九。</li><li>Progress in Neurobiology，最新14.162。美国（77）第一，中国大陆（17）第五。</li><li>Current Opinion in Neurobiology，最新6.541。美国（282）第一，中国大陆（小于11）未进前十。</li><li>Neuroscientist，7.461。美国（71）第一，中国大陆（10）第5，位居意大利之后。</li></ul><p>– 精神疾病期刊</p><ul><li><strong>JAMA Psychiatry</strong>，16.642。美国（512）第一，中国大陆（19）和西班牙、意大利并列第十。</li><li><strong>Molecular Psychiatry</strong>，11.640。两篇来自ENIGMA的paper位列前5。美国（394）第一，中国（45）第九。</li><li><strong>Biological Psychiatry</strong>，11.982。美国（2101）第一，中国大陆（66）第九。</li><li><strong>Lancet Psychiatry</strong>，最新15.233。美国（331）第一，中国大陆（less than 23）未进前十。</li><li>Molecular Neurodegeneration，6.426。前五为美国（125）、中国大陆（41）、英国/德国、西班牙。</li><li>Neuropsychopharmacology，6.544。关键词Stress/Anxiety/Depression/Social deficits/Autism。美国（2377）第一，中国大陆（40）第九。</li><li>PLoS Genetics，5.540。国家地区排名，美国（1244）、英国、德国、中国大陆（217）和法国。</li><li>Neuropharmacology，4.249。美国（545）第一，中国（150）第二。</li></ul><p>– 心理学相关</p><ul><li>Annual Review of Psychology，22.774。Olaf Sporns的Modualr Brain Networks位列第四。国家地区排名，美国（69）第一，中国大陆（1）第九。</li><li>Psychological Bulletin，13.250。美国（88）第一，中国大陆（小于4）未进前十。</li><li>Annual Review of Clinical Psychology，13.278。美国（51）第一，中国大陆（小于1）未进前十。</li><li>Psychological Review，7.230。美国（68）第一，中国大陆（小于4）未进前十。</li><li>Psychological Science，6.128。美国（385）第一，中国大陆（18）和苏格兰并列第八。</li></ul><p>– <strong>新晋期刊</strong></p><ul><li><strong>Science Advances 第一个影响因子 11.511。美国（904）第一，中国大陆（252）位居第二</strong>。</li></ul><p>– 其他期刊：</p><ul><li>Neuroscience Bulletin，3.155。中国（215）第一，美国（41）第二。</li><li>PeerJ，一个新的OA综合期刊。自2014年有影响因子以来，其影响因子一直维持在2.1+，5年影响因子有上升趋势，从最初的2.112升到今年的2.469。文章来源主要是USA（1,135），远超第二名的China Mainland（486）和第三的England（375）。</li><li>NeuroReport，一个有历史的神经科学期刊，影响因子一直不高，最新为1.266，投稿相对容易。稿源主要是China Mainland（261），其次是USA、Japan和South Koren。China Mainland大学中文章贡献最多的西安交通大学XI’AN JIAOTONG UNIVERSITY和重庆医科大学CHONGQING MEDICAL UNIVERSITY，北师大、浙大和中科院系统紧随其后。</li></ul><p><strong>中国大陆在个别期刊的贡献赶上并超越美国，而其中除国产牛刊National Science Review外，其他多为网上为人诟病的“水刊”，值得国人深思。</strong></p><ul><li>National Science Review，9.408。国产期刊！中国大陆（209）第一，其次为美国（68），澳大利亚、德国和英国。贡献最多的院校机构为中科院系统、北大、清华和中科大。</li><li><em>Scientific Reports</em>，4.122。中国大陆（19,861）第一，美国（14,610）第二。稿源主要来自中科院系统、上海交通大学、浙大和北大。</li><li><em>PLos ONE</em>，2.766。美国（20,935）第一，中国大陆（12,321）第二。稿源主要来自中科院系统。</li><li><em>Medicine</em>，2.028。中国大陆（4510）第一，随后为韩国（1073），台湾（1061）和美国（707）。稿源前十有四川大学、中国医学科学院、首都医科大学、浙大和中山大学（以及几所台湾的单位）。</li><li><em>Oncology Letters</em>，1.664。中国大陆（3232）第一，随后为日本（502）、美国（187）和韩国（162）。稿源前十院校是山东大学、浙大、吉林大学、郑州大学、上海交通大学、首都医科大学、中南大学、中山大学、复旦大学和四川大学。</li><li>Oncology Research，3.143。中国大陆第一（257），美国第二（13），日本第三（9）。稿源前十院校是西安交通大学、吉林大学、郑州大学、中南大学、河南大学、南京医科大学、第四军医大学、河北大学、哈尔滨医科大学、西安医科大学、中山大学和华南医科大学。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;近日，最新的学术期刊影响因子（基于2015-2017年3年的期刊文章引用数据）发布，虽然大家一再强调，要淡化影响因子在科研评估中的份量，但是&lt;strong&gt;每年影响因子的起伏就好像股票的跌涨，还是牵动着众多研究者的心&lt;/strong&gt;。&lt;br&gt;新的影响因子系统还提供了引用贡
      
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>多中心合作与脑科学研究 由最近一篇文章想到的</title>
    <link href="http://conxz.net/2018/05/19/collaborative-team-research/"/>
    <id>http://conxz.net/2018/05/19/collaborative-team-research/</id>
    <published>2018-05-19T09:46:00.000Z</published>
    <updated>2018-05-19T11:27:54.282Z</updated>
    
    <content type="html"><![CDATA[<p>按照惯例，先放上论文的信息，方便查阅，也请多多指教。<br>Kong, X., Mathias, S. R., Guadalupe, T., ENIGMA Laterality Working Group, Glahn, D. C., Franke, B., Crivello, F., Tzourio-Mazoyer, N., Fisher, S. E., Thompson, P. M., &amp; Francks, C. (2018). Mapping Cortical Brain Asymmetry in 17,141 Healthy Individuals Worldwide via the ENIGMA Consortium. Proceedings of the National Academy of Sciences of the United States of America. Advance online publication. <a href="https://doi.org/10.1073/pnas.1718418115" target="_blank" rel="noopener">doi:10.1073/pnas.1718418115</a></p><p><img src="/images/post_images/pnassites.jpg" alt="脑皮层偏侧化研究中的多中心"><br><a id="more"></a><br>论文主要通过多中心合作的研究模式，汇集了来自全球99个数据集的17000+个健康脑结构影像数据，以刻画人脑结构的不对称性；文中同时考察了这种不对称性的个体差异，以及这种个体差异与年龄、性别、利手，以及遗传因素之间的关联。文中具体描述了一些有意思的发现，可能对今后关于脑功能偏侧化和脑结构不对称性之间关联，以及脑不对性的遗传基础等研究可以提供一些有用的信息；同时，这一研究提供了一个健康样本在群体水平的脑结构偏侧化模式，对于今后脑疾病相关研究可以提供参考信息。</p><p>很高兴这篇论文最近被PNAS接收，从去年十月底投稿，到半月前接收，差不多正好是6个月的时间。审稿过程相对顺利，中间对文章可能存在的问题做了一些补充和回复，非常感激编辑和5位审稿人对文章的欣赏和认可。这里不好透露审稿意见原文，这里仅提及一点，即，<strong>多中心合作的研究模式</strong>。</p><p><img src="/images/post_images/multisites.jpg" alt="多中心合作"></p><p>说到<strong>多中心合作</strong>，我觉得不得不提及最近总会被提及的<strong>可重复性问题</strong>。关于可重复性问题，个人认为这一问题的根本原因并不是伪造数据，选择性报告结果或p-hacking（虽然这种现象真的存在，但不是主流）。更根本的原因应该是样本量与真实效应量之间的不对等，即研究问题的真实效应量往往很小，在小样本量的研究中得到的（统计显著的）结果往往是对效应量的高估，甚至假阳性；归结到一个词，就是统计效力（statistical power）问题。以常用的效应量Cohen’s d为例，在两组样本真实差异的效应量为0.3时，两组样本的分布有接近90%的重合，可以想象在这种情况下，如果仅从每一组中抽取少量的样本，得到的组间差异会呈现怎样一副图景（关于效应量的解释，推荐这个网页工具<a href="http://rpsychologist.com/d3/cohend/" target="_blank" rel="noopener">Interpreting Cohen’s d effect size</a>）。</p><p><strong>多中心合作</strong>的研究模式可能有以下几点优势：</p><ul><li>在单个中心资源有限的情况下，针对特定研究问题可以有更大的样本量</li><li>可以更稳定更全面的考察感兴趣效应，以及这一效应在不同数据集之间的变异</li><li>数据互通有无，充分利用资源：比如，可能有些数据A实验室有，但是A实验室并不感兴趣，但是这些数据可能对B实验室的研究问题极为重要</li><li>研究方法互通有无，使研究更全面：比如，B实验室可以提供A实验室目前并不熟悉的分析方法，可以让数据分析更全面</li><li>结果讨论相互补充，使讨论更深入：比如，B实验室可能从A实验室不熟悉的视角提供对结果的不同解读</li></ul><p>这里仅列举几例，多中心合作的优势绝不止这几点。当然多中心合作也存在一些潜在的问题和约束，比如数据质量控制问题，比如数据共享中的隐私保护问题，比如数据分享中的约束可能导致的特定研究无法深入的问题，等等。个人认为这些问题基本都可以通过人为努力尽量避免，即使特定情况下无法避免，基于大样本的多中心合作的研究结果也是对现有研究模式的强有力的补充。</p><p>最近在思考基于中国的资源成立类似多中心合作的联盟的可能性（比如以“<strong>脑与个体差异</strong>”为主题），也和几位同行做了一些交流，总体是可行的（文后附了国内现有的多中心合作项目）。大致模式可以如下：</p><ul><li>单个中心不需要事先共享数据，仅需要提供自己已经采集的数据，测量和样本信息，比如脑影像数据模态、行为测量等</li><li>研究者提出研究问题，并明确需要的测量和数据要求，比如脑影像数据测量指标和行为测量名称</li><li>其他研究者采用自愿加入模式，对感兴趣的研究问题自愿选择是否加入研究项目</li><li>各个中心定期更新自有数据的信息</li><li>成果署名采用国际惯例，主要研究者决定第一作者，通讯作者和资深作者，其他所有贡献者作为共同作者（根据贡献大小或姓氏拼音排名）</li><li>平台起初仅限内部共享，组织内部共享信息</li><li>项目初期可以以邮件列表的形式开展，通过收集研究想法和数据需求–&gt;发布信息到邮件列表中各研究者–&gt;研究者直接联系并参与项目–&gt;文章写作和发表等流程实现；当然如果能有基金支持，可以形成一个去中心化的网络合作平台</li></ul><p>欢迎感兴趣的同行一起交流学习。</p><hr><p>附：目前我所知的国内的多中心合作研究，欢迎补充。</p><ul><li>中科院心理所（左西年老师）、北师大、杭州师大、中科院自动化所、南京大学、首都医科大学等和国外机构合作的关于脑功能连接组的重测数据集<br>Zuo, Xi-Nian, et al. “An open science resource for establishing reliability and reproducibility in functional connectomics.” Scientific data 1 (2014): 140049.</li><li>复旦大学（冯建峰老师）、西南大学（邱江老师）和国外大学合作的关于抑郁症脑功能异常的研究<br>Cheng, Wei, et al. “Medial reward and lateral non-reward orbitofrontal cortex circuits change in opposite directions in depression.” Brain 139.12 (2016): 3296-3309.</li><li>中科院心理所（严超赣老师）、国内多所大学（或附属医院）和国外研究机构合作的关于抑郁症静息态功能磁共振的多中心研究<br>Yan, Chao-Gan, et al. “Reduced but not Enhanced Default Mode Network Functional Connectivity in Major Depressive Disorder: Evidence from 25 Cohorts in the REST-meta-MDD Project.” bioRxiv (2018): 321745.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;按照惯例，先放上论文的信息，方便查阅，也请多多指教。&lt;br&gt;Kong, X., Mathias, S. R., Guadalupe, T., ENIGMA Laterality Working Group, Glahn, D. C., Franke, B., Crivello, F., Tzourio-Mazoyer, N., Fisher, S. E., Thompson, P. M., &amp;amp; Francks, C. (2018). Mapping Cortical Brain Asymmetry in 17,141 Healthy Individuals Worldwide via the ENIGMA Consortium. Proceedings of the National Academy of Sciences of the United States of America. Advance online publication. &lt;a href=&quot;https://doi.org/10.1073/pnas.1718418115&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;doi:10.1073/pnas.1718418115&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/post_images/pnassites.jpg&quot; alt=&quot;脑皮层偏侧化研究中的多中心&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="collaborative team research" scheme="http://conxz.net/tags/collaborative-team-research/"/>
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>学术发表用高质量图片保存</title>
    <link href="http://conxz.net/2018/03/15/figures-for-publication/"/>
    <id>http://conxz.net/2018/03/15/figures-for-publication/</id>
    <published>2018-03-15T21:30:59.000Z</published>
    <updated>2018-03-15T21:54:38.483Z</updated>
    
    <content type="html"><![CDATA[<p>在学术论文发表中，不同期刊对图片质量的要求通常有所差异，比如，并不是每个期刊对图片质量的要求都是300ppi。在学术写作中，关于如何保存高质量图片有一些小trick，写在这里方便查询。</p><p>准备工作：</p><ul><li><strong>期刊对分辨率的要求</strong>：一般情况下300ppi可以满足出版要求，不同期刊针对不同类型的要求有所不同。通常对统计作图的线条或柱状图的要求高一些（比如1000ppi），对图片要求低一些（比如300ppi或600ppi）。</li><li><strong>字体大小</strong>：字体不要太小，一般要求图中字体不能小于6点（point或pt）。72 点等于 1英寸，1 point 约等于0.353 mm，6ponit不到2.12mm。</li><li><strong>图片格式</strong>：通常期刊接受TIFF文件，这个可以通过PPT直接导出（注意设置ppi），或者R直接保存（注意ppi），或者从Photoshop或Illustrator导出（同样需要注意ppi的设置）。更推荐的方式是直接保存矢量图，比如采用R保存svg或pdf，或Illustrator保存pdf或eps。</li><li><strong>图片尺寸</strong>：在准备图片时，需要注意图片出版时的大小。有些期刊对图片的尺寸要求不严，但是有一些期刊由于涉及到排版问题，对图片要求相对严一些。通常学术论文采用双栏排版，图片可以是单栏（9cm），一栏半（14cm），或两栏（19cm）（图一）。因此考虑到排版需要，期刊对图片的宽度有特定要求，比如PNAS要求1栏图片的宽度为8.7cm，1.5栏图片的宽度为11.4cm，而2栏图片的宽度为17.8cm。</li></ul><p><img src="/images/post_images/scifig.png" alt="论文图片尺寸"></p><p><strong>推荐参数：TIFF图片分辨率600ppi（统计图1000ppi），或直接保存矢量图（比如pdf格式） + 图片宽度8.7/11.4/17.8cm + 最小字号6-8</strong></p><hr><p><strong>R/RStudio:</strong><br>保存TIFF格式图片</p><p><code>tiff(file = &quot;C:/test1.tiff&quot;, res = 600, width = 11.4, height = 15, units=&#39;cm&#39;, compression = &quot;lzw&quot;)</code><br><code>plot(1:22, pch = 1:22, cex = 1:3, col = 1:5)</code><br><code>dev.off()</code></p><p>保存PDF格式</p><p><code>pdf(fig_file, width = 11.4, height = 15, pointsize = 8)</code><br><code>plot(1:22, pch = 1:22, cex = 1:3, col = 1:5)</code><br><code>dev.off()</code></p><hr><p><strong>Illustrator：</strong><br>设置图片尺寸：File &gt; New…，根据需要设置宽度Width，注意单位Units<br>设置导出非矢量图时的分辨率：Effect &gt; Document Raster Effect Settings，Color Mode选RGB，Resolution根据需要设定。<br>导出TIFF：File &gt; Export…， 选择TIFF格式保存。<br>保存PDF或EPS：File &gt; Save As…，选择相应格式并保存。<br>其他：<br>如果发现图片边框空白太多，可以采用Illustrator截取多余的部分：File &gt; Document Setup …，点击Edit Artboards，然后可以通过拖拽虚线方框设定感兴趣的区域。</p><hr><p><strong>PPT + Photoshop：</strong><br>此法不推荐，虽然是我之前最常用的作图方法。<br>PPT导出TIFF图片（注意保存前，需要通过File &gt; Options &gt; Advanced &gt; Image Size and Quality设置导出图片的分辨率为330ppi，并勾选‘Do not compress image in file’）<br>此后，在Photoshop中打开图片，然后Image &gt; Image Size…，设置Document Size下的Width和Resolution到相当的参数（可选项：取消勾选‘Resample Image’）。<br>最后保存图片为TIFF格式。</p><hr><p><strong>PPT + Illustrator：</strong><br>采用PPT设计图片排版，之后将各元素一起复制粘贴到Illustrator。同样注意，在ppt中设计排版之前，设置Slide Size为相应的尺寸（Design &gt; Slide Size &gt; Custom Slide Size…）。之后的操作在Illustrator中完成。</p><p>当然，所有排版、设置和保存等步骤都可以在Photoshop或Illustrator中完成。</p><p>ps：关于修改图片分辨率，这个漫画的右上角是现实。<br><a href="http://www.phdcomics.com/comics/archive/phd040609s.gif" target="_blank" rel="noopener">http://www.phdcomics.com/comics/archive/phd040609s.gif</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在学术论文发表中，不同期刊对图片质量的要求通常有所差异，比如，并不是每个期刊对图片质量的要求都是300ppi。在学术写作中，关于如何保存高质量图片有一些小trick，写在这里方便查询。&lt;/p&gt;
&lt;p&gt;准备工作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;期刊对分辨率的要求&lt;
      
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="paper" scheme="http://conxz.net/tags/paper/"/>
    
      <category term="publication" scheme="http://conxz.net/tags/publication/"/>
    
  </entry>
  
  <entry>
    <title>Retreat是什么会议？</title>
    <link href="http://conxz.net/2018/03/08/whatisretreat/"/>
    <id>http://conxz.net/2018/03/08/whatisretreat/</id>
    <published>2018-03-08T22:32:48.000Z</published>
    <updated>2018-03-08T23:01:03.826Z</updated>
    
    <content type="html"><![CDATA[<p>计划5月中旬去New York参加Society of Biological Psychiatry（SOBP）的Annual Meeting。以往主要关注像OHBM这种脑影像相关的国际会议，这是第一次参加这个生物精神病学的会议。今年SOBP Annual Meeting的主题是“Biomarkers, Biomodels, and Psychiatric Disorders”。在此期间，ENIGMA在New York计划组织了一次小型会议，命名为ENIGMA Annual Retreat，因此，最近也在收集参会人的信息。这里涉及到一个生词<strong>Retreat</strong>（我词汇量也有限），于是心生疑问，这个Retreat和Meeting/Conference有什么区别？</p><p>于是乎搜了一些信息，这里有个<a href="http://blog.sina.com.cn/s/blog_4bc09c100100mmna.html" target="_blank" rel="noopener">博客</a>很系统收集了几种常用的会议相关的词的用法，包括Meeting、Conference、Symposium、Congress、Convention、Forum、Lecture、Seminar、Workshop、Colloquium、Panel Discussion和Assembly等。这里涉及到上面提到的SOBP和OHBM用的Annual Meeting，即“年会”。另一个词是Colloquium（座谈会或专题报告），我认识这个词源自现在单位的不定期活动<a href="http://www.mpi.nl/events/copy_of_mpi-colloquium-series" target="_blank" rel="noopener">MPI Colloquium</a>，是Seminar（研讨会或者学术讨论）的一种正式的说法。Panel Discussion是围绕具体问题的现场“小组讨论”或“座谈”。</p><p>根据搜到的一些资料看(比如<a href="https://ministryservingministry.com/2013/12/12/retreat-or-conference-that-is-the-question/" target="_blank" rel="noopener">这篇</a>)，Retreat和Conference是不同的，不过有时候还是会出现混用。可能主要的区别在于，Retreat源于宗教场合，意为闭关，静修，用在会议上包含了这个词本身包含的休息、放松的意思，一般指非正式会议；而Conference则仅是围绕特定主题的会议，期间并没有过多可以休息的时间。同时Retreat似乎是小范围的类似会员聚会。如此看，Retreat更适用那种特定组织，以学术交流为主题，同时兼顾放松、休闲的集会活动。如此想来，倒也确实适合借助其他Annual Meeting之便，将参会的部分成员召集在一起，兼顾学术和放松的Annual Retreat活动。</p><p>中文有“务虚会议”这个词，感觉不太直观；也有新闻报道中直接用Retreat会议或非正式会议；结合这种会议的范围，可能翻译成“<strong>闭门会议</strong>”可能更合适。</p><p><img src="/images/post_images/retreat.jpg" alt="Retreat"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;计划5月中旬去New York参加Society of Biological Psychiatry（SOBP）的Annual Meeting。以往主要关注像OHBM这种脑影像相关的国际会议，这是第一次参加这个生物精神病学的会议。今年SOBP Annual Meeting的主
      
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="conference" scheme="http://conxz.net/tags/conference/"/>
    
  </entry>
  
  <entry>
    <title>unzip解压压缩包中指定的文件</title>
    <link href="http://conxz.net/2017/12/13/unzip/"/>
    <id>http://conxz.net/2017/12/13/unzip/</id>
    <published>2017-12-13T06:14:26.000Z</published>
    <updated>2018-03-08T22:43:18.291Z</updated>
    
    <content type="html"><![CDATA[<p>近年来，开放科学Open Science在学术圈得到越来越多的关注。在开放数据方面，研究者开始接受将采集的数据在线共享，同时越来越多的研究者开始基于在线共享的数据开展研究。</p><p>研究者通常以压缩包的形式将数据上传到网络。而在其他研究使用公开共享的数据开展研究时，由于通常情况下，该数据并非为其设计和采集，数据使用者需要将所有数据下载，并解压所有数据文件。有些时候（比如，用个人的笔记本下10几G的HCP数据），下载的压缩包本身就很大，如果全部解压，将会占用更多硬盘空间（然而，我硬盘空间不够解压所有数据了。。）。碰到这个问题，解决方案可以是将数据copy到另一台电脑或服务器，全部解压后，挑选需要的数据；另一个方案可以考虑选择性的解压一些需要的文件。本文就是笔者在使用HCP数据时，由于碰到Mac空间有限的问题，找到的解决方案。</p><p>以HCP1200的处理好的数据为例，HCP1200_Parcellation_Timeseries_Netmats.zip大概有13G，如果全部解压出来需要差不多相当的空间。而笔者只感兴趣其中的几个文件，于是想到应该有一种解压感兴趣文件的解决方案，比如称为“基于感兴趣文件的解压” FOI（Files of Interest）-based Unzip 哈哈。</p><ul><li><p>通过下面一条命令可以查看压缩文件中的目录结构，但不做实际解压。这样可以从结果中挑选兴趣的文件。<br><code>unzip -v HCP1200_Parcellation_Timeseries_Netmats.zip</code></p></li><li><p>通过下面一条命令解压指定的文件。比如，这里我们感兴趣与scripts.tar.gz这个文件。<br><code>unzip HCP1200_Parcellation_Timeseries_Netmats.zip “HCP_PTN1200/scripts.tar.gz”</code></p></li><li><p>如果感兴趣于多个文件，可以重复2中的命令。此外，如果只是对其中的某个/些文件不敢兴趣，可以采用-x参数，以在解压时排除指定文件(们)。<br><code>unzip -x file1 file2 file2 HCP1200_Parcellation_Timeseries_Netmats.zip</code></p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;近年来，开放科学Open Science在学术圈得到越来越多的关注。在开放数据方面，研究者开始接受将采集的数据在线共享，同时越来越多的研究者开始基于在线共享的数据开展研究。&lt;/p&gt;
&lt;p&gt;研究者通常以压缩包的形式将数据上传到网络。而在其他研究使用公开共享的数据开展研究时，由
      
    
    </summary>
    
      <category term="Tools" scheme="http://conxz.net/categories/Tools/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="data sharing" scheme="http://conxz.net/tags/data-sharing/"/>
    
  </entry>
  
  <entry>
    <title>脑科学相关SCI Top期刊_2017</title>
    <link href="http://conxz.net/2017/11/08/scitop/"/>
    <id>http://conxz.net/2017/11/08/scitop/</id>
    <published>2017-11-08T06:14:11.000Z</published>
    <updated>2018-03-08T22:41:15.364Z</updated>
    
    <content type="html"><![CDATA[<p>在学术成果评价中，经常会提及SCI Top期刊。SCI Top是中国科学院文献情报中心发布的中科院期刊分区中的一些排名靠前的期刊，紧随其后的期刊一般标签为SCI2，SCI3和SCI4区期刊。所谓SCI Top实际上是包括了SCI1区的期刊和部分SCI2区的期刊，其中SCI1区大致定义为领域排名前5%的期刊。由于一些领域期刊数量有限，导致SCI1区期刊屈指可数，导致SCI1区在实际的学术成果评价中可用性不大；可能是出于这一原因，中科院期刊分区单独定义了SCI Top期刊，以涵盖更多领域认可的期刊。</p><p><img src="/images/post_images/scitop.jpg" alt="SCI Top 期刊" title="SCI Top 期刊"></p><p>近期2016年版（2017最新版）中科院期刊分区正式发布，笔者注意到SCI Top期刊列表变化有些大，新加了一些期刊。下面是查询到的常见的脑科学（神经科学、认知神经科学和神经影像，以及一些高影响的综合期刊）相关的SCI Top期刊列表（欢迎在下方评论中补充）。</p><h3 id="期刊名称-影响因子-Top期刊"><a href="#期刊名称-影响因子-Top期刊" class="headerlink" title="期刊名称 影响因子 Top期刊"></a>期刊名称 影响因子 Top期刊</h3><p>Nature 40.137 是<br>Science 37.205 是</p><p>Nature Neuroscience 17.839 是<br>Neuron 14.024 是</p><p>Nature Communications 12.124 是<br>PNAS 9.661 是<br>Current Biology 8.851 是<br>Brain 10.292 是<br>PLOS Biology 9.797 是</p><p>Cerebral Cortex 6.559 是<br>eLife 7.725 是<br>Journal of Neuroscience 5.988 是</p><p>NeuroImage 5.835 是<br>Human Brain Mapping 4.530 是<br>Brain Structure &amp; Function 4.698 是<br>Cortex 4.279 是</p><p>Nature Review Neuroscience 28.880 是<br>Trends in Cognitive Science 15.402 是<br>Behavioral and Brain Science 14.200 是<br>Trends in Neurosciences 11.124 是<br>Neuroscience &amp; Biobehavioral Reviews 8.299 是<br>Neuroscientists 7.391 是</p><p>JAMA Psychiatry 15.307 是<br>Molecular Psychiatry 13.204 是<br>Biological Psychiatry 11.412 是<br>Lancet Psychiatry 11.588 是<br>Molecular Neurodegeneration 6.780 是<br>Neuropsychopharmacology 6.403 是</p><p>National Science Review 8.843 是<br>Annual Review of Neuroscience 15.630 是<br>Progress in Neurobiology 13.217 是</p><p>Current Opinion in Neurobiology 6.133 是<br>PLoS Genetics 6.100 是<br>Neuropharmacology 5.012 是</p><p>Annual Review of Psychology 19.950 是<br>Psychological Bulletin 16.793 是<br>Annual Review of Clinical Psychology 12.136 是<br>Psychological Review 7.638 是</p><p>Diabetes Care 11.857 是<br>Stroke 6.032 是<br>Pain 5.445 是<br>Sleep Medicine Reviews 8.958 是</p><p>此外，Psychological Science是很好的期刊，影响因子5.667，由于只属SSCI期刊，并不在中科院分区范围。</p><p>数据来源：<a href="http://www.letpub.com.cn/index.php?page=journalapp" target="_blank" rel="noopener">http://www.letpub.com.cn/index.php?page=journalapp</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在学术成果评价中，经常会提及SCI Top期刊。SCI Top是中国科学院文献情报中心发布的中科院期刊分区中的一些排名靠前的期刊，紧随其后的期刊一般标签为SCI2，SCI3和SCI4区期刊。所谓SCI Top实际上是包括了SCI1区的期刊和部分SCI2区的期刊，其中SCI1
      
    
    </summary>
    
      <category term="OpenScience" scheme="http://conxz.net/categories/OpenScience/"/>
    
    
      <category term="open science" scheme="http://conxz.net/tags/open-science/"/>
    
      <category term="publication" scheme="http://conxz.net/tags/publication/"/>
    
  </entry>
  
  <entry>
    <title>Look Back：颞平面不对称性 Planum Temporale Asymmetry</title>
    <link href="http://conxz.net/2017/10/22/planum-temporale-asymmetry/"/>
    <id>http://conxz.net/2017/10/22/planum-temporale-asymmetry/</id>
    <published>2017-10-22T05:13:55.000Z</published>
    <updated>2018-01-24T06:59:51.000Z</updated>
    
    <content type="html"><![CDATA[<p>颞平面（planum temporale）是位于颞上回（superior temporal gyrus）后部背侧皮层的一个三角形区域，其左侧脑区与经典的语言功能区Wernicke’s area存在一定的重合。一直以来，颞平面被认为是人脑皮层中结构偏侧化最明显的脑区。同时，由于广泛存在的言语和语言网络的左偏侧化，颞平面的偏侧化更被研究者与人类独特的语言能力相关联。</p><p>关于颞平面偏侧化的早起实证研究可以追溯到Geschwind和Levitsky于1968年发表在Science上的一篇短文（甚至更早）。该研究首次基于多达100个成人脑postmortem样本，揭示了颞平面在脑结构上的不对称性。具体而言，研究者首先基于脑的地标Landmark信息手动识别出每个脑的颞平面边界（如图）；统计发现，在65%的样本中，左侧颞平面大于右侧；而右侧颞平面大于左侧的只占11%。此外，左侧颞平面平均比右侧长约1/3。</p><p><img src="/images/post_images/tp_asym.png" alt="颞平面不对称性" title="颞平面不对称性"></p><p>最后，作者提到，在类人猿Anthropoid apes相应的脑区，研究者并未发现这一偏侧化。这一对比表明，颞平面偏侧化的出现，可能与人类进化，以及语言的产生存在密切关联，同时，颞平面偏侧化可能受到一些特定基因的调控。</p><p>参考文献<br>Geschwind, N., &amp; Levitsky, W. (1968). Human brain: left-right asymmetries in temporal speech region. Science, 161(3837), 186-187.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;颞平面（planum temporale）是位于颞上回（superior temporal gyrus）后部背侧皮层的一个三角形区域，其左侧脑区与经典的语言功能区Wernicke’s area存在一定的重合。一直以来，颞平面被认为是人脑皮层中结构偏侧化最明显的脑区。同时，由
      
    
    </summary>
    
      <category term="BrainResearch" scheme="http://conxz.net/categories/BrainResearch/"/>
    
    
      <category term="brain asymmetry" scheme="http://conxz.net/tags/brain-asymmetry/"/>
    
  </entry>
  
</feed>
