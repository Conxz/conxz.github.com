<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Kong Brain Observatory"><title>小孔成像 | Kong Brain Observatory</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-26255736-1','auto');ga('send','pageview');
</script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">小孔成像</h1><a id="logo" href="/.">小孔成像</a><p class="description">Kong Brain Observatory</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/news/"><i class="fa fa-twitter"> News &amp; Events</i></a><a href="/collection/"><i class="fa fa-cloud"> Collection</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/2017/06/20/personally-identifiable-brain/">Structural and functional MRI brain scans of (young) ME</a></h1><div class="post-meta">2017-06-20</div><a class="disqus-comment-count" data-disqus-identifier="2017/06/20/personally-identifiable-brain/" href="/2017/06/20/personally-identifiable-brain/#disqus_thread"></a><div class="post-content"><p>It has been a long time since I planed to share the imaging data of my own brain. The idea is inspired by Poldrack’s <a href="http://myconnectome.org/wp/" target="_blank" rel="noopener">MyConnectome</a> project. As a neuroscientist, we usually scan our own brains. Although each single dataset is much smaller (compared to MyConnetome), many a little make a mickle. If these datasets are collected and shared, it would be a unique resource for better understanding of human brain, in particular of the neuroscientists’ brain and their academic life (as well as many other individual differences).</p></div><p class="readmore"><a href="/2017/06/20/personally-identifiable-brain/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/05/04/hippocampus-and-seahorse/">海马之所以叫海马</a></h1><div class="post-meta">2017-05-04</div><a class="disqus-comment-count" data-disqus-identifier="2017/05/04/hippocampus-and-seahorse/" href="/2017/05/04/hippocampus-and-seahorse/#disqus_thread"></a><div class="post-content"><p>海马（Hippocampus）是人脑中的重要结构，在大脑两侧各有一个，位于颞叶内侧区域。研究表明，海马主要负责学习与记忆，比如短时记忆信息的巩固和空间导航中的空间记忆等，因此，该脑结构的损伤会导致短时记忆缺失和迷失方向等症状，与阿尔兹海默症（Alzheimer’s disease）之间存在密切关联。<br><img src="/images/post_images/400px-Hippocampus_and_seahorse_cropped.JPG" alt="Hippocampus and seahorse"><br>那么，为什么人脑中一个重要结构为什么叫“海马”呢？</div><p class="readmore"><a href="/2017/05/04/hippocampus-and-seahorse/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/04/01/parcellation-display-freesurfer/">Parcellation display with the same color using freesurfer</a></h1><div class="post-meta">2017-04-01</div><a class="disqus-comment-count" data-disqus-identifier="2017/04/01/parcellation-display-freesurfer/" href="/2017/04/01/parcellation-display-freesurfer/#disqus_thread"></a><div class="post-content"><p>Two methods for displaying ROI analysis results with brain parcellation in FreeSurfer. </p>
<ol>
<li><p>Solution #1 using R. The R code can be found <a href="https://github.com/Conxz/vis/blob/master/CreateFSLUT.r" target="_blank" rel="noopener">HERE</a>. After running the code, a configration file (like <a href="https://github.com/Conxz/vis/blob/master/lh-Area-ColorLUT.txt" target="_blank" rel="noopener">THIS</a>) can be obtained. Then, by following the instructions at the end of the R code, you can have the display with tksurfer.<br><img src="/images/post_images/vis_fig_r_lateral.png" alt="surf vis 1" title="vis1"></p></div><p class="readmore"><a href="/2017/04/01/parcellation-display-freesurfer/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/02/08/WGCNA-Background/">WGCNA Background</a></h1><div class="post-meta">2017-02-08</div><a class="disqus-comment-count" data-disqus-identifier="2017/02/08/WGCNA-Background/" href="/2017/02/08/WGCNA-Background/#disqus_thread"></a><div class="post-content"><p>WGCNA是Weighted Gene Co-expression Network Analysis的简称，其从网络连接的角度出发，考查基因之间的交互。该方法的提出背景是通过微阵列（microarray）实验可以获取的信息远多于仅得到一组差异表达的基因（differentially expressed genes）。基于微阵列microarray数据，我们可以通过计算基因表达模式（gene expression profiles）之间的相关来考查不同基因之间的交互。采用WGCNA方法，可以从数千基因的表达水平数据中识别可能具有临床价值的基因模块（gene modules），并最终采用模块内连接（intramodular connectivity）和基因-特质相关（gene significance）来发现某些疾病通路的关键基因，用于进一步验证。</p></div><p class="readmore"><a href="/2017/02/08/WGCNA-Background/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2017/01/21/3D-print-your-brain/">3D Print Your Brain from MRI</a></h1><div class="post-meta">2017-01-21</div><a class="disqus-comment-count" data-disqus-identifier="2017/01/21/3D-print-your-brain/" href="/2017/01/21/3D-print-your-brain/#disqus_thread"></a><div class="post-content"><p>Do you think it would be cool to have a 3D printed brain of yourself? With standard anatomical MRI scanning and some 3D surface reconstraction methods, you can make it. Here are some useful links for making this dream come true.</p></div><p class="readmore"><a href="/2017/01/21/3D-print-your-brain/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2016/11/17/An-Excel-problem-in-scatter-plot-and-solutions/">An Excel problem in scatter plot and solutions</a></h1><div class="post-meta">2016-11-17</div><a class="disqus-comment-count" data-disqus-identifier="2016/11/17/An-Excel-problem-in-scatter-plot-and-solutions/" href="/2016/11/17/An-Excel-problem-in-scatter-plot-and-solutions/#disqus_thread"></a><div class="post-content"><p>Can you imagine using Excel without plot or formulas? Recently I came this kind of problem when using the Excel 2016 on my office PC: Excel functions like SUM() did not work, and I could not get any plot as expected. A bunch of questions flash across my mind. Is it a bug of the new version of Excel? Is my Excel corrupt or is this due to some malicious virus? This might also be caused by the different language using in the system. After a few days’ worry and search, here is the solutions to the problem I had, which might be helpful for others. </p></div><p class="readmore"><a href="/2016/11/17/An-Excel-problem-in-scatter-plot-and-solutions/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2016/09/21/switching-from-octopress-to-hexo/">Switching from Octopress to Hexo</a></h1><div class="post-meta">2016-09-21</div><a class="disqus-comment-count" data-disqus-identifier="2016/09/21/switching-from-octopress-to-hexo/" href="/2016/09/21/switching-from-octopress-to-hexo/#disqus_thread"></a><div class="post-content"><p>Now, I am a reseach staff at a new institute. New campus, new air, new office, new computer. Everything is completelt new to me. To go on with my blog, I decided to switch (from Octopress) to Hexo, which is ‘A fast, simple &amp; powerful blog framework’. So, March on, soldier! </p></div><p class="readmore"><a href="/2016/09/21/switching-from-octopress-to-hexo/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2015/05/23/2015-05-16-introduction-to-bayes-factor/">Bayes Factor (简述贝叶斯因子) [1]</a></h1><div class="post-meta">2015-05-23</div><a class="disqus-comment-count" data-disqus-identifier="2015/05/23/2015-05-16-introduction-to-bayes-factor/" href="/2015/05/23/2015-05-16-introduction-to-bayes-factor/#disqus_thread"></a><div class="post-content"><p><strong>Bayes factor是什么？</strong></p>
<p>最近读文献，发现研究者开始使用Bayes factor来说明一些问题（比如Russell实验室的新文Julian et al., 2015），看来大势所趋了，需要学习一下。</p>
<p>Bayes factor（贝叶斯因子）被用来描述一个理论优于另一个理论的相对确证性（ the relative evidence for one theory over another ）(Dienes, 2014)，采用数学符号表示即</p>
<p><img src="/images/post_images/bayes_2.jpg" alt=""></p>
<p>其中，x为观测到的数据，H0和H1分别为两种理论或模型，p(x|Hi)表示Hi成立时，观测到x的概率，即x数据底层模型满足Hi的概率。实际上p(x|Hi)的一个常用的名字叫似然概率（likelihood），这样，Bayes factor因为由基于两个模型的likelihood的比值定义，也被称为似然比（likelihood ratio）。</p>
<p>因此，Bayes factor量化的就是数据x支持不同理论的确证性，换句话说，Bayes factor量化的是数据x支持模型A的概率是支持模型B的概率的倍数。为了使用方便，研究者给不同大小的Bayes factor打上了类似假设检验中“显著”“边缘显著”“不显著”的标签（Jeffreys H.，1939/1961）： 一般大于3或小于1/3被认为是实质性的证据（substantial evidence）；而1/3到3之间则被认为是较弱或有待验证的证据（weak or anecdotal evidence） </p>
<p>参考文献：</p>
<ul>
<li><p>Julian et al. (2015). Place recognition and heading retrieval are mediated by dissociable cognitive systems in mice. Proc.Natl.Acad.Sci.U.S.A. www.pnas.org/cgi/doi/10.1073/pnas.1424194112</p>
</li>
<li><p>Dienes Z. (2014). Using Bayes to get the most out of non-significant results. Front.Psychol. 5:781. doi:10.3389/fpsyg.2014.00781</p>
</li>
<li><p>Jeffreys, H. (1939/1961). The Theory of Probability, 1st/3rd Edn. Oxford, England: Oxford University Press.</p>
</li>
</ul></div><p class="readmore"><a href="/2015/05/23/2015-05-16-introduction-to-bayes-factor/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2015/05/23/2015-05-23-introduction-to-bayes-factor-2/">Bayes Factor (简述贝叶斯因子) [2]</a></h1><div class="post-meta">2015-05-23</div><a class="disqus-comment-count" data-disqus-identifier="2015/05/23/2015-05-23-introduction-to-bayes-factor-2/" href="/2015/05/23/2015-05-23-introduction-to-bayes-factor-2/#disqus_thread"></a><div class="post-content"><p><strong>Bayes factor的几个应用途径</strong></p>
<ol>
<li><p>作为一种统计推断的方法，Bayes factor首先可以<strong>用来代替p值</strong>（一般根据p&lt;0.05来决定拒绝虚无假设（null hypothesis, H0），接受备择假设（alternative hypothesis, H1））来确定备择假设是否可靠。这里的H0和H1即两个不同的模型，计算Bayes factor（<img src="/images/post_images/bayes_2.jpg" alt="">）。同样，如果计算得到的Bayes factor大于3，即数据x支持H1的概率是数据x支持H0的3倍以上，则被认为有足够的证据说明模型H1的正确性（类似根据p&lt;0.05做出的结论）。</p>
</li>
<li><p>采用p值做统计推断时，一个常识是不可以简单地使用p&gt;0.05作为H0成立的证据，即研究者不可以简单地做接受H0的结论（因为导致不显著的原因除了“H0成立”之外，还有比如样本不足，不够敏感等的影响；因此，如果非要做结论，一般需要结合power或effect size的信息来辅助进行）。而Bayes factor在这种场景中却派上了用场。如果统计结果显示上面计算得到的Bayes factor小于1/3，甚至更小，研究者就有足够的信心来接受H0模型。因此，<strong>Bayes factor可以方便研究者确定“没有结果”的可靠性</strong>，用于理论检验和构建。</p>
</li>
<li><p>个人认为Bayes factor还可以在另一个地方派上用场，即关于大样本研究中发现的效应值小（small effect size）的问题。随着数据采集条件的完善，行为神经科学中大样本的数据不断普及。同时研究者也发现，在大样本的数据统计中，0.2左右的效应量变得异常普遍，于是一些没有相关经验的审稿人（reviewer）便通常会提出类似“the amount of variance that impulsivity accounted for was a mere 2%”的问题，并质疑结果的可靠性。这个时候reviewer一般会要求做分半，进一步验证结果的可靠性。Bayes factor提供了另一个角度来<strong>展示结论的可靠性</strong>。以我自己的研究为例（Kong et al., PLOS ONE, 2014），我们发现被试在核磁扫描中头动（In-scanner head motion）的大小和被试的自我控制特质（Self-control impulsivity）存在显著关联，但是相关系数只有0.14（p=0.001），这时，可以计算该分析的Bayes factor发现BF = 9.1，因为大于3，可以认为有足够的证据确信头功和被试的自我控制特质之间存在的关联。</p>
</li>
</ol>
<p>参考文献：</p>
<ul>
<li><em>Kong X-Z</em>, Zhen Z, Li X, Lu H-h, Wang R, Liu, L, He, Y, Zang, Y-f, Liu, J. (2014) Individual Differences in Impulsivity Predict Head Motion during Magnetic Resonance Imaging. PLoS ONE 9(8): e104989. doi:10.1371/journal.pone.0104989.</li>
</ul></div><p class="readmore"><a href="/2015/05/23/2015-05-23-introduction-to-bayes-factor-2/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2015/01/31/2015-01-31-head-motion-is-not-simply-a-technical-artifact/">Head Motion is Not Simply a Technical Artifact（学术年会上的报告）</a></h1><div class="post-meta">2015-01-31</div><a class="disqus-comment-count" data-disqus-identifier="2015/01/31/2015-01-31-head-motion-is-not-simply-a-technical-artifact/" href="/2015/01/31/2015-01-31-head-motion-is-not-simply-a-technical-artifact/#disqus_thread"></a><div class="post-content"><p>各位老师，同学，大家好！我报告的题目是“头动并非简单的技术噪声：脑成像中头动的心理和神经相关”。</p>
<p>核磁共振成像技术的出现，为研究人类心智和脑疾病提供了新的契机。但是，扫描过程会受到很多混淆因素的影响，比如头动。剧烈的头动不仅让脑偏移了位置，还会干扰信号采集。<strong>一直以来，研究者会在数据预处理中采用头动校正来消除头动带来的影响，但是近年来，人们发现头动校正是不够的。</strong>比如2012年连续有几篇很有影响的文章（van Dijk et al., 2012; Power et al., 2012; Satterthwaite et al., 2012; Ling et al., 2012）发现：即使采用了严格的头动校正，头动还是会影响功能连接和大脑白质测量。考虑到病人往往头动会相对严重，<strong>由此人们开始怀疑，以前发现的脑上的差异到底是脑损伤还是头动引起的扫描噪声</strong>。2012年以后人们的头动问题的关注不断增多，头动问题也开始让研究者重新思考疾病机理研究中脑影像的应用。<br></div><p class="readmore"><a href="/2015/01/31/2015-01-31-head-motion-is-not-simply-a-technical-artifact/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/10/05/2014-10-05-a-new-approach-to-measuring-single-subject-morphological-relationship-of-cortical-regions/">一种基于单被试MRI脑影像量化脑区间连接的新方法</a></h1><div class="post-meta">2014-10-05</div><a class="disqus-comment-count" data-disqus-identifier="2014/10/05/2014-10-05-a-new-approach-to-measuring-single-subject-morphological-relationship-of-cortical-regions/" href="/2014/10/05/2014-10-05-a-new-approach-to-measuring-single-subject-morphological-relationship-of-cortical-regions/#disqus_thread"></a><div class="post-content"><p>目前研究者普遍认为，人类复杂的认知过程并不能由单独的某个脑区完成，而是依赖多个脑区间的协调工作。因此，考查脑区间的关联对进一步深入理解大脑的工作机制有极为重要的意义，也是近年来脑区连接和脑网络成为脑科学研究热点的主要原因。</p>
<p>目前通过核磁共振成像技术采集的脑数据构建脑区连接和脑网络主要有以下几种方式：基于DTI数据量化脑区间白质纤维连接进而构建脑网络；基于fMRI数据通过脑区间BOLD信号的波动共变量化功能连接进而构建脑网络；通过MRI数据通过脑区测量（如皮层厚度、体积等）在被试间的共变量化结构连接进而构建脑网络。其中，前两种方法都可以实现对单个被试网络的构建，而已有基于MRI数据量化连接的方法主要基于一组被试，无法实现对单个被试中脑区连接的量化。</p>
<p>但是，构建单个被试脑区连接在实际应用中是极为需要的。比如通过构建了单个被试的脑区连接和网络，可以提高对疾病的个体差异的认识，并进而促进未来基于核磁数据的诊断。<a href="http://www.sciencedirect.com/science/article/pii/S0165027014003203" target="_blank" rel="noopener">这个研究</a>旨在提出一种基于MRI脑结构数据量化脑区间关联的新方法。该方法可以总结为一下三步：</p>
<ol>
<li>计算脑中每个体素的局部形态学特征；</li>
<li>脑区分割，并估计每个脑区形态学特征的分布；</li>
<li>通过估计两两脑区的形态学特征的分布来量化两两脑区间的关系，即脑区连接。</li>
</ol>
<p>下面是该方法的流程示意图。</p>
<p><a href="http://www.sciencedirect.com/science/article/pii/S0165027014003203" target="_blank" rel="noopener">X.-z.  Kong  et  al.  /  Journal  of  Neuroscience  Methods  237  (2014)  103–107  105</a></p>
<p><img src="/images/post_images/dbir.jpg" alt="DBIR" title="DBIR"></p></div><p class="readmore"><a href="/2014/10/05/2014-10-05-a-new-approach-to-measuring-single-subject-morphological-relationship-of-cortical-regions/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/09/16/2014-09-16-do-not-move-your-head/">保持冷静，不要头动</a></h1><div class="post-meta">2014-09-16</div><a class="disqus-comment-count" data-disqus-identifier="2014/09/16/2014-09-16-do-not-move-your-head/" href="/2014/09/16/2014-09-16-do-not-move-your-head/#disqus_thread"></a><div class="post-content"><p>在网上看到一张图，贴在核磁扫描间是不是很应景，哈哈！</p>
<p><img src="http://ww2.sinaimg.cn/bmiddle/49f8908ejw1ekeokp0heej20go0jg0u4.jpg" alt="保持冷静，不要头动"></p>
<p>致谢：<a href="https://twitter.com/m_wall" target="_blank" rel="noopener">Matt Wall@Twitter</a></p></div><p class="readmore"><a href="/2014/09/16/2014-09-16-do-not-move-your-head/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/09/10/2014-09-10-pymvpa-install/">PyMVPA安装</a></h1><div class="post-meta">2014-09-10</div><a class="disqus-comment-count" data-disqus-identifier="2014/09/10/2014-09-10-pymvpa-install/" href="/2014/09/10/2014-09-10-pymvpa-install/#disqus_thread"></a><div class="post-content"><p>多体素模式分析(multi-voxel pattern analysis, MVPA)是一种基于机器学习理论发展出来的一种功能磁共振数据分析技术，简单说，就是通过多个体素的信息融合在一起用于后续的预测等统计分析。具体实现上，PyMVPA是研究者常用的一个工具包。下面记录PyMVPA安装步骤，备查。</p>
<p>系统环境：Centos 5.7 64bit 非root用户</p>
<p>和<a href="http://www.conxz.net/blog/2014/06/16/scipy-install/" target="_blank" rel="noopener">Scipy安装方法</a>类似，主要涉及如下命令：</p>
<pre><code># pip install --user pymvpa2
</code></pre><p>如果安装顺利，会显示如下文字，表示安装完成：</p>
<pre><code>Successfully installed pymvpa2
Cleaning up...
</code></pre><p>但是，更多的可能会碰到如下问题：</p>
<pre><code>unable to execute &apos;swig&apos;: No such file or directory
error: command &apos;swig&apos; failed with exit status 1
</code></pre><p>这个报错说明需要首先另外安装这个叫swip的工具，实际上，SWIG可以允许一些脚本语言调用C/C++语言的接口。支持的语言有：Perl, Python, Tcl, Ruby, Guile, and Java。在PyMVPA中主要就是涉及与Python的对接了。安装SWIP步骤如下：</div><p class="readmore"><a href="/2014/09/10/2014-09-10-pymvpa-install/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/08/22/2014-08-22-a-paper-on-head-motion-and-impulsivity/">投稿经历: A Paper On Head Motion And Impulsivity</a></h1><div class="post-meta">2014-08-22</div><a class="disqus-comment-count" data-disqus-identifier="2014/08/22/2014-08-22-a-paper-on-head-motion-and-impulsivity/" href="/2014/08/22/2014-08-22-a-paper-on-head-motion-and-impulsivity/#disqus_thread"></a><div class="post-content"><p><a href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0104989" target="_blank" rel="noopener">这个研究</a>关注的问题是：核磁扫描过程中的头动纯属设备噪声，还是携带了关于被试的有意义的信息？</p>
<p>下面是我简单写了一个中文摘要：</p>
<p>核磁共振成像（MRI）技术的发展为我们理解人类智能和脑疾病提供了有效的手段，在实际应用中，MRI扫描过程受到了一些无关因素的影响，头动就是其中之一。传统观点认为，头动是毫无意义的混淆因素，由于它会影响MRI信号，研究者想尽各种办法试图将头动的信息彻底去除，而这些方法往往是基于一个未经验证的假设：MRI扫描过程中的头动是简单的技术噪声。但是，这些头动究究竟只是简单的噪声，还是其本身也带有很重要的信息，目前我们对此知之甚少。本研究对MRI扫描过程中的头动的个体差异是否反映了被试的心理特质做了系统探讨。首先，我们在大样本的儿童（N=245）和成人（N=581）中均发现，头动的个体差异与被试的冲动水平存在显著相关，即被试越冲动，头动越大。进而，结果发现，多动症儿童与正常对照儿童在头动上的差异，很大程度上是由于他们在冲动水平上的差异导致的。综上所述，本研究发现MRI扫描过程中的头动反映了被试的冲动水平，这为更全面地认识头动提供了实验证据和全新的观察视角，同时，本研究对新的消除头动影响算法和处理策略的提出也有着深的指导意义。</p>
<p><a href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0104989" target="_blank" rel="noopener">Kong X-z, Zhen Z, Li X, Lu H-h, Wang R, et al. (2014) Individual Differences in Impulsivity Predict Head Motion during Magnetic Resonance Imaging. PLoS ONE 9(8): e104989. doi:10.1371/journal.pone.0104989</a></p>
<p>这篇文章从2013年4月11日开始投出到2014年7月16日终于接收，历时15个月又5天。期间共收到9次Reject，送审5次，其中2次Major revision，最快的回应来自Current Biology，相隔一夜。发生了奇葩的同一个reviewer连续审了三次的故事(具体见下面的投稿记录和感触)。</p>
<ul>
<li>过程中，虽然收到reject会有些失望，但是不断有来自外界的意见也会感到很踏实，每次都根据意见修改，每次都有所提高。</li>
<li>投稿过程中<strong>推荐reviewer至关重要</strong>，尤其对于neuroimage以下的这种中等杂志。</li>
<li>如果有机会回复reviewer的意见，要尽力做到<strong>100%满足reviewer</strong>的意见。</li>
<li>回复reviewer意见和提交修改稿要安排好时间，<strong>尽量在20~30天时完成重新提交</strong>。</li>
</ul>
<p>虽然只能发表在PLoS ONE上，但是能把一个自己的观点表达出去还是很高兴的。况且文章刚发表，就得到了领域大牛BB的认可。大牛BB得知这篇文章后，主动和我老板通邮件，表达恭喜的同时，说<br><code>Congrats on a really interesting paper on head motion and impulsivity. (Even more surprising is that it was not in a high impact journal!)</code></p>
<p>不管怎样，能得到大牛如此高度的认可，真的荣幸至极！感谢我的导师刘嘉老板在这个过程中的悉心指导和不断鼓励。</p>
<hr>
<p><strong>下面投稿记录：</strong></div><p class="readmore"><a href="/2014/08/22/2014-08-22-a-paper-on-head-motion-and-impulsivity/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/08/20/2014-08-20-afni-install/">AFNI安装/AFNI Installation</a></h1><div class="post-meta">2014-08-20</div><a class="disqus-comment-count" data-disqus-identifier="2014/08/20/2014-08-20-afni-install/" href="/2014/08/20/2014-08-20-afni-install/#disqus_thread"></a><div class="post-content"><p>除了FSL和SPM，AFNI也是研究者常用的脑影像处理工具。官方提供了详尽的安装步骤（非管理员权限），点<a href="http://afni.nimh.nih.gov/pub/dist/HOWTO/howto/ht00_inst/html/linux_inst_basic.html" target="_blank" rel="noopener">我</a>。这里做一些补充。</p>
<p>根据<a href="http://afni.nimh.nih.gov/pub/dist/HOWTO/howto/ht00_inst/html/linux_inst_basic.html" target="_blank" rel="noopener">官方安装步骤</a>的说明，在安装AFNI之前，需要首先安装几个依赖的package，包括libXp, tcsh，PyQt4, 和R。安装步骤参看上面提及的链接，下面几条命令用于检查自己的机器是否安装完成了上述依赖package。</p>
<pre><code>rpm -qa | grep libXp
rpm -qa | grep tcsh
</code></pre><p>这两条命令会在terminal中print出相应package的文件名。</p>
<pre><code>which R
</code></pre><p>正常情况下，上面这条命令会print出R的路径。</p>
<p>PyQt4是Python的一个工具包，下面检查是否安装完成PyQt4.</p>
<pre><code>ipython
&gt;from PyQt4 import QtCore
&gt;
</code></pre><p>在Python中输入第二条命令后如果没有报错，就是安装完成了。</p>
<p>接下来可以按照<a href="http://afni.nimh.nih.gov/pub/dist/HOWTO/howto/ht00_inst/html/linux_inst_basic.html" target="_blank" rel="noopener">官方安装步骤</a>完后进行。在选择AFNI的版本时，如果机器有多个CPU，可以选<code>linux_openmp</code>或64位系统的<code>linux_openmp_64</code>;只有一个CPU的话，可以选<code>linux_xorg7</code>或<code>linux_xorg7_64</code>。</p>
<p>我用的Centos7，环境变量PATH采用<code>~/.bashrc</code>控制，而不是官方安装步骤中的.cshrc，所以在<code>~/.bashrc</code>中添加如下几行即可：</div><p class="readmore"><a href="/2014/08/20/2014-08-20-afni-install/">Read More</a></p></div><nav class="page-navigator"><a class="extend prev" rel="prev" href="/">Previous</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/">Next</a></nav><script id="dsq-count-scr" src="//conimaging.disqus.com/count.js" async></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://conxz.net"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BrainResearch/">BrainResearch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Methods/">Methods</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/OpenScience/">OpenScience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Xs/">Xs</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/bayes-factor/" style="font-size: 15px;">bayes factor</a> <a href="/tags/brain-asymmetry/" style="font-size: 15px;">brain asymmetry</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/mutual-information/" style="font-size: 15px;">mutual information</a> <a href="/tags/freesurfer/" style="font-size: 15px;">freesurfer</a> <a href="/tags/paired-t-test/" style="font-size: 15px;">paired t-test</a> <a href="/tags/brain-network/" style="font-size: 15px;">brain network</a> <a href="/tags/reading/" style="font-size: 15px;">reading</a> <a href="/tags/mvpa/" style="font-size: 15px;">mvpa</a> <a href="/tags/endnote/" style="font-size: 15px;">endnote</a> <a href="/tags/blog/" style="font-size: 15px;">blog</a> <a href="/tags/R/" style="font-size: 15px;">R</a> <a href="/tags/afni/" style="font-size: 15px;">afni</a> <a href="/tags/head-motion/" style="font-size: 15px;">head motion</a> <a href="/tags/two-sample-t-test/" style="font-size: 15px;">two-sample t-test</a> <a href="/tags/white-matter/" style="font-size: 15px;">white matter</a> <a href="/tags/gene/" style="font-size: 15px;">gene</a> <a href="/tags/open-science/" style="font-size: 15px;">open science</a> <a href="/tags/collaborative-team-research/" style="font-size: 15px;">collaborative team research</a> <a href="/tags/paper/" style="font-size: 15px;">paper</a> <a href="/tags/hippocampus/" style="font-size: 15px;">hippocampus</a> <a href="/tags/publication/" style="font-size: 15px;">publication</a> <a href="/tags/sex/" style="font-size: 15px;">sex</a> <a href="/tags/navigation/" style="font-size: 15px;">navigation</a> <a href="/tags/neuroscience/" style="font-size: 15px;">neuroscience</a> <a href="/tags/shiny-app/" style="font-size: 15px;">shiny app</a> <a href="/tags/data-science/" style="font-size: 15px;">data science</a> <a href="/tags/data-sharing/" style="font-size: 15px;">data sharing</a> <a href="/tags/p-value/" style="font-size: 15px;">p value</a> <a href="/tags/conference/" style="font-size: 15px;">conference</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/01/13/scitop2018/">脑科学相关SCI Top期刊_2018</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/27/obsBrainApp/">记第一个Shiny应用obsBrain</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/paper-preview/">研究前沿论文先睹为快</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/06/journalsci2017/">脑科学期刊最新影响因子和中美差距</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/19/collaborative-team-research/">多中心合作与脑科学研究 由最近一篇文章想到的</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/15/figures-for-publication/">学术发表用高质量图片保存</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/08/whatisretreat/">Retreat是什么会议？</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/12/13/unzip/">unzip解压压缩包中指定的文件</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/11/08/scitop/">脑科学相关SCI Top期刊_2017</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/22/planum-temporale-asymmetry/">Look Back：颞平面不对称性 Planum Temporale Asymmetry</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//conimaging.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">小孔成像.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>