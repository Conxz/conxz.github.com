<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Kong Brain Observatory"><title>小孔成像 | Kong Brain Observatory</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-26255736-1','auto');ga('send','pageview');
</script><script data-ad-client="ca-pub-7680017147908727" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">小孔成像</h1><a id="logo" href="/.">小孔成像</a><p class="description">Kong Brain Observatory</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/news/"><i class="fa fa-twitter"> News &amp; Events</i></a><a href="/collection/"><i class="fa fa-cloud"> Collection</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/2014/09/10/2014-09-10-pymvpa-install/">PyMVPA安装</a></h1><div class="post-meta">2014-09-10</div><a class="disqus-comment-count" data-disqus-identifier="2014/09/10/2014-09-10-pymvpa-install/" href="/2014/09/10/2014-09-10-pymvpa-install/#disqus_thread"></a><div class="post-content"><p>多体素模式分析(multi-voxel pattern analysis, MVPA)是一种基于机器学习理论发展出来的一种功能磁共振数据分析技术，简单说，就是通过多个体素的信息融合在一起用于后续的预测等统计分析。具体实现上，PyMVPA是研究者常用的一个工具包。下面记录PyMVPA安装步骤，备查。</p>
<p>系统环境：Centos 5.7 64bit 非root用户</p>
<p>和<a href="http://www.conxz.net/blog/2014/06/16/scipy-install/" target="_blank" rel="noopener">Scipy安装方法</a>类似，主要涉及如下命令：</p>
<pre><code># pip install --user pymvpa2
</code></pre><p>如果安装顺利，会显示如下文字，表示安装完成：</p>
<pre><code>Successfully installed pymvpa2
Cleaning up...
</code></pre><p>但是，更多的可能会碰到如下问题：</p>
<pre><code>unable to execute &apos;swig&apos;: No such file or directory
error: command &apos;swig&apos; failed with exit status 1
</code></pre><p>这个报错说明需要首先另外安装这个叫swip的工具，实际上，SWIG可以允许一些脚本语言调用C/C++语言的接口。支持的语言有：Perl, Python, Tcl, Ruby, Guile, and Java。在PyMVPA中主要就是涉及与Python的对接了。安装SWIP步骤如下：</div><p class="readmore"><a href="/2014/09/10/2014-09-10-pymvpa-install/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/08/22/2014-08-22-a-paper-on-head-motion-and-impulsivity/">投稿经历: A Paper On Head Motion And Impulsivity</a></h1><div class="post-meta">2014-08-22</div><a class="disqus-comment-count" data-disqus-identifier="2014/08/22/2014-08-22-a-paper-on-head-motion-and-impulsivity/" href="/2014/08/22/2014-08-22-a-paper-on-head-motion-and-impulsivity/#disqus_thread"></a><div class="post-content"><p><a href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0104989" target="_blank" rel="noopener">这个研究</a>关注的问题是：核磁扫描过程中的头动纯属设备噪声，还是携带了关于被试的有意义的信息？</p>
<p>下面是我简单写了一个中文摘要：</p>
<p>核磁共振成像（MRI）技术的发展为我们理解人类智能和脑疾病提供了有效的手段，在实际应用中，MRI扫描过程受到了一些无关因素的影响，头动就是其中之一。传统观点认为，头动是毫无意义的混淆因素，由于它会影响MRI信号，研究者想尽各种办法试图将头动的信息彻底去除，而这些方法往往是基于一个未经验证的假设：MRI扫描过程中的头动是简单的技术噪声。但是，这些头动究究竟只是简单的噪声，还是其本身也带有很重要的信息，目前我们对此知之甚少。本研究对MRI扫描过程中的头动的个体差异是否反映了被试的心理特质做了系统探讨。首先，我们在大样本的儿童（N=245）和成人（N=581）中均发现，头动的个体差异与被试的冲动水平存在显著相关，即被试越冲动，头动越大。进而，结果发现，多动症儿童与正常对照儿童在头动上的差异，很大程度上是由于他们在冲动水平上的差异导致的。综上所述，本研究发现MRI扫描过程中的头动反映了被试的冲动水平，这为更全面地认识头动提供了实验证据和全新的观察视角，同时，本研究对新的消除头动影响算法和处理策略的提出也有着深的指导意义。</p>
<p><a href="http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0104989" target="_blank" rel="noopener">Kong X-z, Zhen Z, Li X, Lu H-h, Wang R, et al. (2014) Individual Differences in Impulsivity Predict Head Motion during Magnetic Resonance Imaging. PLoS ONE 9(8): e104989. doi:10.1371/journal.pone.0104989</a></p>
<p>这篇文章从2013年4月11日开始投出到2014年7月16日终于接收，历时15个月又5天。期间共收到9次Reject，送审5次，其中2次Major revision，最快的回应来自Current Biology，相隔一夜。发生了奇葩的同一个reviewer连续审了三次的故事(具体见下面的投稿记录和感触)。</p>
<ul>
<li>过程中，虽然收到reject会有些失望，但是不断有来自外界的意见也会感到很踏实，每次都根据意见修改，每次都有所提高。</li>
<li>投稿过程中<strong>推荐reviewer至关重要</strong>，尤其对于neuroimage以下的这种中等杂志。</li>
<li>如果有机会回复reviewer的意见，要尽力做到<strong>100%满足reviewer</strong>的意见。</li>
<li>回复reviewer意见和提交修改稿要安排好时间，<strong>尽量在20~30天时完成重新提交</strong>。</li>
</ul>
<p>虽然只能发表在PLoS ONE上，但是能把一个自己的观点表达出去还是很高兴的。况且文章刚发表，就得到了领域大牛BB的认可。大牛BB得知这篇文章后，主动和我老板通邮件，表达恭喜的同时，说<br><code>Congrats on a really interesting paper on head motion and impulsivity. (Even more surprising is that it was not in a high impact journal!)</code></p>
<p>不管怎样，能得到大牛如此高度的认可，真的荣幸至极！感谢我的导师刘嘉老板在这个过程中的悉心指导和不断鼓励。</p>
<hr>
<p><strong>下面投稿记录：</strong></div><p class="readmore"><a href="/2014/08/22/2014-08-22-a-paper-on-head-motion-and-impulsivity/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/08/20/2014-08-20-afni-install/">AFNI安装/AFNI Installation</a></h1><div class="post-meta">2014-08-20</div><a class="disqus-comment-count" data-disqus-identifier="2014/08/20/2014-08-20-afni-install/" href="/2014/08/20/2014-08-20-afni-install/#disqus_thread"></a><div class="post-content"><p>除了FSL和SPM，AFNI也是研究者常用的脑影像处理工具。官方提供了详尽的安装步骤（非管理员权限），点<a href="http://afni.nimh.nih.gov/pub/dist/HOWTO/howto/ht00_inst/html/linux_inst_basic.html" target="_blank" rel="noopener">我</a>。这里做一些补充。</p>
<p>根据<a href="http://afni.nimh.nih.gov/pub/dist/HOWTO/howto/ht00_inst/html/linux_inst_basic.html" target="_blank" rel="noopener">官方安装步骤</a>的说明，在安装AFNI之前，需要首先安装几个依赖的package，包括libXp, tcsh，PyQt4, 和R。安装步骤参看上面提及的链接，下面几条命令用于检查自己的机器是否安装完成了上述依赖package。</p>
<pre><code>rpm -qa | grep libXp
rpm -qa | grep tcsh
</code></pre><p>这两条命令会在terminal中print出相应package的文件名。</p>
<pre><code>which R
</code></pre><p>正常情况下，上面这条命令会print出R的路径。</p>
<p>PyQt4是Python的一个工具包，下面检查是否安装完成PyQt4.</p>
<pre><code>ipython
&gt;from PyQt4 import QtCore
&gt;
</code></pre><p>在Python中输入第二条命令后如果没有报错，就是安装完成了。</p>
<p>接下来可以按照<a href="http://afni.nimh.nih.gov/pub/dist/HOWTO/howto/ht00_inst/html/linux_inst_basic.html" target="_blank" rel="noopener">官方安装步骤</a>完后进行。在选择AFNI的版本时，如果机器有多个CPU，可以选<code>linux_openmp</code>或64位系统的<code>linux_openmp_64</code>;只有一个CPU的话，可以选<code>linux_xorg7</code>或<code>linux_xorg7_64</code>。</p>
<p>我用的Centos7，环境变量PATH采用<code>~/.bashrc</code>控制，而不是官方安装步骤中的.cshrc，所以在<code>~/.bashrc</code>中添加如下几行即可：</div><p class="readmore"><a href="/2014/08/20/2014-08-20-afni-install/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/06/16/2014-06-16-scipy-install/">Scipy安装步骤</a></h1><div class="post-meta">2014-06-16</div><a class="disqus-comment-count" data-disqus-identifier="2014/06/16/2014-06-16-scipy-install/" href="/2014/06/16/2014-06-16-scipy-install/#disqus_thread"></a><div class="post-content"><p>Scipy函数库是基于python做科学和工程计算中常用的库，其中包括了众多的线性代数、数值计算、图像和信号处理、稀疏矩阵等。在基于python做脑影像处理时，scipy也是最常用到的python库之一。下面记录安装scipy的步骤，备查。</p>
<p>系统环境：Centos 5.7 64bit</p>
<p>在非root权限下，需要把库安装在自己有权限的目录下，比如采用pip提供的—user参数将默认安装到.local/lib/python2.7/site-packages/中。</p>
<p>安装scipy涉及到的主要命令如下：</p>
<pre><code>pip install –user scipy
</code></pre><p>不过一般情况下，你会碰到如下的问题：</div><p class="readmore"><a href="/2014/06/16/2014-06-16-scipy-install/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/06/03/2014-06-03-may/">这个5月</a></h1><div class="post-meta">2014-06-03</div><a class="disqus-comment-count" data-disqus-identifier="2014/06/03/2014-06-03-may/" href="/2014/06/03/2014-06-03-may/#disqus_thread"></a><div class="post-content"><p>这个五月是一个折腾的五月，时间关系，简单罗列如下。</p>
<p>五月初，参加在北京举办的<a href="http://biomedicalimaging.org/2014/" target="_blank" rel="noopener">ISBI2014</a>，第一次带着<a href="http://figshare.com/articles/Measuring_Regional_Diffusivity_Dependency_via_Mutual_Information/1022945" target="_blank" rel="noopener">自己的poster</a>在会场展示，虽然只是一个one-page paper，也是第一次自己一个人参加国际学术会议，经历难得。会上学习到很多，也结识了不少新朋友。</p></div><p class="readmore"><a href="/2014/06/03/2014-06-03-may/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/04/12/2014-04-12-non-fast-forward-error-with-octopress/">deploy时[non-fast-forward]reject问题解决方案</a></h1><div class="post-meta">2014-04-12</div><a class="disqus-comment-count" data-disqus-identifier="2014/04/12/2014-04-12-non-fast-forward-error-with-octopress/" href="/2014/04/12/2014-04-12-non-fast-forward-error-with-octopress/#disqus_thread"></a><div class="post-content"><p>Github+Octopress rake deploy时[non-fast-forward]reject问题解决方案</p>
<p>好久没更新blog，今天写好文deploy时发现报错：</p>
<pre><code>! [rejected]        master -&gt; master (non-fast-forward)
</code></pre><p>在网络google了半下午，终于找到了解决方案：</p>
<p>更换目录，并更新：</p>
<pre><code>cd octopress/_deploy
git pull origin master
</code></pre><p>跳出目录，重新deploy：<br>    cd ..<br>    rake deploy</p>
<p>问题解决。<br></div><p class="readmore"><a href="/2014/04/12/2014-04-12-non-fast-forward-error-with-octopress/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/04/12/2014-04-12-paired-t-or-two-sample-t-test/">Paired t or two-sample t-test</a></h1><div class="post-meta">2014-04-12</div><a class="disqus-comment-count" data-disqus-identifier="2014/04/12/2014-04-12-paired-t-or-two-sample-t-test/" href="/2014/04/12/2014-04-12-paired-t-or-two-sample-t-test/#disqus_thread"></a><div class="post-content"><p>之所以谈这两种t检验方法，是因为一篇很有意思的问题，即Neurobiological basis of head motion in brain imaging。在介绍完两种t检验方法后在回来谈论这篇文章。</p>
<p>双样本t检验Two-sample t-test  |  配对t检验Paired t-test</p>
<p>双样本t检验，也叫独立样本t检验。即考查两个相互独立的样本的均值的差异。（与配对t检验相比，这里的两组样本是没有配对信息的，比如比较男生和女生在方向感能力上的差异）</p>
<p><img src="/images/post_images/f1.jpg" alt="f1" title="f1"></p>
<p>其中s1和s2分别为两个样本的标准差，n1和n2为两个样本的样本量。此时，t值的自由度为n1-1和n2-1中较小的一个。</p>
<pre><code>Note: 在假设两个样本的variance相等的情况下，自由度为n1+n2-2，这也是我们常见的自由度计算方式，SPSS中给出了假设方差相等的自由度，以及方差不等时根据两个样本各自的方差和样本量估计的自由度。感谢@斯图拉特 童鞋提醒 :)
</code></pre><p>当n1=n2=N时，可以简化为</p>
<p><img src="/images/post_images/f2.jpg" alt="f2" title="f2"></p>
<p>这时候自由度为n1+n2-2，即2N-2。</div><p class="readmore"><a href="/2014/04/12/2014-04-12-paired-t-or-two-sample-t-test/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2014/01/11/2014-01-11-install-and-use-r-package/">Install and Use R Package</a></h1><div class="post-meta">2014-01-11</div><a class="disqus-comment-count" data-disqus-identifier="2014/01/11/2014-01-11-install-and-use-r-package/" href="/2014/01/11/2014-01-11-install-and-use-r-package/#disqus_thread"></a><div class="post-content"><p><strong>安装：</strong></p>
<ul>
<li>Method 1: </li>
</ul>
<p>Install from source<br>下载工具包, 比如irr包，用于计算ICC:</p>
<blockquote>
<p>$ R CMD INSTALL irr_0.84.tar.gz -l /my/own/R-packages/</p>
</blockquote>
<p>注：这是在Linux的Terminal中完成的。</p>
<ul>
<li>Method 2: </li>
</ul>
<p>Install from CRAN directly:</p>
<blockquote>
<p>install.packages(“irr”, lib=”/my/own/R-packages/“)</p>
</blockquote>
<p>注：这是在R中完成的。</p>
<p>上述两种方式有一个很明显的区别，即方法一不会自动下载安装irr包需要的依赖包，比如lpSolve包，而后一种方法则可以自动检查并下载需要的依赖包。</p>
<p><strong>使用：</strong></p>
<p>下面是如何使用R，在使用irr包中的函数之前，需要首先导入该包，也就是告诉R你需要调用哪个包里的函数，这个包在哪里：</div><p class="readmore"><a href="/2014/01/11/2014-01-11-install-and-use-r-package/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2013/12/19/2013-12-19-plot-dynamic-network-matrix/">动态网络矩阵 可视化</a></h1><div class="post-meta">2013-12-19</div><a class="disqus-comment-count" data-disqus-identifier="2013/12/19/2013-12-19-plot-dynamic-network-matrix/" href="/2013/12/19/2013-12-19-plot-dynamic-network-matrix/#disqus_thread"></a><div class="post-content"><p>在过去的几年里，网络分析方法从社交网络辗转到人脑网络，火爆一时，也饱受诟病。不管怎样，网络分析方法确实给我们提供了一个新的观察和认识人脑的方式。</p>
<p>科学发展往往遵循一个“从一元到多元，从静态到动态”的演变规律，如今，研究者也不再满足分析一个单独的静态网络，而是开始试图从动态变化的视角观察人脑网络。这个动态可是短时的（比如一次扫描中人脑网络的变化），也可以是长时的（比如是在一天中不同时段人脑网络的变化，甚至是人的一生中脑网络的动态变化）。</p>
<p>通常，研究者采用一个矩阵来存储一个网络，矩阵中每个行或列表示一个node，而每个cell的值表示相应的两个node的连接强度。</p>
<p><img src="/images/post_images/mat_imshow.jpg" alt="网络矩阵" title="网络矩阵"><br></div><p class="readmore"><a href="/2013/12/19/2013-12-19-plot-dynamic-network-matrix/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2013/12/15/2013-12-15-add-endnote-style/">添加Endnote样式</a></h1><div class="post-meta">2013-12-15</div><a class="disqus-comment-count" data-disqus-identifier="2013/12/15/2013-12-15-add-endnote-style/" href="/2013/12/15/2013-12-15-add-endnote-style/#disqus_thread"></a><div class="post-content"><p>学术论文投稿过程中一个重要的步骤是按照学术期刊要求整理manuscript的格式，其中参考文献的格式是很关键的一步。Endnote是参考文献管理的一个很好用的工具。</p>
<p>在具体操作过程中，期刊一般会指定参考文献的Endnote样式，或者提供专用样式下载。针对第一种情况，选择相应的样式即可，针对后一种情况，则需要首先将专用样式下载，然后加入到Endnote中。具体方式以Human Brain Mapping为例记录备查。<br></div><p class="readmore"><a href="/2013/12/15/2013-12-15-add-endnote-style/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2013/11/14/2013-11-14-thoughts-on-an-article/">由一篇JN上的文章想到的</a></h1><div class="post-meta">2013-11-14</div><a class="disqus-comment-count" data-disqus-identifier="2013/11/14/2013-11-14-thoughts-on-an-article/" href="/2013/11/14/2013-11-14-thoughts-on-an-article/#disqus_thread"></a><div class="post-content"><p>这周组会我报告的是薛贵老师发在JN上的一篇脑结构预测reading ability的文章。起初选择该文章是出于以下两点考虑：1. 近期做个体差异的工作相对多一些，在分析方法上可能有所借鉴；2. 写作思路上的借鉴。</p>
<p>这篇文章内容大致如下：</p>
<p>在以往存在功能和结构成像技术研究reading的加工机制和个体差异的神经基础的背景下，作者提出已有研究存在两个问题，一方面往往采用单一的reading task，而reading ability是一个复杂的能力，由多个成分构成；另一方面样本量相对偏小。然后作者针对这两点，展开自己的研究。这篇文章涉及到7个不同的reading task，作者首先做了因素分析找到其中的3个成分，并分别命名为<code>phonological reading</code>，<code>form-sound association</code>和<code>naming speed</code>。然后采用fMRI研究中常用的MVPA的方法采用VBM的结构数据分别对3个成分进行预测。最后也采用传统的一元分析方式与MVPA的结果做了简单的对比。<br></div><p class="readmore"><a href="/2013/11/14/2013-11-14-thoughts-on-an-article/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2013/11/13/2013-11-13-paired-t-test-with-freesurfer-metrics/">对surface参数做配对T检验:以睡眠剥夺实验为例</a></h1><div class="post-meta">2013-11-13</div><a class="disqus-comment-count" data-disqus-identifier="2013/11/13/2013-11-13-paired-t-test-with-freesurfer-metrics/" href="/2013/11/13/2013-11-13-paired-t-test-with-freesurfer-metrics/#disqus_thread"></a><div class="post-content"><p>在脑科学的研究中，带有操纵的前后测实验相对于个体差异或组间比较的实验，分量要相对大很多。而前后测往往就涉及到统计上的配对T检验。下面以一个例子记录一下针对Freesurfer生成的surface上的参数做配对T检验（Paired T-test）的流程。一方面自己备查，另一方面也希望对有相同需求的同学有所帮助。</p>
<p>这是一个前后测的研究，中间睡眠剥夺约72小时，共8名男性参与测试。下面的分析旨在考查72小时的睡眠剥夺是否对被试的皮层厚度（thickness）产生了一定的影响。</div><p class="readmore"><a href="/2013/11/13/2013-11-13-paired-t-test-with-freesurfer-metrics/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2013/11/08/2013-11-08-from-freesurfer-labels-to-volumetric-masks/">From freesurfer labels to volumetric masks</a></h1><div class="post-meta">2013-11-08</div><a class="disqus-comment-count" data-disqus-identifier="2013/11/08/2013-11-08-from-freesurfer-labels-to-volumetric-masks/" href="/2013/11/08/2013-11-08-from-freesurfer-labels-to-volumetric-masks/#disqus_thread"></a><div class="post-content"><p>最近的工作涉及到获取两个脑区的mask：<code>Fusiform Gyrus</code>和<code>Entorhinal Cortex</code>。考虑到被试间的结构变异，决定采用Freesurfer针对被试的T1像分割的结果，其中主要涉及到recon-all这个命令。</p>
<p>在每个被试分割生成的结果中有两个分割方案，分别是aparc.annot[<a href="http://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation?action=AttachFile&amp;do=get&amp;target=annot-desikan.jpg" target="_blank" rel="noopener">图</a>]和aparc.a2009s.annot[<a href="http://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation?action=AttachFile&amp;do=get&amp;target=annot-destrieux.jpg" target="_blank" rel="noopener">图</a>]。查看一些材料后，发现在要获取的mask上，两个分割方案存在一些差别。其中，aparc.annot中有单独的Entorhinal Cortex，而在aparc.a2009s中则将其融合进了旁海马的结构中，这样为了获取Entorhinal Cortex，可以从aparc.annot中获取；这对Fusiform Gyrus，在aparc.annot中存在一个Fusiform Cortex，即包括了Gyrus和Sulcus的结构，而在aparc.a2009s.annot中则把Gyrus和Sulcus做了区分，这样Fusiform Gyrus就可以从aparc.a2009s.annot中获取了。</p>
<p>接下来简单的记录一下从label到mask的操作过程（以Entorhinal Cortex为例）：</div><p class="readmore"><a href="/2013/11/08/2013-11-08-from-freesurfer-labels-to-volumetric-masks/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2013/10/26/2013-10-26-about-mutual-information/">互信息杂谈</a></h1><div class="post-meta">2013-10-26</div><a class="disqus-comment-count" data-disqus-identifier="2013/10/26/2013-10-26-about-mutual-information/" href="/2013/10/26/2013-10-26-about-mutual-information/#disqus_thread"></a><div class="post-content"><p>谈到互信息，必然涉及到“信息”和“熵”两个概念。信息论的创始人Shannon给信息的定义是“用来消除不确定性的东西”；而在信息论中，熵表示的是不确定性的度量，不确定性越大，熵越高。对于一个熵越大的随机变量，需要越多的信息量来确定它的值。</p>
<p>而互信息是一个用来在信息论中衡量两个信号关联程度的度量，后其被用来对两个随机变量间的关联程度进行描述。互信息<code>I(X;Y)=H(X)-H(X|Y)</code>直观的意思就是知道了Y的值以后，我们对X的不确定性的减少量，即Y的值透露了多少关于X的信息量。<code>(Mutual information measures the reduction of uncertainty in X after observing Y. )</code></p>
<p>互信息是非负的，也是对称的。当<code>I(X;Y)</code>远大于0时，表示二者关联度大；当<code>I(X;Y)=0</code>时，二者无关。且<code>I(X; Y) = I(Y; X)</code>。虽然，在某些计算互信息的工具包中二者并不相等。</div><p class="readmore"><a href="/2013/10/26/2013-10-26-about-mutual-information/">Read More</a></p></div><div class="post"><h1 class="post-title"><a href="/2013/10/25/2013-10-25-sloppy-python-snippets-to-capture-command-output/">用Python获取命令行输出</a></h1><div class="post-meta">2013-10-25</div><a class="disqus-comment-count" data-disqus-identifier="2013/10/25/2013-10-25-sloppy-python-snippets-to-capture-command-output/" href="/2013/10/25/2013-10-25-sloppy-python-snippets-to-capture-command-output/#disqus_thread"></a><div class="post-content"><p></p><p>Python在慢慢成为脑影像数据处理中的主流语言。而在做脑影像处理时，不免有时候需要用到一些别人开发好的工具包，而这些包并不都是python包。比如对方采用C写好了算法，我们觉得这个算法很好，用在自己的数据上应该会有不错的结果。我在处理脑影像数据时遇到下面的情况：</p><p></p>
<p></p><p>需要用的工具包是C写的，那第一件事就是需要在运行该脚本的机器上重新编译该代码为可执行的程序，也就是用<code>make</code>了。</p><p></p>
<p></p><p>产生可执行文件后，在Terminal中执行测试，可以正常运行，发现结果以print到屏幕上的形式给出。</p><p></p>
<p></p><p>通常我采用python进行脑影像数据的读写，在读取数据后并进行一定的预处理后，需要循环调用上面提及的可执行程序，并获取其输出的结果。这时候如何来实现呢？显然，常用的’os.system()’是搞不定的，引起它只会返回程序的执行状态。下面是在网上查到的几种方案，尝试过都可以work。</p><br></div><p class="readmore"><a href="/2013/10/25/2013-10-25-sloppy-python-snippets-to-capture-command-output/">Read More</a></p></div><nav class="page-navigator"><a class="extend prev" rel="prev" href="/page/2/">Previous</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/4/">Next</a></nav><script id="dsq-count-scr" src="//conimaging.disqus.com/count.js" async></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML" async></script></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://conxz.net"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/BrainResearch/">BrainResearch</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Methods/">Methods</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/OpenScience/">OpenScience</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Tools/">Tools</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Xs/">Xs</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/bayes-factor/" style="font-size: 15px;">bayes factor</a> <a href="/tags/brain-asymmetry/" style="font-size: 15px;">brain asymmetry</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/mutual-information/" style="font-size: 15px;">mutual information</a> <a href="/tags/freesurfer/" style="font-size: 15px;">freesurfer</a> <a href="/tags/reading/" style="font-size: 15px;">reading</a> <a href="/tags/mvpa/" style="font-size: 15px;">mvpa</a> <a href="/tags/paired-t-test/" style="font-size: 15px;">paired t-test</a> <a href="/tags/endnote/" style="font-size: 15px;">endnote</a> <a href="/tags/brain-network/" style="font-size: 15px;">brain network</a> <a href="/tags/R/" style="font-size: 15px;">R</a> <a href="/tags/blog/" style="font-size: 15px;">blog</a> <a href="/tags/two-sample-t-test/" style="font-size: 15px;">two-sample t-test</a> <a href="/tags/afni/" style="font-size: 15px;">afni</a> <a href="/tags/head-motion/" style="font-size: 15px;">head motion</a> <a href="/tags/white-matter/" style="font-size: 15px;">white matter</a> <a href="/tags/open-science/" style="font-size: 15px;">open science</a> <a href="/tags/collaborative-team-research/" style="font-size: 15px;">collaborative team research</a> <a href="/tags/paper/" style="font-size: 15px;">paper</a> <a href="/tags/gene/" style="font-size: 15px;">gene</a> <a href="/tags/hippocampus/" style="font-size: 15px;">hippocampus</a> <a href="/tags/google-adsense/" style="font-size: 15px;">google adsense</a> <a href="/tags/publication/" style="font-size: 15px;">publication</a> <a href="/tags/sex/" style="font-size: 15px;">sex</a> <a href="/tags/navigation/" style="font-size: 15px;">navigation</a> <a href="/tags/neuroscience/" style="font-size: 15px;">neuroscience</a> <a href="/tags/shiny-app/" style="font-size: 15px;">shiny app</a> <a href="/tags/data-science/" style="font-size: 15px;">data science</a> <a href="/tags/data-sharing/" style="font-size: 15px;">data sharing</a> <a href="/tags/p-value/" style="font-size: 15px;">p value</a> <a href="/tags/conference/" style="font-size: 15px;">conference</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/12/26/fix-multple-google-adsense-account-issues/">Google AdSense多账号问题解决方案</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/25/google-adsense-add-to-hexo/">添加Google AdSense到Hexo博客</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/04/asymOCD/">我的黑洞计划：刻画强迫症中的脑不对称性异常</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/13/scitop2018/">脑科学相关SCI Top期刊_2018</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/27/obsBrainApp/">记第一个Shiny应用obsBrain</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/15/paper-preview/">研究前沿论文先睹为快</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/06/journalsci2017/">脑科学期刊最新影响因子和中美差距</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/19/collaborative-team-research/">多中心合作与脑科学研究 由最近一篇文章想到的</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/15/figures-for-publication/">学术发表用高质量图片保存</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/08/whatisretreat/">Retreat是什么会议？</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-comment-o"> Recent Comments</i></div><script type="text/javascript" src="//conimaging.disqus.com/recent_comments_widget.js?num_items=5&amp;hide_avatars=1&amp;avatar_size=32&amp;excerpt_length=20&amp;hide_mods=1"></script></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">小孔成像.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>