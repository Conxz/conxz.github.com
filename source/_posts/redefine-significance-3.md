---
title: p值:这个锅，我不背!
date: 2017-10-1 07:13:37
tags: open science, p value
category: OpenScience
---
在关于重新定义显著性阈值的文章（Benjamin_2017_Redefine statistical significance）在线发表后，关于p值争论就没有停息，其中有支持，有反对，更有人提出了包括舍弃显著性阈值，甚至p值的新方案。这些争论很多来自方法学领域的领军人物，各方言辞凿凿，其中的争议可见一斑，短期内也不可能有个定论。下面是一些笔者自己关于p值与可重复性问题的random想法。

![显著性](/images/post_images/sig.jpg "显著性")

笔者认为，将显著性阈值本身是否合理，与研究结果的可重复性问题联系起来，本身就值得思考。这一联系，本身反映了一些研究者自身对p值的误解，以及这种误解的根深蒂固。实际上，p值反映的是，在零假设为真的情况下，出现当前结果（或更极端结果）的可能性；其与研究结果的可重复性（已发表的结果可重复的概率）并没有直接联系。更具体地，前者是Prob(p<0.05 | H0为真)，而后者是Prob(H0为真| p<0.05)，二者并非一个东西。如果期望采用0.05的显著性阈值，达到发表结果95%的可重复性的想法，本身就是有错误的。

更重要的是，理论上，显著性阈值设在0.05时，可以很好的将假阳性率控制在5%；为了更直观地呈现这一点，这里有个[模拟数据的结果](http://conxz.net/2017/09/21/redefine-significance/)。也就是说，在不存在数据操纵等不科学行为的前提下，显著性阈值可以很好的控制错误拒绝零假设的概率。

那么，现在引起众多争议的可重复性问题是如何产生的呢？

显然，如上面所示，显著性阈值本身可以很好的控制假阳性，其并非问题的根本原因。

该问题更直接的原因是**p hacking**和**power failure**。

其中，p hacking与现存的期刊倾向于发表显著结果的现状（publication bias）存在密切关联，是指一些研究者在数据采集和分析过程中，采用各种各样的手段，以试图将p值控制在显著性阈值以下；或从众多结果中，挑选显著的结果用于报告等；这一操作本身将引起估计的效应量夸大，甚至出现假阳性结果，使得错误拒绝零假设的可能性明显增加。

而power failure是指，在实际研究中，统计效力（statistical power）不够，即实际采用的样本量并不能检测感兴趣的效应，从而导致大量效应被认为是不存在的；这一问题直接导致，研究者与很多实际存在的效应只能擦肩而过，从而导致已发表的结果中，这些实际存在的效应的确实。

如此，一多（p hacking导致的假阳性结果增加）一少（power failure导致的实际存在的效应得到检测到的数量减少），从而引发已发表的研究结果的可重复性问题。

至于降低显著性阈值的策略是否能解决已发表文章的可重复性问题，这本身还是一个问题。比如，显著性阈值减低，确实可以使得假阳性结果会减少，但是，能够成功检测到的效应的数量也会减少，最终得以发表的结果的可重复性将如何变化，要取决于二者之间的权衡。

说到底，可重复性问题的根源在研究者的不合理行为：说一下极端情况，如果完全没有p hacking，同时每一个研究都有足够的统计power，那么，即使显著性阈值取0.05，也可以很好的控制研究发现的可重复性。